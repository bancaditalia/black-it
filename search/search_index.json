{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"* Black-box ABM calibration kit This package contains a black-box calibrator, which can be used to calibrate a specified model, using a loss function and a sequence of chosen search algorithms to estimate the wanted parameters. It comes with a set of ready-to-use example models, loss functions and search algorithms. Custom models and functions can be implemented to use with the calibrator. Why use it While this tool can be used as a general optimizer for any built-in or custom model, it has been created with agent-based models in mind, or any situation in which a simple optimization is not enough but you have to combine techniques. That's why the package is easily customizable in terms of model, loss and algorithms, and comes with the ability to combine search algorithms sequentially. Installation This project requires Python v3.8 or later and Poetry . To install the package simply run pip install black-it How to run Several calibration examples can be found in the examples folder of the GitHub repo. To run them, you first need to clone the repo git clone https://github.com/bancaditalia/black-it.git In the next section we will analyse in detail the main.py script, which you can run by cd black-it/examples python main.py How to use To write a basic script, it is enough to instantiate a Calibrator object and use the calibrate(n_batches) method. The following example will refer to examples/main.py . # define a loss loss = MethodOfMomentsLoss () # define the calibration seed calibration_seed = 1 # initialize a Calibrator object cal = Calibrator ( samplers = [ halton_sampler , random_forest_sampler , best_batch_sampler ], real_data = real_data , model = model , parameters_bounds = bounds , parameters_precision = bounds_step , ensemble_size = 3 , loss_function = loss , random_state = calibration_seed , ) # calibrate the model params , losses = cal . calibrate ( n_batches = 5 ) The calibrator constructor accepts as inputs: the real dataset ( real_data ), a stochastic model ( model ), a loss function ( loss_function ), the parameter space ( parameters_bounds ) a list of search algorithms ( samplers ) The method used to run the calibration ( calibrate ) accepts as input the number of batches to be executed ( n_batches ). For more information, check the Code Reference section of the documentation. Model The model must be specified as a function and is used by the calibrator to produce simulated data (for more information about this, check how it works ). In examples/main.py , the following is used: # define a model to be calibrated model = md . MarkovC_KP A list of simple models can be found in the examples/models directory. A custom model may be specified by implementing a custom function. If an external simulator has to be used instead, check simulator_interface page. Loss function The loss function must be a concrete class inheriting from the abstract class BaseLoss and is used by the calibrator to evaluate the distance between the real dataset and the simulated one. In examples/main.py , the MinkowskiLoss is used. A list of functions can be found in the loss_functions module or, again, a the BaseLoss class can be extended to implement a specific loss function. Search algorithms The calibrator accepts a list of search algorithms which are used sequentially to estimate the wanted parameters. The parameter space to be searched is defined through its bounds by specifying parameters_bounds . Each search algorithm must be specified as an object and must be instantiated first. In this example, batch_size = 8 halton_sampler = HaltonSampler ( batch_size = batch_size ) random_forest_sampler = RandomForestSampler ( batch_size = batch_size ) best_batch_sampler = BestBatchSampler ( batch_size = batch_size ) Each sampler has its own subclass derived from BaseSampler and a list of ready-to-use samplers is contained in samplers . To specify a custom algorithm, one must extend the BaseSampler superclass and implement its method sample_batch to specify how to sample a batch of parameters. Remark : when instantiated, the sampler accepts a batch_size parameter. While in this example every sampler runs on the same batch size, they can also run on different sizes, if required. License Black-it is released under the GNU Affero General Public License v3 or later (AGPLv3+). Copyright 2021-2022 Banca d'Italia. Original Author Gennaro Catapano < gennaro.catapano@bancaditalia.it > Co-authors/Maintainers Marco Benedetti < marco.benedetti@bancaditalia.it > Francesco De Sclavis < francesco.desclavis@bancaditalia.it > Marco Favorito < marco.favorito@bancaditalia.it > Aldo Glielmo < aldo.glielmo@bancaditalia.it > Davide Magnanimi < davide.magnanimi@bancaditalia.it > Antonio Muci < antonio.muci@bancaditalia.it > * Credits to Sara Corbo for the logo.","title":"Home"},{"location":"#why-use-it","text":"While this tool can be used as a general optimizer for any built-in or custom model, it has been created with agent-based models in mind, or any situation in which a simple optimization is not enough but you have to combine techniques. That's why the package is easily customizable in terms of model, loss and algorithms, and comes with the ability to combine search algorithms sequentially.","title":"Why use it"},{"location":"#installation","text":"This project requires Python v3.8 or later and Poetry . To install the package simply run pip install black-it","title":"Installation"},{"location":"#how-to-run","text":"Several calibration examples can be found in the examples folder of the GitHub repo. To run them, you first need to clone the repo git clone https://github.com/bancaditalia/black-it.git In the next section we will analyse in detail the main.py script, which you can run by cd black-it/examples python main.py","title":"How to run"},{"location":"#how-to-use","text":"To write a basic script, it is enough to instantiate a Calibrator object and use the calibrate(n_batches) method. The following example will refer to examples/main.py . # define a loss loss = MethodOfMomentsLoss () # define the calibration seed calibration_seed = 1 # initialize a Calibrator object cal = Calibrator ( samplers = [ halton_sampler , random_forest_sampler , best_batch_sampler ], real_data = real_data , model = model , parameters_bounds = bounds , parameters_precision = bounds_step , ensemble_size = 3 , loss_function = loss , random_state = calibration_seed , ) # calibrate the model params , losses = cal . calibrate ( n_batches = 5 ) The calibrator constructor accepts as inputs: the real dataset ( real_data ), a stochastic model ( model ), a loss function ( loss_function ), the parameter space ( parameters_bounds ) a list of search algorithms ( samplers ) The method used to run the calibration ( calibrate ) accepts as input the number of batches to be executed ( n_batches ). For more information, check the Code Reference section of the documentation.","title":"How to use"},{"location":"#model","text":"The model must be specified as a function and is used by the calibrator to produce simulated data (for more information about this, check how it works ). In examples/main.py , the following is used: # define a model to be calibrated model = md . MarkovC_KP A list of simple models can be found in the examples/models directory. A custom model may be specified by implementing a custom function. If an external simulator has to be used instead, check simulator_interface page.","title":"Model"},{"location":"#loss-function","text":"The loss function must be a concrete class inheriting from the abstract class BaseLoss and is used by the calibrator to evaluate the distance between the real dataset and the simulated one. In examples/main.py , the MinkowskiLoss is used. A list of functions can be found in the loss_functions module or, again, a the BaseLoss class can be extended to implement a specific loss function.","title":"Loss function"},{"location":"#search-algorithms","text":"The calibrator accepts a list of search algorithms which are used sequentially to estimate the wanted parameters. The parameter space to be searched is defined through its bounds by specifying parameters_bounds . Each search algorithm must be specified as an object and must be instantiated first. In this example, batch_size = 8 halton_sampler = HaltonSampler ( batch_size = batch_size ) random_forest_sampler = RandomForestSampler ( batch_size = batch_size ) best_batch_sampler = BestBatchSampler ( batch_size = batch_size ) Each sampler has its own subclass derived from BaseSampler and a list of ready-to-use samplers is contained in samplers . To specify a custom algorithm, one must extend the BaseSampler superclass and implement its method sample_batch to specify how to sample a batch of parameters. Remark : when instantiated, the sampler accepts a batch_size parameter. While in this example every sampler runs on the same batch size, they can also run on different sizes, if required.","title":"Search algorithms"},{"location":"#license","text":"Black-it is released under the GNU Affero General Public License v3 or later (AGPLv3+). Copyright 2021-2022 Banca d'Italia.","title":"License"},{"location":"#original-author","text":"Gennaro Catapano < gennaro.catapano@bancaditalia.it >","title":"Original Author"},{"location":"#co-authorsmaintainers","text":"Marco Benedetti < marco.benedetti@bancaditalia.it > Francesco De Sclavis < francesco.desclavis@bancaditalia.it > Marco Favorito < marco.favorito@bancaditalia.it > Aldo Glielmo < aldo.glielmo@bancaditalia.it > Davide Magnanimi < davide.magnanimi@bancaditalia.it > Antonio Muci < antonio.muci@bancaditalia.it > * Credits to Sara Corbo for the logo.","title":"Co-authors/Maintainers"},{"location":"benchmarking_samplers/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Benchmarking different samplers against a standard ABM In this tutorial we compare the performance of different sampling methods for the calibration of the paradigmatic model for asset pricing by Brock and Hommes ( Journal of Economic Dynamics and Control , 1998). import numpy as np from models.economics.brock_hommes import BH4 import matplotlib.pyplot as plt from black_it.calibrator import Calibrator import pandas as pd # generate a single realisation of the BH4 using parameters # from the literature (see Platt (2020)) true_params = [ 0.0 , # g1 0.0 , # b1 0.9 , # g2 0.2 , # b2 0.9 , # g3 - 0.2 , # b3 1.01 , # g4 0.01 ] # b4 parameter_bounds = [[ 0. , 0. , 0. , 0. , 0. , - 1. , 1. , 0. ], # lower bounds [ 0.1 , 0.1 , 1. , 1. , 1. , 0. , 1.1 , 1. ]] # upper bounds precisions = [ 0.01 , 0.01 , 0.01 , 0.01 , 0.01 , 0.01 , 0.01 , 0.01 ] target_series = BH4 ( true_params , N = 1000 , seed = 0 ) # plot the target time series plt . figure ( figsize = ( 7 , 5 )) plt . plot ( target_series ) plt . xlabel ( 't' , fontsize = 14 ) plt . ylabel ( 'x' , fontsize = 14 ) plt . xticks ( fontsize = 12 ); plt . yticks ( fontsize = 12 ); # import a series of samplers to benchmark from black_it.samplers.halton import HaltonSampler from black_it.samplers.random_forest import RandomForestSampler from black_it.samplers.best_batch import BestBatchSampler all_samplers = [ HaltonSampler , RandomForestSampler , BestBatchSampler ] # initialize a set of sampling methods to test, # note that each method uses the same effective batch size # 3 single samplers, batch size = 6 batch_size = 6 single_samplers = [[ s ( batch_size = batch_size )] for s in all_samplers ] # the 3 combinations of 2 different samplers, batch sizes = 3 couple_indices = [[ 0 , 1 ], [ 0 , 2 ], [ 1 , 2 ]] couple_samplers = [] for ci in couple_indices : couple = [] for i in ci : couple . append ( all_samplers [ i ]( batch_size = int ( batch_size / 2 ))) couple_samplers . append ( couple ) # a combination of all 3 samplers, batch sizes = 2 triplet_indices = [ 0 , 1 , 2 ] triplet_samplers = [[ all_samplers [ i ]( batch_size = int ( batch_size / 3 )) for i in triplet_indices ]] # define a list with all calibration strategies all_calibration_strategies = single_samplers + couple_samplers + triplet_samplers # define a method of moments loss from black_it.loss_functions.msm import MethodOfMomentsLoss loss = MethodOfMomentsLoss () # sample a few random parameters to provide a starting point to the adaptive samplers from black_it.samplers.random_uniform import RandomUniformSampler random_sampler = RandomUniformSampler ( batch_size ) cal = Calibrator ( real_data = target_series , samplers = [ random_sampler ], loss_function = loss , model = BH4 , parameters_bounds = parameter_bounds , parameters_precision = precisions , ensemble_size = 3 , saving_folder = 'initial_state' ) _ , _ = cal . calibrate ( 1 ) *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: RandomUniformSampler ----> sim exec elapsed time: 2.8s ----> min loss new params: 4.09 ----> avg loss new params: 4.419277934778664e+71 ----> avg loss exist params: 4.419277934778664e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 2.8s Checkpoint saved in 0.0s # run a series of experiments of 10 epochs each, and save the results for i , samplers in enumerate ( all_calibration_strategies ): print ( 'Sampling strategy ' , i , 'of ' , len ( all_calibration_strategies )) sampler_name = '' for s in samplers : sampler_name += type ( s ) . __name__ cal = Calibrator . restore_from_checkpoint ( 'initial_state' , model = BH4 ) cal . set_samplers ( samplers ) cal . saving_folder = sampler_name cal . calibrate ( 10 ) Sampling strategy 0 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 3.66 ----> avg loss new params: 8.300758412517313e+24 ----> avg loss exist params: 2.2096389673893325e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.9s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 1.8143899404071114e+25 ----> avg loss new params: 1.9531662506640626e+49 ----> avg loss exist params: 1.4730926449262217e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.9s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 635.52 ----> avg loss new params: 1.4682776406569115e+65 ----> avg loss exist params: 1.1048198507640762e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.9s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 1.08 ----> avg loss new params: 1.0259600018245788e+25 ----> avg loss exist params: 8.838558806112611e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.8s Checkpoint saved in 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 1.1663765177260362e+33 ----> avg loss new params: 1.2315345916152899e+57 ----> avg loss exist params: 7.365465671760529e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.9s Checkpoint saved in 0.0s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: HaltonSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 522.0 ----> avg loss new params: 2.650221569942234e+65 ----> avg loss exist params: 6.313260076111268e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.8s Checkpoint saved in 0.0s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 3.13 ----> avg loss new params: 6.323596971065026e+31 ----> avg loss exist params: 5.524102566597359e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.9s Checkpoint saved in 0.0s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 9.871204642368983e+32 ----> avg loss new params: 2.0354753999901843e+57 ----> avg loss exist params: 4.910313392531009e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.8s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 389.87 ----> avg loss new params: 1.9594869275792813e+65 ----> avg loss exist params: 4.419284012764835e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.9s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 2.95 ----> avg loss new params: 1.9693240640656187e+32 ----> avg loss exist params: 4.017530920695304e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.7s Checkpoint saved in 0.1s Sampling strategy 1 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 1.44 ----> avg loss new params: 2.9772293266637943e+72 ----> avg loss exist params: 1.7095785600708306e+72 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.0s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 3.09 ----> avg loss new params: 8.046150675194563e+17 ----> avg loss exist params: 1.1397190400472204e+72 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.0s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.0s ----> min loss new params: 158.86 ----> avg loss new params: 1.1850121207855025e+18 ----> avg loss exist params: 8.547892800354153e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 1.9s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 230659.17 ----> avg loss new params: 4.2845603081718367e+55 ----> avg loss exist params: 6.838314240283323e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 1.9s Checkpoint saved in 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 7.16 ----> avg loss new params: 4.952491859756142e+17 ----> avg loss exist params: 5.698595200236102e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.8s Checkpoint saved in 0.0s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 4.51 ----> avg loss new params: 28.13 ----> avg loss exist params: 4.884510171630944e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.7s Checkpoint saved in 0.1s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 4.59 ----> avg loss new params: 1.4545076704483378e+30 ----> avg loss exist params: 4.2739464001770764e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.5s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.4s ----> min loss new params: 2.49 ----> avg loss new params: 1.4027803946629642e+22 ----> avg loss exist params: 3.799063466824068e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.4s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 1.28 ----> avg loss new params: 4.658999191050945e+16 ----> avg loss exist params: 3.4191571201416613e+71 ----> curr min loss: 1.2772975970984322 ====> total elapsed time: 2.4s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 1.01 ----> avg loss new params: 1.327724523081595e+40 ----> avg loss exist params: 3.1083246546742375e+71 ----> curr min loss: 1.005559758393759 ====> total elapsed time: 1.8s Checkpoint saved in 0.1s Sampling strategy 2 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.0s ----> min loss new params: 1.2743993839456501e+33 ----> avg loss new params: 3.134246498833947e+73 ----> avg loss exist params: 1.589219639090867e+73 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 1.0s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.0s ----> min loss new params: 4.69 ----> avg loss new params: 2.3299915681425326e+48 ----> avg loss exist params: 1.0594797593939112e+73 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 1.0s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 3.54 ----> avg loss new params: 5.4794875763647744e+72 ----> avg loss exist params: 9.315970089545528e+72 ----> curr min loss: 3.537864613089154 ====> total elapsed time: 1.1s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: BestBatchSampler ----> sim exec elapsed time: 2.0s ----> min loss new params: 3.65 ----> avg loss new params: 5.477355418974891e+54 ----> avg loss exist params: 7.452776071636422e+72 ----> curr min loss: 3.537864613089154 ====> total elapsed time: 2.0s Checkpoint saved in 0.1s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.7s ----> min loss new params: 3.06 ----> avg loss new params: 3.648147170157569e+32 ----> avg loss exist params: 6.210646726363686e+72 ----> curr min loss: 3.061494620652621 ====> total elapsed time: 1.7s Checkpoint saved in 0.1s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.0s ----> min loss new params: 2.75 ----> avg loss new params: 3.19 ----> avg loss exist params: 5.323411479740301e+72 ----> curr min loss: 2.7469033833359866 ====> total elapsed time: 1.0s Checkpoint saved in 0.0s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.5s ----> min loss new params: 2.51 ----> avg loss new params: 3.32 ----> avg loss exist params: 4.657985044772764e+72 ----> curr min loss: 2.5106289507714665 ====> total elapsed time: 1.5s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.4s ----> min loss new params: 1.69 ----> avg loss new params: 2.8230131715153864e+46 ----> avg loss exist params: 4.140431150909123e+72 ----> curr min loss: 1.6890182521981136 ====> total elapsed time: 1.4s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 1.74 ----> avg loss new params: 2.4 ----> avg loss exist params: 3.726388035818211e+72 ----> curr min loss: 1.6890182521981136 ====> total elapsed time: 0.9s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 1.71 ----> avg loss new params: 1.371171529418354e+16 ----> avg loss exist params: 3.3876254871074644e+72 ----> curr min loss: 1.6890182521981136 ====> total elapsed time: 0.8s Checkpoint saved in 0.1s Sampling strategy 3 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.66 ----> avg loss new params: 23759.98 ----> avg loss exist params: 2.9461852898524434e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 266.38 ----> avg loss new params: 4.929504599938332e+24 ----> avg loss exist params: 2.2096389673893325e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 1.4s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 259408.3 ----> avg loss new params: 1.3418466928955868e+25 ----> avg loss exist params: 1.7677111739114658e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 5.59 ----> avg loss new params: 9.91 ----> avg loss exist params: 1.4730926449262217e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 1.3s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.218208797625005e+25 ----> avg loss new params: 4.330494474331893e+33 ----> avg loss exist params: 1.2626508385081898e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 4.79 ----> avg loss new params: 4.1039175555312315e+40 ----> avg loss exist params: 1.1048194836946663e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 1.9s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 1.0817917199830301e+42 ----> avg loss new params: 3.9053598974827594e+49 ----> avg loss exist params: 9.820617632841477e+70 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 3.19 ----> avg loss new params: 1.9816531622380618e+31 ----> avg loss exist params: 8.838555869557329e+70 ----> curr min loss: 3.190897002897203 ====> total elapsed time: 1.7s Checkpoint saved in 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 7.022331859686527e+57 ----> avg loss new params: 3.5277422231985074e+64 ----> avg loss exist params: 8.035051111210502e+70 ----> curr min loss: 3.190897002897203 ====> total elapsed time: 0.7s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 2.38 ----> avg loss new params: 5475.56 ----> avg loss exist params: 7.365463518609625e+70 ----> curr min loss: 2.376892792787833 ====> total elapsed time: 3.5s Checkpoint saved in 0.0s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 606.59 ----> avg loss new params: 3.6625250278652666e+65 ----> avg loss exist params: 6.798892219120445e+70 ----> curr min loss: 2.376892792787833 ====> total elapsed time: 0.7s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 4.47 ----> avg loss new params: 19.76 ----> avg loss exist params: 6.313257060611841e+70 ----> curr min loss: 2.376892792787833 ====> total elapsed time: 2.4s Checkpoint saved in 0.2s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: HaltonSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 1.11 ----> avg loss new params: 7.18 ----> avg loss exist params: 5.892373256571052e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 1.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 6.03 ----> avg loss new params: 27.11 ----> avg loss exist params: 5.524099928035361e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 2.2s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 1.14089698130206e+17 ----> avg loss new params: 2.1170674425931233e+25 ----> avg loss exist params: 5.199152873445046e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.6s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 1.22 ----> avg loss new params: 12.59 ----> avg loss exist params: 4.9103110471425434e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 1.7s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: HaltonSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 2.785000441888143e+33 ----> avg loss new params: 2.1868878143494303e+41 ----> avg loss exist params: 4.651873623608726e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.6s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 13.6 ----> avg loss new params: 1.1235228254061286e+32 ----> avg loss exist params: 4.419279942428289e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 1.3s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: HaltonSampler ----> sim exec elapsed time: 1.5s ----> min loss new params: 7.165734019763288e+48 ----> avg loss new params: 2.613140765222106e+57 ----> avg loss exist params: 4.2088380404079067e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 1.5s METHOD: RandomForestSampler ----> sim exec elapsed time: 1.9s ----> min loss new params: 6.33 ----> avg loss new params: 9.43 ----> avg loss exist params: 4.017527220389366e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 4.1s Checkpoint saved in 0.2s Sampling strategy 4 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 3.66 ----> avg loss new params: 23759.98 ----> avg loss exist params: 2.9461852898524434e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.91 ----> avg loss new params: 9.57 ----> avg loss exist params: 2.2096389673893325e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 259408.3 ----> avg loss new params: 1.3418466928955868e+25 ----> avg loss exist params: 1.7677111739114658e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 3.38 ----> avg loss new params: 3.63 ----> avg loss exist params: 1.4730926449262217e+71 ----> curr min loss: 3.3807587026196213 ====> total elapsed time: 0.8s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 3.218208797625005e+25 ----> avg loss new params: 4.330494474331893e+33 ----> avg loss exist params: 1.2626508385081898e+71 ----> curr min loss: 3.3807587026196213 ====> total elapsed time: 0.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 2.99 ----> avg loss new params: 4.57 ----> avg loss exist params: 1.1048194836946663e+71 ----> curr min loss: 2.986363446469386 ====> total elapsed time: 0.5s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 1.0817917199830301e+42 ----> avg loss new params: 3.9053598974827594e+49 ----> avg loss exist params: 9.820617632841477e+70 ----> curr min loss: 2.986363446469386 ====> total elapsed time: 0.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 2.91 ----> avg loss new params: 4.303297507113467e+39 ----> avg loss exist params: 8.838555869557329e+70 ----> curr min loss: 2.9081793471084874 ====> total elapsed time: 0.5s Checkpoint saved in 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 7.022331859686527e+57 ----> avg loss new params: 3.5277422231985074e+64 ----> avg loss exist params: 8.035051111210502e+70 ----> curr min loss: 2.9081793471084874 ====> total elapsed time: 0.4s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 1.61 ----> avg loss new params: 4.36 ----> avg loss exist params: 7.365463518609625e+70 ----> curr min loss: 1.6090030240712685 ====> total elapsed time: 0.4s Checkpoint saved in 0.1s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 606.59 ----> avg loss new params: 3.6625250278652666e+65 ----> avg loss exist params: 6.798892219120445e+70 ----> curr min loss: 1.6090030240712685 ====> total elapsed time: 0.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.62 ----> avg loss new params: 123998723929308.95 ----> avg loss exist params: 6.313257060611841e+70 ----> curr min loss: 1.6090030240712685 ====> total elapsed time: 0.4s Checkpoint saved in 0.1s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 1.11 ----> avg loss new params: 7.18 ----> avg loss exist params: 5.892373256571052e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.9s ----> min loss new params: 1.9 ----> avg loss new params: 3.978581939282771e+31 ----> avg loss exist params: 5.524099928035361e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 1.9s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 1.14089698130206e+17 ----> avg loss new params: 2.1170674425931233e+25 ----> avg loss exist params: 5.199152873445046e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 1.13 ----> avg loss new params: 1.48 ----> avg loss exist params: 4.9103110471425434e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.8s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 2.785000441888143e+33 ----> avg loss new params: 2.1868878143494303e+41 ----> avg loss exist params: 4.651873623608726e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 0.94 ----> avg loss new params: 1.14 ----> avg loss exist params: 4.419279942428289e+70 ----> curr min loss: 0.942413698087732 ====> total elapsed time: 1.1s Checkpoint saved in 0.2s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 7.165734019763288e+48 ----> avg loss new params: 2.613140765222106e+57 ----> avg loss exist params: 4.2088380404079067e+70 ----> curr min loss: 0.942413698087732 ====> total elapsed time: 0.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.0s ----> min loss new params: 1.18 ----> avg loss new params: 1.470380789543466e+48 ----> avg loss exist params: 4.017527220389366e+70 ----> curr min loss: 0.942413698087732 ====> total elapsed time: 1.0s Checkpoint saved in 0.1s Sampling strategy 5 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 12.66 ----> avg loss new params: 30.73 ----> avg loss exist params: 2.9461852898524434e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 2.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.4s ----> min loss new params: 12.8 ----> avg loss new params: 10431.01 ----> avg loss exist params: 2.2096389673893325e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 1.4s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 6.81 ----> avg loss new params: 4.3550320248811904e+17 ----> avg loss exist params: 1.7677111739114658e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 4.8s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 8.52 ----> avg loss new params: 9.864850943917757e+62 ----> avg loss exist params: 1.4730926465703633e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 0.6s Checkpoint saved in 0.1s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: RandomForestSampler ----> sim exec elapsed time: 2.2s ----> min loss new params: 9.55 ----> avg loss new params: 3.887305425463723e+32 ----> avg loss exist params: 1.2626508399174543e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 3.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 2.5s ----> min loss new params: 6.55 ----> avg loss new params: 10.8 ----> avg loss exist params: 1.1048194849277725e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 2.6s Checkpoint saved in 0.2s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: RandomForestSampler ----> sim exec elapsed time: 2.4s ----> min loss new params: 3.03 ----> avg loss new params: 3.9 ----> avg loss exist params: 9.820617643802423e+70 ----> curr min loss: 3.0284708010510477 ====> total elapsed time: 4.3s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.9s ----> min loss new params: 4.5 ----> avg loss new params: 1.120218120072616e+40 ----> avg loss exist params: 8.838555879422181e+70 ----> curr min loss: 3.0284708010510477 ====> total elapsed time: 1.9s Checkpoint saved in 0.2s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.3s ----> min loss new params: 3.96 ----> avg loss new params: 7.5 ----> avg loss exist params: 8.035050799474711e+70 ----> curr min loss: 3.0284708010510477 ====> total elapsed time: 3.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 4.88 ----> avg loss new params: 7.83 ----> avg loss exist params: 7.365463232851817e+70 ----> curr min loss: 3.0284708010510477 ====> total elapsed time: 1.1s Checkpoint saved in 0.1s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.3s ----> min loss new params: 3.01 ----> avg loss new params: 6.78 ----> avg loss exist params: 6.798889138017061e+70 ----> curr min loss: 3.0120008197397503 ====> total elapsed time: 3.3s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 3.48 ----> avg loss new params: 4.2366396762870067e+18 ----> avg loss exist params: 6.313254199587272e+70 ----> curr min loss: 3.0120008197397503 ====> total elapsed time: 0.8s Checkpoint saved in 0.1s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.5s ----> min loss new params: 2.35 ----> avg loss new params: 5.86 ----> avg loss exist params: 5.892370586281454e+70 ----> curr min loss: 2.3490688746866115 ====> total elapsed time: 3.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 2.1 ----> avg loss new params: 4.5170950241116807e+24 ----> avg loss exist params: 5.524097424638862e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 1.2s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 143.9 ----> avg loss new params: 6.3136134841751816e+16 ----> avg loss exist params: 5.1991505173071656e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 1.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 2.21 ----> avg loss new params: 2.87 ----> avg loss exist params: 4.910308821901212e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 0.8s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 3.78 ----> avg loss new params: 7.144988739148858e+18 ----> avg loss exist params: 4.651871515485358e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 2.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 2.16 ----> avg loss new params: 2.52 ----> avg loss exist params: 4.4192779397110904e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 0.7s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 2.133175205090705e+26 ----> avg loss new params: 9.445350178094928e+55 ----> avg loss exist params: 4.2088361330581827e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 1.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 2.81 ----> avg loss new params: 1.8945860536525166e+39 ----> avg loss exist params: 4.0175253997373555e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 0.6s Checkpoint saved in 0.1s Sampling strategy 6 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.66 ----> avg loss new params: 7.73 ----> avg loss exist params: 3.3144584510839986e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 156.11 ----> avg loss new params: 1.421244832993949e+26 ----> avg loss exist params: 2.6515667608671987e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 1.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 4.64 ----> avg loss new params: 9.528436025701058e+22 ----> avg loss exist params: 2.2096389673893325e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.5s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 94300.57 ----> avg loss new params: 149916.69 ----> avg loss exist params: 1.893976257762285e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.5s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 59.02 ----> avg loss new params: 589.01 ----> avg loss exist params: 1.6572292255419993e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 2.2s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 3.49 ----> avg loss new params: 3.74 ----> avg loss exist params: 1.4730926449262217e+71 ----> curr min loss: 3.490052814946999 ====> total elapsed time: 0.6s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 2.2252400654072278e+17 ----> avg loss new params: 2.0762227039805127e+25 ----> avg loss exist params: 1.3257833804335994e+71 ----> curr min loss: 3.490052814946999 ====> total elapsed time: 0.7s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 2.25 ----> avg loss new params: 387216.91 ----> avg loss exist params: 1.2052576185759994e+71 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 1.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 2.85 ----> avg loss new params: 5.110258403121564e+31 ----> avg loss exist params: 1.1048194836946663e+71 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 0.4s Checkpoint saved in 0.1s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 2.0543465401664097e+25 ----> avg loss new params: 3.6848605655597034e+33 ----> avg loss exist params: 1.0198333695643073e+71 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 0.8s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 3.71 ----> avg loss new params: 4.03 ----> avg loss exist params: 9.469881288811425e+70 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 1.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 2.4 ----> avg loss new params: 2.58 ----> avg loss exist params: 8.838555869557329e+70 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 0.5s Checkpoint saved in 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: HaltonSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 9.534641615636949e+33 ----> avg loss new params: 5.457569779907695e+41 ----> avg loss exist params: 8.286146127709996e+70 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 0.8s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.61 ----> avg loss new params: 8.29 ----> avg loss exist params: 7.798725767256467e+70 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 1.8s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 2.21 ----> avg loss new params: 2.49 ----> avg loss exist params: 7.365463224631108e+70 ----> curr min loss: 2.2063781203583126 ====> total elapsed time: 0.4s Checkpoint saved in 0.1s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 1.2930856737877442e+42 ----> avg loss new params: 5.852402936836168e+49 ----> avg loss exist params: 6.977807265439997e+70 ----> curr min loss: 2.2063781203583126 ====> total elapsed time: 0.9s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 6.67 ----> avg loss new params: 137.43 ----> avg loss exist params: 6.628916902167997e+70 ----> curr min loss: 2.2063781203583126 ====> total elapsed time: 2.3s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 1.45 ----> avg loss new params: 1.0122406761007165e+48 ----> avg loss exist params: 6.313254192540949e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 0.4s Checkpoint saved in 0.0s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: HaltonSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 4.693912088645729e+57 ----> avg loss new params: 7.321340783291673e+57 ----> avg loss exist params: 6.02628809288003e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 0.3s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 8.39 ----> avg loss new params: 34.61 ----> avg loss exist params: 5.764275567102637e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 1.4s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 3.19 ----> avg loss new params: 1.698842407427921e+47 ----> avg loss exist params: 5.524097418473361e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 0.3s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 3.288144112758467e+65 ----> avg loss new params: 7.102222980735781e+65 ----> avg loss exist params: 5.303136362623619e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 0.3s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 2.82 ----> avg loss new params: 4.49 ----> avg loss exist params: 5.099169579445788e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 1.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 1.33 ----> avg loss new params: 1.4 ----> avg loss exist params: 4.910311446873721e+70 ----> curr min loss: 1.3320791175674513 ====> total elapsed time: 0.3s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 601.45 ----> avg loss new params: 1593.66 ----> avg loss exist params: 4.734943180913945e+70 ----> curr min loss: 1.3320791175674513 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 6.76 ----> avg loss new params: 3.645056588348578e+24 ----> avg loss exist params: 4.5716692781238096e+70 ----> curr min loss: 1.3320791175674513 ====> total elapsed time: 1.2s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 9.80672370968492e+16 ----> avg loss new params: 1.0486335887746384e+32 ----> avg loss exist params: 4.419280302186348e+70 ----> curr min loss: 1.3320791175674513 ====> total elapsed time: 0.3s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: HaltonSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 0.9 ----> avg loss new params: 7.53 ----> avg loss exist params: 4.2767228730835636e+70 ----> curr min loss: 0.9031595091997369 ====> total elapsed time: 0.6s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 10611.75 ----> avg loss new params: 2.84600288413688e+31 ----> avg loss exist params: 4.143075283299702e+70 ----> curr min loss: 0.9031595091997369 ====> total elapsed time: 1.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 4.82 ----> avg loss new params: 8.096356842026602e+24 ----> avg loss exist params: 4.0175275474421353e+70 ----> curr min loss: 0.9031595091997369 ====> total elapsed time: 0.4s Checkpoint saved in 0.1s # load the results from the corresponding folders, and plot them! plt . figure ( figsize = ( 7 , 5 )) lss = [ ':' ] * 3 + [ '--' ] * 3 + [ '-' ] for i , sampler in enumerate ( all_calibration_strategies ): # name of the corresponding folder sampler_name = '' for s in sampler : sampler_name += type ( s ) . __name__ # get array of minimum losses achieved losses = pd . read_csv ( sampler_name + '/calibration_results.csv' )[ 'losses_samp' ] . cummin () sampler_name = sampler_name . replace ( \"Sampler\" , \" \" ) # plot the loss curve plt . plot ( losses , label = sampler_name , ls = lss [ i ], lw = 2.5 ) plt . legend ( loc = 'upper center' , bbox_to_anchor = ( 0.4 , - 0.14 ), prop = { 'size' : 14 }) plt . xlabel ( 'model calls' , fontsize = 14 ) plt . ylabel ( 'loss' , fontsize = 14 ); plt . xticks ( fontsize = 12 ); plt . yticks ( fontsize = 12 );","title":"Benchmarking samplers"},{"location":"benchmarking_samplers/#benchmarking-different-samplers-against-a-standard-abm","text":"In this tutorial we compare the performance of different sampling methods for the calibration of the paradigmatic model for asset pricing by Brock and Hommes ( Journal of Economic Dynamics and Control , 1998). import numpy as np from models.economics.brock_hommes import BH4 import matplotlib.pyplot as plt from black_it.calibrator import Calibrator import pandas as pd # generate a single realisation of the BH4 using parameters # from the literature (see Platt (2020)) true_params = [ 0.0 , # g1 0.0 , # b1 0.9 , # g2 0.2 , # b2 0.9 , # g3 - 0.2 , # b3 1.01 , # g4 0.01 ] # b4 parameter_bounds = [[ 0. , 0. , 0. , 0. , 0. , - 1. , 1. , 0. ], # lower bounds [ 0.1 , 0.1 , 1. , 1. , 1. , 0. , 1.1 , 1. ]] # upper bounds precisions = [ 0.01 , 0.01 , 0.01 , 0.01 , 0.01 , 0.01 , 0.01 , 0.01 ] target_series = BH4 ( true_params , N = 1000 , seed = 0 ) # plot the target time series plt . figure ( figsize = ( 7 , 5 )) plt . plot ( target_series ) plt . xlabel ( 't' , fontsize = 14 ) plt . ylabel ( 'x' , fontsize = 14 ) plt . xticks ( fontsize = 12 ); plt . yticks ( fontsize = 12 ); # import a series of samplers to benchmark from black_it.samplers.halton import HaltonSampler from black_it.samplers.random_forest import RandomForestSampler from black_it.samplers.best_batch import BestBatchSampler all_samplers = [ HaltonSampler , RandomForestSampler , BestBatchSampler ] # initialize a set of sampling methods to test, # note that each method uses the same effective batch size # 3 single samplers, batch size = 6 batch_size = 6 single_samplers = [[ s ( batch_size = batch_size )] for s in all_samplers ] # the 3 combinations of 2 different samplers, batch sizes = 3 couple_indices = [[ 0 , 1 ], [ 0 , 2 ], [ 1 , 2 ]] couple_samplers = [] for ci in couple_indices : couple = [] for i in ci : couple . append ( all_samplers [ i ]( batch_size = int ( batch_size / 2 ))) couple_samplers . append ( couple ) # a combination of all 3 samplers, batch sizes = 2 triplet_indices = [ 0 , 1 , 2 ] triplet_samplers = [[ all_samplers [ i ]( batch_size = int ( batch_size / 3 )) for i in triplet_indices ]] # define a list with all calibration strategies all_calibration_strategies = single_samplers + couple_samplers + triplet_samplers # define a method of moments loss from black_it.loss_functions.msm import MethodOfMomentsLoss loss = MethodOfMomentsLoss () # sample a few random parameters to provide a starting point to the adaptive samplers from black_it.samplers.random_uniform import RandomUniformSampler random_sampler = RandomUniformSampler ( batch_size ) cal = Calibrator ( real_data = target_series , samplers = [ random_sampler ], loss_function = loss , model = BH4 , parameters_bounds = parameter_bounds , parameters_precision = precisions , ensemble_size = 3 , saving_folder = 'initial_state' ) _ , _ = cal . calibrate ( 1 ) *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: RandomUniformSampler ----> sim exec elapsed time: 2.8s ----> min loss new params: 4.09 ----> avg loss new params: 4.419277934778664e+71 ----> avg loss exist params: 4.419277934778664e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 2.8s Checkpoint saved in 0.0s # run a series of experiments of 10 epochs each, and save the results for i , samplers in enumerate ( all_calibration_strategies ): print ( 'Sampling strategy ' , i , 'of ' , len ( all_calibration_strategies )) sampler_name = '' for s in samplers : sampler_name += type ( s ) . __name__ cal = Calibrator . restore_from_checkpoint ( 'initial_state' , model = BH4 ) cal . set_samplers ( samplers ) cal . saving_folder = sampler_name cal . calibrate ( 10 ) Sampling strategy 0 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 3.66 ----> avg loss new params: 8.300758412517313e+24 ----> avg loss exist params: 2.2096389673893325e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.9s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 1.8143899404071114e+25 ----> avg loss new params: 1.9531662506640626e+49 ----> avg loss exist params: 1.4730926449262217e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.9s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 635.52 ----> avg loss new params: 1.4682776406569115e+65 ----> avg loss exist params: 1.1048198507640762e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.9s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 1.08 ----> avg loss new params: 1.0259600018245788e+25 ----> avg loss exist params: 8.838558806112611e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.8s Checkpoint saved in 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 1.1663765177260362e+33 ----> avg loss new params: 1.2315345916152899e+57 ----> avg loss exist params: 7.365465671760529e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.9s Checkpoint saved in 0.0s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: HaltonSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 522.0 ----> avg loss new params: 2.650221569942234e+65 ----> avg loss exist params: 6.313260076111268e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.8s Checkpoint saved in 0.0s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 3.13 ----> avg loss new params: 6.323596971065026e+31 ----> avg loss exist params: 5.524102566597359e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.9s Checkpoint saved in 0.0s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 9.871204642368983e+32 ----> avg loss new params: 2.0354753999901843e+57 ----> avg loss exist params: 4.910313392531009e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.8s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 389.87 ----> avg loss new params: 1.9594869275792813e+65 ----> avg loss exist params: 4.419284012764835e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.9s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 2.95 ----> avg loss new params: 1.9693240640656187e+32 ----> avg loss exist params: 4.017530920695304e+70 ----> curr min loss: 1.0764783501698882 ====> total elapsed time: 0.7s Checkpoint saved in 0.1s Sampling strategy 1 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 1.44 ----> avg loss new params: 2.9772293266637943e+72 ----> avg loss exist params: 1.7095785600708306e+72 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.0s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 3.09 ----> avg loss new params: 8.046150675194563e+17 ----> avg loss exist params: 1.1397190400472204e+72 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.0s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.0s ----> min loss new params: 158.86 ----> avg loss new params: 1.1850121207855025e+18 ----> avg loss exist params: 8.547892800354153e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 1.9s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 230659.17 ----> avg loss new params: 4.2845603081718367e+55 ----> avg loss exist params: 6.838314240283323e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 1.9s Checkpoint saved in 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 7.16 ----> avg loss new params: 4.952491859756142e+17 ----> avg loss exist params: 5.698595200236102e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.8s Checkpoint saved in 0.0s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 4.51 ----> avg loss new params: 28.13 ----> avg loss exist params: 4.884510171630944e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.7s Checkpoint saved in 0.1s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 4.59 ----> avg loss new params: 1.4545076704483378e+30 ----> avg loss exist params: 4.2739464001770764e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.5s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.4s ----> min loss new params: 2.49 ----> avg loss new params: 1.4027803946629642e+22 ----> avg loss exist params: 3.799063466824068e+71 ----> curr min loss: 1.442009376321102 ====> total elapsed time: 2.4s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 1.28 ----> avg loss new params: 4.658999191050945e+16 ----> avg loss exist params: 3.4191571201416613e+71 ----> curr min loss: 1.2772975970984322 ====> total elapsed time: 2.4s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 1.01 ----> avg loss new params: 1.327724523081595e+40 ----> avg loss exist params: 3.1083246546742375e+71 ----> curr min loss: 1.005559758393759 ====> total elapsed time: 1.8s Checkpoint saved in 0.1s Sampling strategy 2 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.0s ----> min loss new params: 1.2743993839456501e+33 ----> avg loss new params: 3.134246498833947e+73 ----> avg loss exist params: 1.589219639090867e+73 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 1.0s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.0s ----> min loss new params: 4.69 ----> avg loss new params: 2.3299915681425326e+48 ----> avg loss exist params: 1.0594797593939112e+73 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 1.0s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 3.54 ----> avg loss new params: 5.4794875763647744e+72 ----> avg loss exist params: 9.315970089545528e+72 ----> curr min loss: 3.537864613089154 ====> total elapsed time: 1.1s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: BestBatchSampler ----> sim exec elapsed time: 2.0s ----> min loss new params: 3.65 ----> avg loss new params: 5.477355418974891e+54 ----> avg loss exist params: 7.452776071636422e+72 ----> curr min loss: 3.537864613089154 ====> total elapsed time: 2.0s Checkpoint saved in 0.1s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.7s ----> min loss new params: 3.06 ----> avg loss new params: 3.648147170157569e+32 ----> avg loss exist params: 6.210646726363686e+72 ----> curr min loss: 3.061494620652621 ====> total elapsed time: 1.7s Checkpoint saved in 0.1s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.0s ----> min loss new params: 2.75 ----> avg loss new params: 3.19 ----> avg loss exist params: 5.323411479740301e+72 ----> curr min loss: 2.7469033833359866 ====> total elapsed time: 1.0s Checkpoint saved in 0.0s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.5s ----> min loss new params: 2.51 ----> avg loss new params: 3.32 ----> avg loss exist params: 4.657985044772764e+72 ----> curr min loss: 2.5106289507714665 ====> total elapsed time: 1.5s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: BestBatchSampler ----> sim exec elapsed time: 1.4s ----> min loss new params: 1.69 ----> avg loss new params: 2.8230131715153864e+46 ----> avg loss exist params: 4.140431150909123e+72 ----> curr min loss: 1.6890182521981136 ====> total elapsed time: 1.4s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 1.74 ----> avg loss new params: 2.4 ----> avg loss exist params: 3.726388035818211e+72 ----> curr min loss: 1.6890182521981136 ====> total elapsed time: 0.9s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 1.71 ----> avg loss new params: 1.371171529418354e+16 ----> avg loss exist params: 3.3876254871074644e+72 ----> curr min loss: 1.6890182521981136 ====> total elapsed time: 0.8s Checkpoint saved in 0.1s Sampling strategy 3 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.66 ----> avg loss new params: 23759.98 ----> avg loss exist params: 2.9461852898524434e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 266.38 ----> avg loss new params: 4.929504599938332e+24 ----> avg loss exist params: 2.2096389673893325e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 1.4s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 259408.3 ----> avg loss new params: 1.3418466928955868e+25 ----> avg loss exist params: 1.7677111739114658e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 5.59 ----> avg loss new params: 9.91 ----> avg loss exist params: 1.4730926449262217e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 1.3s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.218208797625005e+25 ----> avg loss new params: 4.330494474331893e+33 ----> avg loss exist params: 1.2626508385081898e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 4.79 ----> avg loss new params: 4.1039175555312315e+40 ----> avg loss exist params: 1.1048194836946663e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 1.9s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 1.0817917199830301e+42 ----> avg loss new params: 3.9053598974827594e+49 ----> avg loss exist params: 9.820617632841477e+70 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 3.19 ----> avg loss new params: 1.9816531622380618e+31 ----> avg loss exist params: 8.838555869557329e+70 ----> curr min loss: 3.190897002897203 ====> total elapsed time: 1.7s Checkpoint saved in 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 7.022331859686527e+57 ----> avg loss new params: 3.5277422231985074e+64 ----> avg loss exist params: 8.035051111210502e+70 ----> curr min loss: 3.190897002897203 ====> total elapsed time: 0.7s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 2.38 ----> avg loss new params: 5475.56 ----> avg loss exist params: 7.365463518609625e+70 ----> curr min loss: 2.376892792787833 ====> total elapsed time: 3.5s Checkpoint saved in 0.0s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 606.59 ----> avg loss new params: 3.6625250278652666e+65 ----> avg loss exist params: 6.798892219120445e+70 ----> curr min loss: 2.376892792787833 ====> total elapsed time: 0.7s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 4.47 ----> avg loss new params: 19.76 ----> avg loss exist params: 6.313257060611841e+70 ----> curr min loss: 2.376892792787833 ====> total elapsed time: 2.4s Checkpoint saved in 0.2s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: HaltonSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 1.11 ----> avg loss new params: 7.18 ----> avg loss exist params: 5.892373256571052e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 1.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 6.03 ----> avg loss new params: 27.11 ----> avg loss exist params: 5.524099928035361e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 2.2s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 1.14089698130206e+17 ----> avg loss new params: 2.1170674425931233e+25 ----> avg loss exist params: 5.199152873445046e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.6s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 1.22 ----> avg loss new params: 12.59 ----> avg loss exist params: 4.9103110471425434e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 1.7s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: HaltonSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 2.785000441888143e+33 ----> avg loss new params: 2.1868878143494303e+41 ----> avg loss exist params: 4.651873623608726e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.6s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 13.6 ----> avg loss new params: 1.1235228254061286e+32 ----> avg loss exist params: 4.419279942428289e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 1.3s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: HaltonSampler ----> sim exec elapsed time: 1.5s ----> min loss new params: 7.165734019763288e+48 ----> avg loss new params: 2.613140765222106e+57 ----> avg loss exist params: 4.2088380404079067e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 1.5s METHOD: RandomForestSampler ----> sim exec elapsed time: 1.9s ----> min loss new params: 6.33 ----> avg loss new params: 9.43 ----> avg loss exist params: 4.017527220389366e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 4.1s Checkpoint saved in 0.2s Sampling strategy 4 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 3.66 ----> avg loss new params: 23759.98 ----> avg loss exist params: 2.9461852898524434e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.91 ----> avg loss new params: 9.57 ----> avg loss exist params: 2.2096389673893325e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 259408.3 ----> avg loss new params: 1.3418466928955868e+25 ----> avg loss exist params: 1.7677111739114658e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 3.38 ----> avg loss new params: 3.63 ----> avg loss exist params: 1.4730926449262217e+71 ----> curr min loss: 3.3807587026196213 ====> total elapsed time: 0.8s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 3.218208797625005e+25 ----> avg loss new params: 4.330494474331893e+33 ----> avg loss exist params: 1.2626508385081898e+71 ----> curr min loss: 3.3807587026196213 ====> total elapsed time: 0.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 2.99 ----> avg loss new params: 4.57 ----> avg loss exist params: 1.1048194836946663e+71 ----> curr min loss: 2.986363446469386 ====> total elapsed time: 0.5s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 1.0817917199830301e+42 ----> avg loss new params: 3.9053598974827594e+49 ----> avg loss exist params: 9.820617632841477e+70 ----> curr min loss: 2.986363446469386 ====> total elapsed time: 0.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 2.91 ----> avg loss new params: 4.303297507113467e+39 ----> avg loss exist params: 8.838555869557329e+70 ----> curr min loss: 2.9081793471084874 ====> total elapsed time: 0.5s Checkpoint saved in 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 7.022331859686527e+57 ----> avg loss new params: 3.5277422231985074e+64 ----> avg loss exist params: 8.035051111210502e+70 ----> curr min loss: 2.9081793471084874 ====> total elapsed time: 0.4s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 1.61 ----> avg loss new params: 4.36 ----> avg loss exist params: 7.365463518609625e+70 ----> curr min loss: 1.6090030240712685 ====> total elapsed time: 0.4s Checkpoint saved in 0.1s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 606.59 ----> avg loss new params: 3.6625250278652666e+65 ----> avg loss exist params: 6.798892219120445e+70 ----> curr min loss: 1.6090030240712685 ====> total elapsed time: 0.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.62 ----> avg loss new params: 123998723929308.95 ----> avg loss exist params: 6.313257060611841e+70 ----> curr min loss: 1.6090030240712685 ====> total elapsed time: 0.4s Checkpoint saved in 0.1s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 1.11 ----> avg loss new params: 7.18 ----> avg loss exist params: 5.892373256571052e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.9s ----> min loss new params: 1.9 ----> avg loss new params: 3.978581939282771e+31 ----> avg loss exist params: 5.524099928035361e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 1.9s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 1.14089698130206e+17 ----> avg loss new params: 2.1170674425931233e+25 ----> avg loss exist params: 5.199152873445046e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 1.13 ----> avg loss new params: 1.48 ----> avg loss exist params: 4.9103110471425434e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.8s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 2.785000441888143e+33 ----> avg loss new params: 2.1868878143494303e+41 ----> avg loss exist params: 4.651873623608726e+70 ----> curr min loss: 1.1066869096045393 ====> total elapsed time: 0.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 0.94 ----> avg loss new params: 1.14 ----> avg loss exist params: 4.419279942428289e+70 ----> curr min loss: 0.942413698087732 ====> total elapsed time: 1.1s Checkpoint saved in 0.2s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 7.165734019763288e+48 ----> avg loss new params: 2.613140765222106e+57 ----> avg loss exist params: 4.2088380404079067e+70 ----> curr min loss: 0.942413698087732 ====> total elapsed time: 0.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.0s ----> min loss new params: 1.18 ----> avg loss new params: 1.470380789543466e+48 ----> avg loss exist params: 4.017527220389366e+70 ----> curr min loss: 0.942413698087732 ====> total elapsed time: 1.0s Checkpoint saved in 0.1s Sampling strategy 5 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 12.66 ----> avg loss new params: 30.73 ----> avg loss exist params: 2.9461852898524434e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 2.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.4s ----> min loss new params: 12.8 ----> avg loss new params: 10431.01 ----> avg loss exist params: 2.2096389673893325e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 1.4s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 6.81 ----> avg loss new params: 4.3550320248811904e+17 ----> avg loss exist params: 1.7677111739114658e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 4.8s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 8.52 ----> avg loss new params: 9.864850943917757e+62 ----> avg loss exist params: 1.4730926465703633e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 0.6s Checkpoint saved in 0.1s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: RandomForestSampler ----> sim exec elapsed time: 2.2s ----> min loss new params: 9.55 ----> avg loss new params: 3.887305425463723e+32 ----> avg loss exist params: 1.2626508399174543e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 3.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 2.5s ----> min loss new params: 6.55 ----> avg loss new params: 10.8 ----> avg loss exist params: 1.1048194849277725e+71 ----> curr min loss: 4.093299221041861 ====> total elapsed time: 2.6s Checkpoint saved in 0.2s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: RandomForestSampler ----> sim exec elapsed time: 2.4s ----> min loss new params: 3.03 ----> avg loss new params: 3.9 ----> avg loss exist params: 9.820617643802423e+70 ----> curr min loss: 3.0284708010510477 ====> total elapsed time: 4.3s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.9s ----> min loss new params: 4.5 ----> avg loss new params: 1.120218120072616e+40 ----> avg loss exist params: 8.838555879422181e+70 ----> curr min loss: 3.0284708010510477 ====> total elapsed time: 1.9s Checkpoint saved in 0.2s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.3s ----> min loss new params: 3.96 ----> avg loss new params: 7.5 ----> avg loss exist params: 8.035050799474711e+70 ----> curr min loss: 3.0284708010510477 ====> total elapsed time: 3.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 4.88 ----> avg loss new params: 7.83 ----> avg loss exist params: 7.365463232851817e+70 ----> curr min loss: 3.0284708010510477 ====> total elapsed time: 1.1s Checkpoint saved in 0.1s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.3s ----> min loss new params: 3.01 ----> avg loss new params: 6.78 ----> avg loss exist params: 6.798889138017061e+70 ----> curr min loss: 3.0120008197397503 ====> total elapsed time: 3.3s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 3.48 ----> avg loss new params: 4.2366396762870067e+18 ----> avg loss exist params: 6.313254199587272e+70 ----> curr min loss: 3.0120008197397503 ====> total elapsed time: 0.8s Checkpoint saved in 0.1s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.5s ----> min loss new params: 2.35 ----> avg loss new params: 5.86 ----> avg loss exist params: 5.892370586281454e+70 ----> curr min loss: 2.3490688746866115 ====> total elapsed time: 3.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 2.1 ----> avg loss new params: 4.5170950241116807e+24 ----> avg loss exist params: 5.524097424638862e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 1.2s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 143.9 ----> avg loss new params: 6.3136134841751816e+16 ----> avg loss exist params: 5.1991505173071656e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 1.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 2.21 ----> avg loss new params: 2.87 ----> avg loss exist params: 4.910308821901212e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 0.8s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: RandomForestSampler ----> sim exec elapsed time: 1.1s ----> min loss new params: 3.78 ----> avg loss new params: 7.144988739148858e+18 ----> avg loss exist params: 4.651871515485358e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 2.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 2.16 ----> avg loss new params: 2.52 ----> avg loss exist params: 4.4192779397110904e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 0.7s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: RandomForestSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 2.133175205090705e+26 ----> avg loss new params: 9.445350178094928e+55 ----> avg loss exist params: 4.2088361330581827e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 1.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 2.81 ----> avg loss new params: 1.8945860536525166e+39 ----> avg loss exist params: 4.0175253997373555e+70 ----> curr min loss: 2.095820051969746 ====> total elapsed time: 0.6s Checkpoint saved in 0.1s Sampling strategy 6 of 7 *** Number of free params: 8. Explorable param space size: 13988943766831. *** Selecting 4 processes for the parallel evaluation of the model BATCH NUMBER: 2 PARAMS SAMPLED: 6 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.66 ----> avg loss new params: 7.73 ----> avg loss exist params: 3.3144584510839986e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 156.11 ----> avg loss new params: 1.421244832993949e+26 ----> avg loss exist params: 2.6515667608671987e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 1.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 4.64 ----> avg loss new params: 9.528436025701058e+22 ----> avg loss exist params: 2.2096389673893325e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.5s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 12 METHOD: HaltonSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 94300.57 ----> avg loss new params: 149916.69 ----> avg loss exist params: 1.893976257762285e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 0.5s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 59.02 ----> avg loss new params: 589.01 ----> avg loss exist params: 1.6572292255419993e+71 ----> curr min loss: 3.6618024049543774 ====> total elapsed time: 2.2s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 3.49 ----> avg loss new params: 3.74 ----> avg loss exist params: 1.4730926449262217e+71 ----> curr min loss: 3.490052814946999 ====> total elapsed time: 0.6s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 18 METHOD: HaltonSampler ----> sim exec elapsed time: 0.7s ----> min loss new params: 2.2252400654072278e+17 ----> avg loss new params: 2.0762227039805127e+25 ----> avg loss exist params: 1.3257833804335994e+71 ----> curr min loss: 3.490052814946999 ====> total elapsed time: 0.7s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 2.25 ----> avg loss new params: 387216.91 ----> avg loss exist params: 1.2052576185759994e+71 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 1.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 2.85 ----> avg loss new params: 5.110258403121564e+31 ----> avg loss exist params: 1.1048194836946663e+71 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 0.4s Checkpoint saved in 0.1s BATCH NUMBER: 5 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 2.0543465401664097e+25 ----> avg loss new params: 3.6848605655597034e+33 ----> avg loss exist params: 1.0198333695643073e+71 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 0.8s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 3.71 ----> avg loss new params: 4.03 ----> avg loss exist params: 9.469881288811425e+70 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 1.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 2.4 ----> avg loss new params: 2.58 ----> avg loss exist params: 8.838555869557329e+70 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 0.5s Checkpoint saved in 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 30 METHOD: HaltonSampler ----> sim exec elapsed time: 0.8s ----> min loss new params: 9.534641615636949e+33 ----> avg loss new params: 5.457569779907695e+41 ----> avg loss exist params: 8.286146127709996e+70 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 0.8s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 3.61 ----> avg loss new params: 8.29 ----> avg loss exist params: 7.798725767256467e+70 ----> curr min loss: 2.2472793592156948 ====> total elapsed time: 1.8s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 2.21 ----> avg loss new params: 2.49 ----> avg loss exist params: 7.365463224631108e+70 ----> curr min loss: 2.2063781203583126 ====> total elapsed time: 0.4s Checkpoint saved in 0.1s BATCH NUMBER: 7 PARAMS SAMPLED: 36 METHOD: HaltonSampler ----> sim exec elapsed time: 0.9s ----> min loss new params: 1.2930856737877442e+42 ----> avg loss new params: 5.852402936836168e+49 ----> avg loss exist params: 6.977807265439997e+70 ----> curr min loss: 2.2063781203583126 ====> total elapsed time: 0.9s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 6.67 ----> avg loss new params: 137.43 ----> avg loss exist params: 6.628916902167997e+70 ----> curr min loss: 2.2063781203583126 ====> total elapsed time: 2.3s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 1.45 ----> avg loss new params: 1.0122406761007165e+48 ----> avg loss exist params: 6.313254192540949e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 0.4s Checkpoint saved in 0.0s BATCH NUMBER: 8 PARAMS SAMPLED: 42 METHOD: HaltonSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 4.693912088645729e+57 ----> avg loss new params: 7.321340783291673e+57 ----> avg loss exist params: 6.02628809288003e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 0.3s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 8.39 ----> avg loss new params: 34.61 ----> avg loss exist params: 5.764275567102637e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 1.4s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 3.19 ----> avg loss new params: 1.698842407427921e+47 ----> avg loss exist params: 5.524097418473361e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 0.3s Checkpoint saved in 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 3.288144112758467e+65 ----> avg loss new params: 7.102222980735781e+65 ----> avg loss exist params: 5.303136362623619e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 0.3s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 2.82 ----> avg loss new params: 4.49 ----> avg loss exist params: 5.099169579445788e+70 ----> curr min loss: 1.4517270271107627 ====> total elapsed time: 1.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 1.33 ----> avg loss new params: 1.4 ----> avg loss exist params: 4.910311446873721e+70 ----> curr min loss: 1.3320791175674513 ====> total elapsed time: 0.3s Checkpoint saved in 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 54 METHOD: HaltonSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 601.45 ----> avg loss new params: 1593.66 ----> avg loss exist params: 4.734943180913945e+70 ----> curr min loss: 1.3320791175674513 ====> total elapsed time: 0.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 6.76 ----> avg loss new params: 3.645056588348578e+24 ----> avg loss exist params: 4.5716692781238096e+70 ----> curr min loss: 1.3320791175674513 ====> total elapsed time: 1.2s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 9.80672370968492e+16 ----> avg loss new params: 1.0486335887746384e+32 ----> avg loss exist params: 4.419280302186348e+70 ----> curr min loss: 1.3320791175674513 ====> total elapsed time: 0.3s Checkpoint saved in 0.1s BATCH NUMBER: 11 PARAMS SAMPLED: 60 METHOD: HaltonSampler ----> sim exec elapsed time: 0.6s ----> min loss new params: 0.9 ----> avg loss new params: 7.53 ----> avg loss exist params: 4.2767228730835636e+70 ----> curr min loss: 0.9031595091997369 ====> total elapsed time: 0.6s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.5s ----> min loss new params: 10611.75 ----> avg loss new params: 2.84600288413688e+31 ----> avg loss exist params: 4.143075283299702e+70 ----> curr min loss: 0.9031595091997369 ====> total elapsed time: 1.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.4s ----> min loss new params: 4.82 ----> avg loss new params: 8.096356842026602e+24 ----> avg loss exist params: 4.0175275474421353e+70 ----> curr min loss: 0.9031595091997369 ====> total elapsed time: 0.4s Checkpoint saved in 0.1s # load the results from the corresponding folders, and plot them! plt . figure ( figsize = ( 7 , 5 )) lss = [ ':' ] * 3 + [ '--' ] * 3 + [ '-' ] for i , sampler in enumerate ( all_calibration_strategies ): # name of the corresponding folder sampler_name = '' for s in sampler : sampler_name += type ( s ) . __name__ # get array of minimum losses achieved losses = pd . read_csv ( sampler_name + '/calibration_results.csv' )[ 'losses_samp' ] . cummin () sampler_name = sampler_name . replace ( \"Sampler\" , \" \" ) # plot the loss curve plt . plot ( losses , label = sampler_name , ls = lss [ i ], lw = 2.5 ) plt . legend ( loc = 'upper center' , bbox_to_anchor = ( 0.4 , - 0.14 ), prop = { 'size' : 14 }) plt . xlabel ( 'model calls' , fontsize = 14 ) plt . ylabel ( 'loss' , fontsize = 14 ); plt . xticks ( fontsize = 12 ); plt . yticks ( fontsize = 12 );","title":"Benchmarking different samplers against a standard ABM"},{"location":"boltzmann_wealth_model/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); A simple model for wealth inequality Here we will explore and calibrate a simple model of agents exchanging wealth. The agents start with a Bernoulli distributed wealth. Then each agent with one unit of money or more gives one unit of wealth to another random agents encountered, unless the ratio of the agents wealths is above a certain threshold. This model is adapted from this source . Note that this notebook requires the installation of the mesa library: you can install it through pip install mesa . import numpy as np import matplotlib.pyplot as plt from models.economics.boltzmann_wealth import BoltzmannWealthModel , compute_gini model = BoltzmannWealthModel ( num_agents = 50 , width = 5 , height = 5 , generosity_ratio = 2.0 , mean_init_wealth = 10 ) model . run_model ( 1000 ) agent_wealths = [ agent . wealth for agent in model . schedule . agents ] plt . hist ( agent_wealths ) plt . xlabel ( \"wealth\" ) plt . ylabel ( \"number of agents\" ) Text(0, 0.5, 'number of agents') compute_gini ( model ) 0.18516634050880632 plt . figure ( figsize = ( 5 , 5 )) s_w = sorted ( agent_wealths ) X_lorenz = np . cumsum ( s_w ) / np . sum ( s_w ) X_lorenz = np . insert ( X_lorenz , 0 , 0 ) X_lorenz [ 0 ], X_lorenz [ - 1 ] plt . plot ( np . arange ( X_lorenz . size ) / ( X_lorenz . size - 1 ), X_lorenz , ) plt . plot ( np . arange ( X_lorenz . size ) / ( X_lorenz . size - 1 ), np . linspace ( 0 , 1 , len ( X_lorenz )), \"k--\" , ) plt . xlabel ( \"fraction of (sorted) population\" ) plt . ylabel ( \"fraction of wealth\" ) Text(0, 0.5, 'fraction of wealth') plt . plot ( model . datacollector . get_model_vars_dataframe ()) [<matplotlib.lines.Line2D at 0x7fbd2c5c33d0>] Calibrate the model on the Italian Gini Index In 2017 the Italian Gini index was 0.36 ( World Bank estimate ) # real GDP of the italian economy italian_data = 0.36 * np . ones (( 100 , 1 )) # wrapper of the ABM with a specific signature def boltzmann_model ( theta , N , seed = None ): model = BoltzmannWealthModel ( num_agents = 100 , width = 10 , height = 10 , generosity_ratio = theta [ 0 ], mean_init_wealth = 5 , ) # burn-in phase of 200 steps model . run_model ( 200 + N ) data = model . datacollector . get_model_vars_dataframe () . to_numpy () # discard initialization and burn-in phase of 200 steps return data [ 201 :] boltzmann_model ([ 1 ], N = 5 , seed = None ) array([[0.10088409], [0.1002947 ], [0.10170923], [0.10332024], [0.1046169 ]]) # Euclidean distance between series from black_it.loss_functions.minkowski import MinkowskiLoss loss = MinkowskiLoss ( p = 2 ) # choose samplers from black_it.samplers.halton import HaltonSampler from black_it.samplers.random_forest import RandomForestSampler halton = HaltonSampler ( batch_size = 4 ) forest = RandomForestSampler ( batch_size = 4 ) # reasonable range of parameter values parameters_bounds = np . array ([[ 0.01 , 100.0 ]]) . T parameters_precision = [ 0.01 , ] # initialize calibrator from black_it.calibrator import Calibrator cal = Calibrator ( model = boltzmann_model , samplers = [ halton , forest ], loss_function = loss , parameters_bounds = parameters_bounds , parameters_precision = parameters_precision , real_data = italian_data , ensemble_size = 3 , ) *** Number of free params: 1. Explorable param space size: 10000. *** Selecting 4 processes for the parallel evaluation of the model # calibrate for 5 epochs params , losses = cal . calibrate ( 5 ) BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: HaltonSampler ----> sim exec elapsed time: 4.0s ----> min loss new params: 1.27 ----> avg loss new params: 1.55 ----> avg loss exist params: 1.55 ----> curr min loss: 1.2709260887871952 ====> total elapsed time: 4.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 2.8s ----> min loss new params: 1.01 ----> avg loss new params: 1.37 ----> avg loss exist params: 1.46 ----> curr min loss: 1.0059668811538809 ====> total elapsed time: 4.1s BATCH NUMBER: 2 PARAMS SAMPLED: 8 METHOD: HaltonSampler ----> sim exec elapsed time: 3.3s ----> min loss new params: 0.7 ----> avg loss new params: 1.42 ----> avg loss exist params: 1.45 ----> curr min loss: 0.6952058780196919 ====> total elapsed time: 3.3s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 2.7s ----> min loss new params: 0.09 ----> avg loss new params: 0.44 ----> avg loss exist params: 1.2 ----> curr min loss: 0.09205704142039979 ====> total elapsed time: 4.1s BATCH NUMBER: 3 PARAMS SAMPLED: 16 METHOD: HaltonSampler ----> sim exec elapsed time: 2.5s ----> min loss new params: 1.27 ----> avg loss new params: 1.65 ----> avg loss exist params: 1.29 ----> curr min loss: 0.09205704142039979 ====> total elapsed time: 2.5s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 2.7s ----> min loss new params: 0.08 ----> avg loss new params: 0.16 ----> avg loss exist params: 1.1 ----> curr min loss: 0.07538664969409653 ====> total elapsed time: 3.9s BATCH NUMBER: 4 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 2.7s ----> min loss new params: 0.37 ----> avg loss new params: 1.22 ----> avg loss exist params: 1.12 ----> curr min loss: 0.07538664969409653 ====> total elapsed time: 2.7s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 2.6s ----> min loss new params: 0.08 ----> avg loss new params: 0.1 ----> avg loss exist params: 0.99 ----> curr min loss: 0.07538664969409653 ====> total elapsed time: 3.7s BATCH NUMBER: 5 PARAMS SAMPLED: 32 METHOD: HaltonSampler ----> sim exec elapsed time: 2.9s ----> min loss new params: 1.53 ----> avg loss new params: 1.55 ----> avg loss exist params: 1.05 ----> curr min loss: 0.07538664969409653 ====> total elapsed time: 2.9s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 2.9s ----> min loss new params: 0.11 ----> avg loss new params: 0.13 ----> avg loss exist params: 0.96 ----> curr min loss: 0.07538664969409653 ====> total elapsed time: 4.1s # optimal parameter found params [ 0 ] array([3.7]) min_idx = np . argmin ( cal . losses_samp ) print ( min_idx ) max_idx = np . argmax ( cal . losses_samp ) print ( max_idx ) 23 18 plt . figure () for i , simulated_series in enumerate ( cal . series_samp [:, 0 , :, 0 ]): if i in ( max_idx ,): continue plt . plot ( simulated_series , color = \"orange\" , alpha = 0.2 ) plt . plot ( cal . series_samp [ min_idx , 0 , :, 0 ], color = \"green\" , label = \"optimal simulated series\" , alpha = 0.9 , linewidth = 3 , ) plt . plot ( italian_data , \"k--\" , label = \"reference value\" , alpha = 0.9 ) plt . xlabel ( \"time step\" ) plt . ylabel ( \"Gini index\" ) plt . legend () plt . ylim ( 0 , 0.6 ) (0.0, 0.6)","title":"Boltzmann wealth model"},{"location":"boltzmann_wealth_model/#a-simple-model-for-wealth-inequality","text":"Here we will explore and calibrate a simple model of agents exchanging wealth. The agents start with a Bernoulli distributed wealth. Then each agent with one unit of money or more gives one unit of wealth to another random agents encountered, unless the ratio of the agents wealths is above a certain threshold. This model is adapted from this source . Note that this notebook requires the installation of the mesa library: you can install it through pip install mesa . import numpy as np import matplotlib.pyplot as plt from models.economics.boltzmann_wealth import BoltzmannWealthModel , compute_gini model = BoltzmannWealthModel ( num_agents = 50 , width = 5 , height = 5 , generosity_ratio = 2.0 , mean_init_wealth = 10 ) model . run_model ( 1000 ) agent_wealths = [ agent . wealth for agent in model . schedule . agents ] plt . hist ( agent_wealths ) plt . xlabel ( \"wealth\" ) plt . ylabel ( \"number of agents\" ) Text(0, 0.5, 'number of agents') compute_gini ( model ) 0.18516634050880632 plt . figure ( figsize = ( 5 , 5 )) s_w = sorted ( agent_wealths ) X_lorenz = np . cumsum ( s_w ) / np . sum ( s_w ) X_lorenz = np . insert ( X_lorenz , 0 , 0 ) X_lorenz [ 0 ], X_lorenz [ - 1 ] plt . plot ( np . arange ( X_lorenz . size ) / ( X_lorenz . size - 1 ), X_lorenz , ) plt . plot ( np . arange ( X_lorenz . size ) / ( X_lorenz . size - 1 ), np . linspace ( 0 , 1 , len ( X_lorenz )), \"k--\" , ) plt . xlabel ( \"fraction of (sorted) population\" ) plt . ylabel ( \"fraction of wealth\" ) Text(0, 0.5, 'fraction of wealth') plt . plot ( model . datacollector . get_model_vars_dataframe ()) [<matplotlib.lines.Line2D at 0x7fbd2c5c33d0>]","title":"A simple model for wealth inequality"},{"location":"boltzmann_wealth_model/#calibrate-the-model-on-the-italian-gini-index","text":"In 2017 the Italian Gini index was 0.36 ( World Bank estimate ) # real GDP of the italian economy italian_data = 0.36 * np . ones (( 100 , 1 )) # wrapper of the ABM with a specific signature def boltzmann_model ( theta , N , seed = None ): model = BoltzmannWealthModel ( num_agents = 100 , width = 10 , height = 10 , generosity_ratio = theta [ 0 ], mean_init_wealth = 5 , ) # burn-in phase of 200 steps model . run_model ( 200 + N ) data = model . datacollector . get_model_vars_dataframe () . to_numpy () # discard initialization and burn-in phase of 200 steps return data [ 201 :] boltzmann_model ([ 1 ], N = 5 , seed = None ) array([[0.10088409], [0.1002947 ], [0.10170923], [0.10332024], [0.1046169 ]]) # Euclidean distance between series from black_it.loss_functions.minkowski import MinkowskiLoss loss = MinkowskiLoss ( p = 2 ) # choose samplers from black_it.samplers.halton import HaltonSampler from black_it.samplers.random_forest import RandomForestSampler halton = HaltonSampler ( batch_size = 4 ) forest = RandomForestSampler ( batch_size = 4 ) # reasonable range of parameter values parameters_bounds = np . array ([[ 0.01 , 100.0 ]]) . T parameters_precision = [ 0.01 , ] # initialize calibrator from black_it.calibrator import Calibrator cal = Calibrator ( model = boltzmann_model , samplers = [ halton , forest ], loss_function = loss , parameters_bounds = parameters_bounds , parameters_precision = parameters_precision , real_data = italian_data , ensemble_size = 3 , ) *** Number of free params: 1. Explorable param space size: 10000. *** Selecting 4 processes for the parallel evaluation of the model # calibrate for 5 epochs params , losses = cal . calibrate ( 5 ) BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: HaltonSampler ----> sim exec elapsed time: 4.0s ----> min loss new params: 1.27 ----> avg loss new params: 1.55 ----> avg loss exist params: 1.55 ----> curr min loss: 1.2709260887871952 ====> total elapsed time: 4.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 2.8s ----> min loss new params: 1.01 ----> avg loss new params: 1.37 ----> avg loss exist params: 1.46 ----> curr min loss: 1.0059668811538809 ====> total elapsed time: 4.1s BATCH NUMBER: 2 PARAMS SAMPLED: 8 METHOD: HaltonSampler ----> sim exec elapsed time: 3.3s ----> min loss new params: 0.7 ----> avg loss new params: 1.42 ----> avg loss exist params: 1.45 ----> curr min loss: 0.6952058780196919 ====> total elapsed time: 3.3s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 2.7s ----> min loss new params: 0.09 ----> avg loss new params: 0.44 ----> avg loss exist params: 1.2 ----> curr min loss: 0.09205704142039979 ====> total elapsed time: 4.1s BATCH NUMBER: 3 PARAMS SAMPLED: 16 METHOD: HaltonSampler ----> sim exec elapsed time: 2.5s ----> min loss new params: 1.27 ----> avg loss new params: 1.65 ----> avg loss exist params: 1.29 ----> curr min loss: 0.09205704142039979 ====> total elapsed time: 2.5s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 2.7s ----> min loss new params: 0.08 ----> avg loss new params: 0.16 ----> avg loss exist params: 1.1 ----> curr min loss: 0.07538664969409653 ====> total elapsed time: 3.9s BATCH NUMBER: 4 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 2.7s ----> min loss new params: 0.37 ----> avg loss new params: 1.22 ----> avg loss exist params: 1.12 ----> curr min loss: 0.07538664969409653 ====> total elapsed time: 2.7s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 2.6s ----> min loss new params: 0.08 ----> avg loss new params: 0.1 ----> avg loss exist params: 0.99 ----> curr min loss: 0.07538664969409653 ====> total elapsed time: 3.7s BATCH NUMBER: 5 PARAMS SAMPLED: 32 METHOD: HaltonSampler ----> sim exec elapsed time: 2.9s ----> min loss new params: 1.53 ----> avg loss new params: 1.55 ----> avg loss exist params: 1.05 ----> curr min loss: 0.07538664969409653 ====> total elapsed time: 2.9s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 2.9s ----> min loss new params: 0.11 ----> avg loss new params: 0.13 ----> avg loss exist params: 0.96 ----> curr min loss: 0.07538664969409653 ====> total elapsed time: 4.1s # optimal parameter found params [ 0 ] array([3.7]) min_idx = np . argmin ( cal . losses_samp ) print ( min_idx ) max_idx = np . argmax ( cal . losses_samp ) print ( max_idx ) 23 18 plt . figure () for i , simulated_series in enumerate ( cal . series_samp [:, 0 , :, 0 ]): if i in ( max_idx ,): continue plt . plot ( simulated_series , color = \"orange\" , alpha = 0.2 ) plt . plot ( cal . series_samp [ min_idx , 0 , :, 0 ], color = \"green\" , label = \"optimal simulated series\" , alpha = 0.9 , linewidth = 3 , ) plt . plot ( italian_data , \"k--\" , label = \"reference value\" , alpha = 0.9 ) plt . xlabel ( \"time step\" ) plt . ylabel ( \"Gini index\" ) plt . legend () plt . ylim ( 0 , 0.6 ) (0.0, 0.6)","title":"Calibrate the model on the Italian Gini Index"},{"location":"calibrator/","text":"black_it.calibrator.Calibrator The class used to perform a calibration. Source code in black_it/calibrator.py class Calibrator : # pylint: disable=too-many-instance-attributes \"\"\"The class used to perform a calibration.\"\"\" STATE_VERSION = 0 def __init__ ( # pylint: disable=too-many-arguments self , samplers : List [ BaseSampler ], loss_function : BaseLoss , real_data : NDArray [ np . float64 ], model : Callable , parameters_bounds : Union [ NDArray [ np . float64 ], List [ List [ float ]]], parameters_precision : Union [ NDArray [ np . float64 ], List [ float ]], ensemble_size : int , convergence_precision : Optional [ int ] = None , verbose : bool = True , saving_folder : Optional [ str ] = None , random_state : Optional [ int ] = None , n_jobs : Optional [ int ] = None , ): \"\"\" Initialize the Calibrator object. It must be initialized with details on the parameters to explore, on the model to calibrate, on the samplers and on the loss function to use. Args: samplers: list of methods to be used in the calibration procedure loss_function: a loss function which evaluates the similarity between simulated and real datasets real_data: an array containing the real time series model: a model with free parameters to be calibrated parameters_bounds: the bounds of the parameter space parameters_precision: the precisions to be used for the discretization of the parameters ensemble_size: number of repetitions to be run for each set of parameters to decrease statistical fluctuations. For deterministic models this should be set to 1. convergence_precision: number of significant digits to consider in the convergence check. The check is not performed if this is set to 'None'. verbose: whether to print calibration updates saving_folder: the name of the folder where data should be saved and/or retrieved random_state: random state of the calibrator, used for model simulations and to initialise the samplers n_jobs: the maximum number of concurrently running jobs. For more details, see the [joblib.Parallel documentation](https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html). \"\"\" self . samplers = samplers self . loss_function = loss_function self . model = model self . random_state = random_state self . real_data = real_data self . ensemble_size = ensemble_size self . N = self . real_data . shape [ 0 ] self . D = self . real_data . shape [ 1 ] self . verbose = verbose self . convergence_precision = ( self . _validate_convergence_precision ( convergence_precision ) if convergence_precision is not None else None ) self . saving_folder = saving_folder # Initialize search grid self . param_grid = SearchSpace ( parameters_bounds , parameters_precision , verbose ) # initialize arrays self . params_samp = np . zeros (( 0 , self . param_grid . dims )) self . losses_samp = np . zeros ( 0 ) self . batch_num_samp = np . zeros ( 0 , dtype = int ) self . method_samp = np . zeros ( 0 , dtype = int ) self . series_samp = np . zeros (( 0 , self . ensemble_size , self . N , self . D )) # initialize variables before calibration self . n_sampled_params = 0 self . current_batch_index = 0 # set number of processes for parallel evaluation of model self . n_jobs = n_jobs if n_jobs is not None else multiprocessing . cpu_count () print ( f \"Selecting { self . n_jobs } processes for the parallel evaluation of the model\" ) self . samplers_id_table = self . _construct_samplers_id_table ( samplers ) @property def random_state ( self ) -> Optional [ int ]: \"\"\"Get the random state.\"\"\" return self . _random_state @random_state . setter def random_state ( self , random_state : Optional [ int ]) -> None : \"\"\"Set the random state.\"\"\" self . _random_state = random_state self . _random_generator = default_rng ( self . random_state ) @property def random_generator ( self ) -> np . random . Generator : \"\"\"Get the random generator.\"\"\" return self . _random_generator def _get_random_seed ( self ) -> int : \"\"\"Get new random seed from the current random generator.\"\"\" return get_random_seed ( self . _random_generator ) def _set_samplers_seeds ( self ) -> None : \"\"\"Set the calibration seed.\"\"\" for sampler in self . samplers : sampler . random_state = self . _get_random_seed () @staticmethod def _construct_samplers_id_table ( samplers : List [ BaseSampler ]) -> Dict [ str , int ]: \"\"\" Construct the samplers-by-id table. Given the list (built-in or user-defined) of samplers a calibration session is going to use, return a map from the sampler human-readable name to a numeric id (starting from 0). Different calibration sessions may result in different conversion tables. Args: samplers: the list of samplers of the calibrator Returns: A dict that maps from the given sampler names to unique ids. \"\"\" samplers_id_table = {} sampler_id = 0 for sampler in samplers : sampler_name = type ( sampler ) . __name__ if sampler_name in samplers_id_table : continue samplers_id_table [ sampler_name ] = sampler_id sampler_id = sampler_id + 1 return samplers_id_table def set_samplers ( self , samplers : List [ BaseSampler ]) -> None : \"\"\"Set the samplers list of the calibrator. This method overwrites the samplers of a calibrator object with a custom list of samplers. Args: samplers: a list of samplers \"\"\" # overwrite the list of samplers self . samplers = samplers # update the samplers_id_table with the new samplers, only if necessary sampler_id = max ( self . samplers_id_table . values ()) + 1 for sampler in samplers : sampler_name = type ( sampler ) . __name__ if sampler_name in self . samplers_id_table : continue self . samplers_id_table [ sampler_name ] = sampler_id sampler_id = sampler_id + 1 @classmethod def restore_from_checkpoint ( # pylint: disable=too-many-locals cls , checkpoint_path : str , model : Callable ) -> \"Calibrator\" : \"\"\" Return an instantiated class from a database file and a model simulator. Args: checkpoint_path: the name of the database file to read from model: the model to calibrate. It must be equal to the one already calibrated Returns: An initialised Calibrator object. \"\"\" ( parameters_bounds , parameters_precision , real_data , ensemble_size , _N , _D , convergence_precision , verbose , saving_file , random_state , random_generator_state , model_name , samplers , loss_function , current_batch_index , n_sampled_params , n_jobs , params_samp , losses_samp , series_samp , batch_num_samp , method_samp , ) = load_calibrator_state ( checkpoint_path , cls . STATE_VERSION ) assert_ ( model_name == model . __name__ , ( \"Error: the model provided appears to be different from the one present \" \"in the database\" ), ) calibrator = cls ( samplers , loss_function , real_data , model , parameters_bounds , parameters_precision , ensemble_size , convergence_precision , verbose , saving_file , random_state , n_jobs , ) calibrator . current_batch_index = current_batch_index calibrator . n_sampled_params = n_sampled_params calibrator . params_samp = params_samp calibrator . losses_samp = losses_samp calibrator . series_samp = series_samp calibrator . batch_num_samp = batch_num_samp calibrator . method_samp = method_samp # reset the random number generator state calibrator . random_generator . bit_generator . state = random_generator_state return calibrator def simulate_model ( self , params : NDArray ) -> NDArray : \"\"\" Simulate the model. This method calls the model simulator in parallel on a given set of parameter values, a number of repeated evaluations are performed for each parameter to average out random fluctuations. Args: params: the array of parameters for which the model should be evaluated # noqa Returns: simulated_data: an array of dimensions (batch_size, ensemble_size, N, D) containing all simulated time series \"\"\" rep_params = np . repeat ( params , self . ensemble_size , axis = 0 ) simulated_data_list = Parallel ( n_jobs = self . n_jobs )( delayed ( self . model )( param , self . N , self . _get_random_seed ()) for i , param in enumerate ( rep_params ) ) simulated_data = np . array ( simulated_data_list ) simulated_data = np . reshape ( simulated_data , ( params . shape [ 0 ], self . ensemble_size , self . N , self . D ) ) return simulated_data def calibrate ( self , n_batches : int ) -> Tuple [ NDArray , NDArray ]: \"\"\" Run calibration for n batches. Args: n_batches (int): number of 'batches' to be executed. Each batch runs over all methods Returns: The sampled parameters and the corresponding sampled losses. Both arrays are sorted by increasing loss values \"\"\" if self . current_batch_index == 0 : # we only set the samplers' random state at the start of a calibration self . _set_samplers_seeds () for _ in range ( n_batches ): print () print ( f \"BATCH NUMBER: { self . current_batch_index + 1 } \" ) print ( f \"PARAMS SAMPLED: { self . n_sampled_params } \" ) for method in self . samplers : t_start = time . time () print () print ( f \"METHOD: { type ( method ) . __name__ } \" ) # get new params from a specific sampler new_params = method . sample ( self . param_grid , self . params_samp , self . losses_samp , ) t_eval = time . time () # simulate an ensemble of models for different parameters new_simulated_data = self . simulate_model ( new_params ) new_losses = [] for sim_data_ensemble in new_simulated_data : new_loss = self . loss_function . compute_loss ( sim_data_ensemble , self . real_data ) new_losses . append ( new_loss ) # update arrays self . params_samp = np . vstack (( self . params_samp , new_params )) self . losses_samp = np . hstack (( self . losses_samp , new_losses )) self . series_samp = np . vstack (( self . series_samp , new_simulated_data )) self . batch_num_samp = np . hstack ( ( self . batch_num_samp , [ self . current_batch_index ] * method . batch_size , ) ) self . method_samp = np . hstack ( ( self . method_samp , [ self . samplers_id_table [ type ( method ) . __name__ ]] * method . batch_size , ) ) # logging t_end = time . time () if self . verbose : min_dist_new_points = np . round ( np . min ( new_losses ), 2 ) avg_dist_new_points = np . round ( np . average ( new_losses ), 2 ) avg_dist_existing_points = np . round ( np . average ( self . losses_samp ), 2 ) elapsed_tot = np . round ( t_end - t_start , 1 ) elapsed_eval = np . round ( t_end - t_eval , 1 ) print ( textwrap . dedent ( f \"\"\" \\ ----> sim exec elapsed time: { elapsed_eval } s ----> min loss new params: { min_dist_new_points } ----> avg loss new params: { avg_dist_new_points } ----> avg loss exist params: { avg_dist_existing_points } ----> curr min loss: { np . min ( self . losses_samp ) } ====> total elapsed time: { elapsed_tot } s \"\"\" ), end = \"\" , ) # update count of number of params sampled self . n_sampled_params = self . n_sampled_params + len ( new_params ) self . current_batch_index += 1 # check convergence for early termination if self . convergence_precision is not None : converged = self . check_convergence ( self . losses_samp , self . n_sampled_params , self . convergence_precision ) if converged and self . verbose : print ( \" \\n CONVERGENCE CHECK:\" ) print ( \"Achieved convergence loss, stopping search.\" ) break if self . saving_folder is not None : self . create_checkpoint ( self . saving_folder ) idx = np . argsort ( self . losses_samp ) return self . params_samp [ idx ], self . losses_samp [ idx ] @staticmethod def check_convergence ( losses_samp : NDArray , n_sampled_params : int , convergence_precision : int ) -> bool : \"\"\" Check convergence of the calibration. Args: losses_samp: the sampled losses n_sampled_params: the number of sampled params convergence_precision: the required convergence precision. Returns: True if the calibration converged, False otherwise. \"\"\" converged = ( np . round ( np . min ( losses_samp [: n_sampled_params ]), convergence_precision ) == 0.0 ) return converged def create_checkpoint ( self , file_name : Union [ str , os . PathLike ]) -> None : \"\"\" Save the current state of the object. Args: file_name: the name of the folder where the data will be saved \"\"\" checkpoint_path : str = os . path . join ( os . path . realpath ( file_name )) t_start = time . time () model_name = self . model . __name__ save_calibrator_state ( checkpoint_path , self . param_grid . parameters_bounds , self . param_grid . parameters_precision , self . real_data , self . ensemble_size , self . N , self . D , self . convergence_precision , self . verbose , self . saving_folder , self . random_state , self . random_generator . bit_generator . state , model_name , self . samplers , self . loss_function , self . current_batch_index , self . n_sampled_params , self . n_jobs , self . params_samp , self . losses_samp , self . series_samp , self . batch_num_samp , self . method_samp , ) t_end = time . time () elapsed = np . round ( t_end - t_start , 1 ) print ( f \"Checkpoint saved in { elapsed } s\" ) @staticmethod def _validate_convergence_precision ( convergence_precision : int ) -> int : \"\"\"Validate convergence precision input.\"\"\" assert_ ( convergence_precision >= 0 , f \"convergence precision must be an integer greater than 0, got { convergence_precision } \" , exc_cls = ValueError , ) return convergence_precision random_generator : Generator property readonly Get the random generator. random_state : Optional [ int ] property writable Get the random state. __init__ ( self , samplers , loss_function , real_data , model , parameters_bounds , parameters_precision , ensemble_size , convergence_precision = None , verbose = True , saving_folder = None , random_state = None , n_jobs = None ) special Initialize the Calibrator object. It must be initialized with details on the parameters to explore, on the model to calibrate, on the samplers and on the loss function to use. Parameters: Name Type Description Default samplers List[black_it.samplers.base.BaseSampler] list of methods to be used in the calibration procedure required loss_function BaseLoss a loss function which evaluates the similarity between simulated and real datasets required real_data ndarray an array containing the real time series required model Callable a model with free parameters to be calibrated required parameters_bounds Union[numpy.ndarray, List[List[float]]] the bounds of the parameter space required parameters_precision Union[numpy.ndarray, List[float]] the precisions to be used for the discretization of the parameters required ensemble_size int number of repetitions to be run for each set of parameters to decrease statistical fluctuations. For deterministic models this should be set to 1. required convergence_precision Optional[int] number of significant digits to consider in the convergence check. The check is not performed if this is set to 'None'. None verbose bool whether to print calibration updates True saving_folder Optional[str] the name of the folder where data should be saved and/or retrieved None random_state Optional[int] random state of the calibrator, used for model simulations and to initialise the samplers None n_jobs Optional[int] the maximum number of concurrently running jobs. For more details, see the joblib.Parallel documentation . None Source code in black_it/calibrator.py def __init__ ( # pylint: disable=too-many-arguments self , samplers : List [ BaseSampler ], loss_function : BaseLoss , real_data : NDArray [ np . float64 ], model : Callable , parameters_bounds : Union [ NDArray [ np . float64 ], List [ List [ float ]]], parameters_precision : Union [ NDArray [ np . float64 ], List [ float ]], ensemble_size : int , convergence_precision : Optional [ int ] = None , verbose : bool = True , saving_folder : Optional [ str ] = None , random_state : Optional [ int ] = None , n_jobs : Optional [ int ] = None , ): \"\"\" Initialize the Calibrator object. It must be initialized with details on the parameters to explore, on the model to calibrate, on the samplers and on the loss function to use. Args: samplers: list of methods to be used in the calibration procedure loss_function: a loss function which evaluates the similarity between simulated and real datasets real_data: an array containing the real time series model: a model with free parameters to be calibrated parameters_bounds: the bounds of the parameter space parameters_precision: the precisions to be used for the discretization of the parameters ensemble_size: number of repetitions to be run for each set of parameters to decrease statistical fluctuations. For deterministic models this should be set to 1. convergence_precision: number of significant digits to consider in the convergence check. The check is not performed if this is set to 'None'. verbose: whether to print calibration updates saving_folder: the name of the folder where data should be saved and/or retrieved random_state: random state of the calibrator, used for model simulations and to initialise the samplers n_jobs: the maximum number of concurrently running jobs. For more details, see the [joblib.Parallel documentation](https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html). \"\"\" self . samplers = samplers self . loss_function = loss_function self . model = model self . random_state = random_state self . real_data = real_data self . ensemble_size = ensemble_size self . N = self . real_data . shape [ 0 ] self . D = self . real_data . shape [ 1 ] self . verbose = verbose self . convergence_precision = ( self . _validate_convergence_precision ( convergence_precision ) if convergence_precision is not None else None ) self . saving_folder = saving_folder # Initialize search grid self . param_grid = SearchSpace ( parameters_bounds , parameters_precision , verbose ) # initialize arrays self . params_samp = np . zeros (( 0 , self . param_grid . dims )) self . losses_samp = np . zeros ( 0 ) self . batch_num_samp = np . zeros ( 0 , dtype = int ) self . method_samp = np . zeros ( 0 , dtype = int ) self . series_samp = np . zeros (( 0 , self . ensemble_size , self . N , self . D )) # initialize variables before calibration self . n_sampled_params = 0 self . current_batch_index = 0 # set number of processes for parallel evaluation of model self . n_jobs = n_jobs if n_jobs is not None else multiprocessing . cpu_count () print ( f \"Selecting { self . n_jobs } processes for the parallel evaluation of the model\" ) self . samplers_id_table = self . _construct_samplers_id_table ( samplers ) calibrate ( self , n_batches ) Run calibration for n batches. Parameters: Name Type Description Default n_batches int number of 'batches' to be executed. Each batch runs over all methods required Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray] The sampled parameters and the corresponding sampled losses. Both arrays are sorted by increasing loss values Source code in black_it/calibrator.py def calibrate ( self , n_batches : int ) -> Tuple [ NDArray , NDArray ]: \"\"\" Run calibration for n batches. Args: n_batches (int): number of 'batches' to be executed. Each batch runs over all methods Returns: The sampled parameters and the corresponding sampled losses. Both arrays are sorted by increasing loss values \"\"\" if self . current_batch_index == 0 : # we only set the samplers' random state at the start of a calibration self . _set_samplers_seeds () for _ in range ( n_batches ): print () print ( f \"BATCH NUMBER: { self . current_batch_index + 1 } \" ) print ( f \"PARAMS SAMPLED: { self . n_sampled_params } \" ) for method in self . samplers : t_start = time . time () print () print ( f \"METHOD: { type ( method ) . __name__ } \" ) # get new params from a specific sampler new_params = method . sample ( self . param_grid , self . params_samp , self . losses_samp , ) t_eval = time . time () # simulate an ensemble of models for different parameters new_simulated_data = self . simulate_model ( new_params ) new_losses = [] for sim_data_ensemble in new_simulated_data : new_loss = self . loss_function . compute_loss ( sim_data_ensemble , self . real_data ) new_losses . append ( new_loss ) # update arrays self . params_samp = np . vstack (( self . params_samp , new_params )) self . losses_samp = np . hstack (( self . losses_samp , new_losses )) self . series_samp = np . vstack (( self . series_samp , new_simulated_data )) self . batch_num_samp = np . hstack ( ( self . batch_num_samp , [ self . current_batch_index ] * method . batch_size , ) ) self . method_samp = np . hstack ( ( self . method_samp , [ self . samplers_id_table [ type ( method ) . __name__ ]] * method . batch_size , ) ) # logging t_end = time . time () if self . verbose : min_dist_new_points = np . round ( np . min ( new_losses ), 2 ) avg_dist_new_points = np . round ( np . average ( new_losses ), 2 ) avg_dist_existing_points = np . round ( np . average ( self . losses_samp ), 2 ) elapsed_tot = np . round ( t_end - t_start , 1 ) elapsed_eval = np . round ( t_end - t_eval , 1 ) print ( textwrap . dedent ( f \"\"\" \\ ----> sim exec elapsed time: { elapsed_eval } s ----> min loss new params: { min_dist_new_points } ----> avg loss new params: { avg_dist_new_points } ----> avg loss exist params: { avg_dist_existing_points } ----> curr min loss: { np . min ( self . losses_samp ) } ====> total elapsed time: { elapsed_tot } s \"\"\" ), end = \"\" , ) # update count of number of params sampled self . n_sampled_params = self . n_sampled_params + len ( new_params ) self . current_batch_index += 1 # check convergence for early termination if self . convergence_precision is not None : converged = self . check_convergence ( self . losses_samp , self . n_sampled_params , self . convergence_precision ) if converged and self . verbose : print ( \" \\n CONVERGENCE CHECK:\" ) print ( \"Achieved convergence loss, stopping search.\" ) break if self . saving_folder is not None : self . create_checkpoint ( self . saving_folder ) idx = np . argsort ( self . losses_samp ) return self . params_samp [ idx ], self . losses_samp [ idx ] check_convergence ( losses_samp , n_sampled_params , convergence_precision ) staticmethod Check convergence of the calibration. Parameters: Name Type Description Default losses_samp ndarray the sampled losses required n_sampled_params int the number of sampled params required convergence_precision int the required convergence precision. required Returns: Type Description bool True if the calibration converged, False otherwise. Source code in black_it/calibrator.py @staticmethod def check_convergence ( losses_samp : NDArray , n_sampled_params : int , convergence_precision : int ) -> bool : \"\"\" Check convergence of the calibration. Args: losses_samp: the sampled losses n_sampled_params: the number of sampled params convergence_precision: the required convergence precision. Returns: True if the calibration converged, False otherwise. \"\"\" converged = ( np . round ( np . min ( losses_samp [: n_sampled_params ]), convergence_precision ) == 0.0 ) return converged create_checkpoint ( self , file_name ) Save the current state of the object. Parameters: Name Type Description Default file_name Union[str, os.PathLike] the name of the folder where the data will be saved required Source code in black_it/calibrator.py def create_checkpoint ( self , file_name : Union [ str , os . PathLike ]) -> None : \"\"\" Save the current state of the object. Args: file_name: the name of the folder where the data will be saved \"\"\" checkpoint_path : str = os . path . join ( os . path . realpath ( file_name )) t_start = time . time () model_name = self . model . __name__ save_calibrator_state ( checkpoint_path , self . param_grid . parameters_bounds , self . param_grid . parameters_precision , self . real_data , self . ensemble_size , self . N , self . D , self . convergence_precision , self . verbose , self . saving_folder , self . random_state , self . random_generator . bit_generator . state , model_name , self . samplers , self . loss_function , self . current_batch_index , self . n_sampled_params , self . n_jobs , self . params_samp , self . losses_samp , self . series_samp , self . batch_num_samp , self . method_samp , ) t_end = time . time () elapsed = np . round ( t_end - t_start , 1 ) print ( f \"Checkpoint saved in { elapsed } s\" ) restore_from_checkpoint ( checkpoint_path , model ) classmethod Return an instantiated class from a database file and a model simulator. Parameters: Name Type Description Default checkpoint_path str the name of the database file to read from required model Callable the model to calibrate. It must be equal to the one already calibrated required Returns: Type Description Calibrator An initialised Calibrator object. Source code in black_it/calibrator.py @classmethod def restore_from_checkpoint ( # pylint: disable=too-many-locals cls , checkpoint_path : str , model : Callable ) -> \"Calibrator\" : \"\"\" Return an instantiated class from a database file and a model simulator. Args: checkpoint_path: the name of the database file to read from model: the model to calibrate. It must be equal to the one already calibrated Returns: An initialised Calibrator object. \"\"\" ( parameters_bounds , parameters_precision , real_data , ensemble_size , _N , _D , convergence_precision , verbose , saving_file , random_state , random_generator_state , model_name , samplers , loss_function , current_batch_index , n_sampled_params , n_jobs , params_samp , losses_samp , series_samp , batch_num_samp , method_samp , ) = load_calibrator_state ( checkpoint_path , cls . STATE_VERSION ) assert_ ( model_name == model . __name__ , ( \"Error: the model provided appears to be different from the one present \" \"in the database\" ), ) calibrator = cls ( samplers , loss_function , real_data , model , parameters_bounds , parameters_precision , ensemble_size , convergence_precision , verbose , saving_file , random_state , n_jobs , ) calibrator . current_batch_index = current_batch_index calibrator . n_sampled_params = n_sampled_params calibrator . params_samp = params_samp calibrator . losses_samp = losses_samp calibrator . series_samp = series_samp calibrator . batch_num_samp = batch_num_samp calibrator . method_samp = method_samp # reset the random number generator state calibrator . random_generator . bit_generator . state = random_generator_state return calibrator set_samplers ( self , samplers ) Set the samplers list of the calibrator. This method overwrites the samplers of a calibrator object with a custom list of samplers. Parameters: Name Type Description Default samplers List[black_it.samplers.base.BaseSampler] a list of samplers required Source code in black_it/calibrator.py def set_samplers ( self , samplers : List [ BaseSampler ]) -> None : \"\"\"Set the samplers list of the calibrator. This method overwrites the samplers of a calibrator object with a custom list of samplers. Args: samplers: a list of samplers \"\"\" # overwrite the list of samplers self . samplers = samplers # update the samplers_id_table with the new samplers, only if necessary sampler_id = max ( self . samplers_id_table . values ()) + 1 for sampler in samplers : sampler_name = type ( sampler ) . __name__ if sampler_name in self . samplers_id_table : continue self . samplers_id_table [ sampler_name ] = sampler_id sampler_id = sampler_id + 1 simulate_model ( self , params ) Simulate the model. This method calls the model simulator in parallel on a given set of parameter values, a number of repeated evaluations are performed for each parameter to average out random fluctuations. Parameters: Name Type Description Default params ndarray the array of parameters for which the model should be evaluated required noqa Returns: Type Description simulated_data an array of dimensions (batch_size, ensemble_size, N, D) containing all simulated time series Source code in black_it/calibrator.py def simulate_model ( self , params : NDArray ) -> NDArray : \"\"\" Simulate the model. This method calls the model simulator in parallel on a given set of parameter values, a number of repeated evaluations are performed for each parameter to average out random fluctuations. Args: params: the array of parameters for which the model should be evaluated # noqa Returns: simulated_data: an array of dimensions (batch_size, ensemble_size, N, D) containing all simulated time series \"\"\" rep_params = np . repeat ( params , self . ensemble_size , axis = 0 ) simulated_data_list = Parallel ( n_jobs = self . n_jobs )( delayed ( self . model )( param , self . N , self . _get_random_seed ()) for i , param in enumerate ( rep_params ) ) simulated_data = np . array ( simulated_data_list ) simulated_data = np . reshape ( simulated_data , ( params . shape [ 0 ], self . ensemble_size , self . N , self . D ) ) return simulated_data","title":"Calibrator"},{"location":"calibrator/#black_it.calibrator.Calibrator","text":"The class used to perform a calibration. Source code in black_it/calibrator.py class Calibrator : # pylint: disable=too-many-instance-attributes \"\"\"The class used to perform a calibration.\"\"\" STATE_VERSION = 0 def __init__ ( # pylint: disable=too-many-arguments self , samplers : List [ BaseSampler ], loss_function : BaseLoss , real_data : NDArray [ np . float64 ], model : Callable , parameters_bounds : Union [ NDArray [ np . float64 ], List [ List [ float ]]], parameters_precision : Union [ NDArray [ np . float64 ], List [ float ]], ensemble_size : int , convergence_precision : Optional [ int ] = None , verbose : bool = True , saving_folder : Optional [ str ] = None , random_state : Optional [ int ] = None , n_jobs : Optional [ int ] = None , ): \"\"\" Initialize the Calibrator object. It must be initialized with details on the parameters to explore, on the model to calibrate, on the samplers and on the loss function to use. Args: samplers: list of methods to be used in the calibration procedure loss_function: a loss function which evaluates the similarity between simulated and real datasets real_data: an array containing the real time series model: a model with free parameters to be calibrated parameters_bounds: the bounds of the parameter space parameters_precision: the precisions to be used for the discretization of the parameters ensemble_size: number of repetitions to be run for each set of parameters to decrease statistical fluctuations. For deterministic models this should be set to 1. convergence_precision: number of significant digits to consider in the convergence check. The check is not performed if this is set to 'None'. verbose: whether to print calibration updates saving_folder: the name of the folder where data should be saved and/or retrieved random_state: random state of the calibrator, used for model simulations and to initialise the samplers n_jobs: the maximum number of concurrently running jobs. For more details, see the [joblib.Parallel documentation](https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html). \"\"\" self . samplers = samplers self . loss_function = loss_function self . model = model self . random_state = random_state self . real_data = real_data self . ensemble_size = ensemble_size self . N = self . real_data . shape [ 0 ] self . D = self . real_data . shape [ 1 ] self . verbose = verbose self . convergence_precision = ( self . _validate_convergence_precision ( convergence_precision ) if convergence_precision is not None else None ) self . saving_folder = saving_folder # Initialize search grid self . param_grid = SearchSpace ( parameters_bounds , parameters_precision , verbose ) # initialize arrays self . params_samp = np . zeros (( 0 , self . param_grid . dims )) self . losses_samp = np . zeros ( 0 ) self . batch_num_samp = np . zeros ( 0 , dtype = int ) self . method_samp = np . zeros ( 0 , dtype = int ) self . series_samp = np . zeros (( 0 , self . ensemble_size , self . N , self . D )) # initialize variables before calibration self . n_sampled_params = 0 self . current_batch_index = 0 # set number of processes for parallel evaluation of model self . n_jobs = n_jobs if n_jobs is not None else multiprocessing . cpu_count () print ( f \"Selecting { self . n_jobs } processes for the parallel evaluation of the model\" ) self . samplers_id_table = self . _construct_samplers_id_table ( samplers ) @property def random_state ( self ) -> Optional [ int ]: \"\"\"Get the random state.\"\"\" return self . _random_state @random_state . setter def random_state ( self , random_state : Optional [ int ]) -> None : \"\"\"Set the random state.\"\"\" self . _random_state = random_state self . _random_generator = default_rng ( self . random_state ) @property def random_generator ( self ) -> np . random . Generator : \"\"\"Get the random generator.\"\"\" return self . _random_generator def _get_random_seed ( self ) -> int : \"\"\"Get new random seed from the current random generator.\"\"\" return get_random_seed ( self . _random_generator ) def _set_samplers_seeds ( self ) -> None : \"\"\"Set the calibration seed.\"\"\" for sampler in self . samplers : sampler . random_state = self . _get_random_seed () @staticmethod def _construct_samplers_id_table ( samplers : List [ BaseSampler ]) -> Dict [ str , int ]: \"\"\" Construct the samplers-by-id table. Given the list (built-in or user-defined) of samplers a calibration session is going to use, return a map from the sampler human-readable name to a numeric id (starting from 0). Different calibration sessions may result in different conversion tables. Args: samplers: the list of samplers of the calibrator Returns: A dict that maps from the given sampler names to unique ids. \"\"\" samplers_id_table = {} sampler_id = 0 for sampler in samplers : sampler_name = type ( sampler ) . __name__ if sampler_name in samplers_id_table : continue samplers_id_table [ sampler_name ] = sampler_id sampler_id = sampler_id + 1 return samplers_id_table def set_samplers ( self , samplers : List [ BaseSampler ]) -> None : \"\"\"Set the samplers list of the calibrator. This method overwrites the samplers of a calibrator object with a custom list of samplers. Args: samplers: a list of samplers \"\"\" # overwrite the list of samplers self . samplers = samplers # update the samplers_id_table with the new samplers, only if necessary sampler_id = max ( self . samplers_id_table . values ()) + 1 for sampler in samplers : sampler_name = type ( sampler ) . __name__ if sampler_name in self . samplers_id_table : continue self . samplers_id_table [ sampler_name ] = sampler_id sampler_id = sampler_id + 1 @classmethod def restore_from_checkpoint ( # pylint: disable=too-many-locals cls , checkpoint_path : str , model : Callable ) -> \"Calibrator\" : \"\"\" Return an instantiated class from a database file and a model simulator. Args: checkpoint_path: the name of the database file to read from model: the model to calibrate. It must be equal to the one already calibrated Returns: An initialised Calibrator object. \"\"\" ( parameters_bounds , parameters_precision , real_data , ensemble_size , _N , _D , convergence_precision , verbose , saving_file , random_state , random_generator_state , model_name , samplers , loss_function , current_batch_index , n_sampled_params , n_jobs , params_samp , losses_samp , series_samp , batch_num_samp , method_samp , ) = load_calibrator_state ( checkpoint_path , cls . STATE_VERSION ) assert_ ( model_name == model . __name__ , ( \"Error: the model provided appears to be different from the one present \" \"in the database\" ), ) calibrator = cls ( samplers , loss_function , real_data , model , parameters_bounds , parameters_precision , ensemble_size , convergence_precision , verbose , saving_file , random_state , n_jobs , ) calibrator . current_batch_index = current_batch_index calibrator . n_sampled_params = n_sampled_params calibrator . params_samp = params_samp calibrator . losses_samp = losses_samp calibrator . series_samp = series_samp calibrator . batch_num_samp = batch_num_samp calibrator . method_samp = method_samp # reset the random number generator state calibrator . random_generator . bit_generator . state = random_generator_state return calibrator def simulate_model ( self , params : NDArray ) -> NDArray : \"\"\" Simulate the model. This method calls the model simulator in parallel on a given set of parameter values, a number of repeated evaluations are performed for each parameter to average out random fluctuations. Args: params: the array of parameters for which the model should be evaluated # noqa Returns: simulated_data: an array of dimensions (batch_size, ensemble_size, N, D) containing all simulated time series \"\"\" rep_params = np . repeat ( params , self . ensemble_size , axis = 0 ) simulated_data_list = Parallel ( n_jobs = self . n_jobs )( delayed ( self . model )( param , self . N , self . _get_random_seed ()) for i , param in enumerate ( rep_params ) ) simulated_data = np . array ( simulated_data_list ) simulated_data = np . reshape ( simulated_data , ( params . shape [ 0 ], self . ensemble_size , self . N , self . D ) ) return simulated_data def calibrate ( self , n_batches : int ) -> Tuple [ NDArray , NDArray ]: \"\"\" Run calibration for n batches. Args: n_batches (int): number of 'batches' to be executed. Each batch runs over all methods Returns: The sampled parameters and the corresponding sampled losses. Both arrays are sorted by increasing loss values \"\"\" if self . current_batch_index == 0 : # we only set the samplers' random state at the start of a calibration self . _set_samplers_seeds () for _ in range ( n_batches ): print () print ( f \"BATCH NUMBER: { self . current_batch_index + 1 } \" ) print ( f \"PARAMS SAMPLED: { self . n_sampled_params } \" ) for method in self . samplers : t_start = time . time () print () print ( f \"METHOD: { type ( method ) . __name__ } \" ) # get new params from a specific sampler new_params = method . sample ( self . param_grid , self . params_samp , self . losses_samp , ) t_eval = time . time () # simulate an ensemble of models for different parameters new_simulated_data = self . simulate_model ( new_params ) new_losses = [] for sim_data_ensemble in new_simulated_data : new_loss = self . loss_function . compute_loss ( sim_data_ensemble , self . real_data ) new_losses . append ( new_loss ) # update arrays self . params_samp = np . vstack (( self . params_samp , new_params )) self . losses_samp = np . hstack (( self . losses_samp , new_losses )) self . series_samp = np . vstack (( self . series_samp , new_simulated_data )) self . batch_num_samp = np . hstack ( ( self . batch_num_samp , [ self . current_batch_index ] * method . batch_size , ) ) self . method_samp = np . hstack ( ( self . method_samp , [ self . samplers_id_table [ type ( method ) . __name__ ]] * method . batch_size , ) ) # logging t_end = time . time () if self . verbose : min_dist_new_points = np . round ( np . min ( new_losses ), 2 ) avg_dist_new_points = np . round ( np . average ( new_losses ), 2 ) avg_dist_existing_points = np . round ( np . average ( self . losses_samp ), 2 ) elapsed_tot = np . round ( t_end - t_start , 1 ) elapsed_eval = np . round ( t_end - t_eval , 1 ) print ( textwrap . dedent ( f \"\"\" \\ ----> sim exec elapsed time: { elapsed_eval } s ----> min loss new params: { min_dist_new_points } ----> avg loss new params: { avg_dist_new_points } ----> avg loss exist params: { avg_dist_existing_points } ----> curr min loss: { np . min ( self . losses_samp ) } ====> total elapsed time: { elapsed_tot } s \"\"\" ), end = \"\" , ) # update count of number of params sampled self . n_sampled_params = self . n_sampled_params + len ( new_params ) self . current_batch_index += 1 # check convergence for early termination if self . convergence_precision is not None : converged = self . check_convergence ( self . losses_samp , self . n_sampled_params , self . convergence_precision ) if converged and self . verbose : print ( \" \\n CONVERGENCE CHECK:\" ) print ( \"Achieved convergence loss, stopping search.\" ) break if self . saving_folder is not None : self . create_checkpoint ( self . saving_folder ) idx = np . argsort ( self . losses_samp ) return self . params_samp [ idx ], self . losses_samp [ idx ] @staticmethod def check_convergence ( losses_samp : NDArray , n_sampled_params : int , convergence_precision : int ) -> bool : \"\"\" Check convergence of the calibration. Args: losses_samp: the sampled losses n_sampled_params: the number of sampled params convergence_precision: the required convergence precision. Returns: True if the calibration converged, False otherwise. \"\"\" converged = ( np . round ( np . min ( losses_samp [: n_sampled_params ]), convergence_precision ) == 0.0 ) return converged def create_checkpoint ( self , file_name : Union [ str , os . PathLike ]) -> None : \"\"\" Save the current state of the object. Args: file_name: the name of the folder where the data will be saved \"\"\" checkpoint_path : str = os . path . join ( os . path . realpath ( file_name )) t_start = time . time () model_name = self . model . __name__ save_calibrator_state ( checkpoint_path , self . param_grid . parameters_bounds , self . param_grid . parameters_precision , self . real_data , self . ensemble_size , self . N , self . D , self . convergence_precision , self . verbose , self . saving_folder , self . random_state , self . random_generator . bit_generator . state , model_name , self . samplers , self . loss_function , self . current_batch_index , self . n_sampled_params , self . n_jobs , self . params_samp , self . losses_samp , self . series_samp , self . batch_num_samp , self . method_samp , ) t_end = time . time () elapsed = np . round ( t_end - t_start , 1 ) print ( f \"Checkpoint saved in { elapsed } s\" ) @staticmethod def _validate_convergence_precision ( convergence_precision : int ) -> int : \"\"\"Validate convergence precision input.\"\"\" assert_ ( convergence_precision >= 0 , f \"convergence precision must be an integer greater than 0, got { convergence_precision } \" , exc_cls = ValueError , ) return convergence_precision","title":"Calibrator"},{"location":"calibrator/#black_it.calibrator.Calibrator.random_generator","text":"Get the random generator.","title":"random_generator"},{"location":"calibrator/#black_it.calibrator.Calibrator.random_state","text":"Get the random state.","title":"random_state"},{"location":"calibrator/#black_it.calibrator.Calibrator.__init__","text":"Initialize the Calibrator object. It must be initialized with details on the parameters to explore, on the model to calibrate, on the samplers and on the loss function to use. Parameters: Name Type Description Default samplers List[black_it.samplers.base.BaseSampler] list of methods to be used in the calibration procedure required loss_function BaseLoss a loss function which evaluates the similarity between simulated and real datasets required real_data ndarray an array containing the real time series required model Callable a model with free parameters to be calibrated required parameters_bounds Union[numpy.ndarray, List[List[float]]] the bounds of the parameter space required parameters_precision Union[numpy.ndarray, List[float]] the precisions to be used for the discretization of the parameters required ensemble_size int number of repetitions to be run for each set of parameters to decrease statistical fluctuations. For deterministic models this should be set to 1. required convergence_precision Optional[int] number of significant digits to consider in the convergence check. The check is not performed if this is set to 'None'. None verbose bool whether to print calibration updates True saving_folder Optional[str] the name of the folder where data should be saved and/or retrieved None random_state Optional[int] random state of the calibrator, used for model simulations and to initialise the samplers None n_jobs Optional[int] the maximum number of concurrently running jobs. For more details, see the joblib.Parallel documentation . None Source code in black_it/calibrator.py def __init__ ( # pylint: disable=too-many-arguments self , samplers : List [ BaseSampler ], loss_function : BaseLoss , real_data : NDArray [ np . float64 ], model : Callable , parameters_bounds : Union [ NDArray [ np . float64 ], List [ List [ float ]]], parameters_precision : Union [ NDArray [ np . float64 ], List [ float ]], ensemble_size : int , convergence_precision : Optional [ int ] = None , verbose : bool = True , saving_folder : Optional [ str ] = None , random_state : Optional [ int ] = None , n_jobs : Optional [ int ] = None , ): \"\"\" Initialize the Calibrator object. It must be initialized with details on the parameters to explore, on the model to calibrate, on the samplers and on the loss function to use. Args: samplers: list of methods to be used in the calibration procedure loss_function: a loss function which evaluates the similarity between simulated and real datasets real_data: an array containing the real time series model: a model with free parameters to be calibrated parameters_bounds: the bounds of the parameter space parameters_precision: the precisions to be used for the discretization of the parameters ensemble_size: number of repetitions to be run for each set of parameters to decrease statistical fluctuations. For deterministic models this should be set to 1. convergence_precision: number of significant digits to consider in the convergence check. The check is not performed if this is set to 'None'. verbose: whether to print calibration updates saving_folder: the name of the folder where data should be saved and/or retrieved random_state: random state of the calibrator, used for model simulations and to initialise the samplers n_jobs: the maximum number of concurrently running jobs. For more details, see the [joblib.Parallel documentation](https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html). \"\"\" self . samplers = samplers self . loss_function = loss_function self . model = model self . random_state = random_state self . real_data = real_data self . ensemble_size = ensemble_size self . N = self . real_data . shape [ 0 ] self . D = self . real_data . shape [ 1 ] self . verbose = verbose self . convergence_precision = ( self . _validate_convergence_precision ( convergence_precision ) if convergence_precision is not None else None ) self . saving_folder = saving_folder # Initialize search grid self . param_grid = SearchSpace ( parameters_bounds , parameters_precision , verbose ) # initialize arrays self . params_samp = np . zeros (( 0 , self . param_grid . dims )) self . losses_samp = np . zeros ( 0 ) self . batch_num_samp = np . zeros ( 0 , dtype = int ) self . method_samp = np . zeros ( 0 , dtype = int ) self . series_samp = np . zeros (( 0 , self . ensemble_size , self . N , self . D )) # initialize variables before calibration self . n_sampled_params = 0 self . current_batch_index = 0 # set number of processes for parallel evaluation of model self . n_jobs = n_jobs if n_jobs is not None else multiprocessing . cpu_count () print ( f \"Selecting { self . n_jobs } processes for the parallel evaluation of the model\" ) self . samplers_id_table = self . _construct_samplers_id_table ( samplers )","title":"__init__()"},{"location":"calibrator/#black_it.calibrator.Calibrator.calibrate","text":"Run calibration for n batches. Parameters: Name Type Description Default n_batches int number of 'batches' to be executed. Each batch runs over all methods required Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray] The sampled parameters and the corresponding sampled losses. Both arrays are sorted by increasing loss values Source code in black_it/calibrator.py def calibrate ( self , n_batches : int ) -> Tuple [ NDArray , NDArray ]: \"\"\" Run calibration for n batches. Args: n_batches (int): number of 'batches' to be executed. Each batch runs over all methods Returns: The sampled parameters and the corresponding sampled losses. Both arrays are sorted by increasing loss values \"\"\" if self . current_batch_index == 0 : # we only set the samplers' random state at the start of a calibration self . _set_samplers_seeds () for _ in range ( n_batches ): print () print ( f \"BATCH NUMBER: { self . current_batch_index + 1 } \" ) print ( f \"PARAMS SAMPLED: { self . n_sampled_params } \" ) for method in self . samplers : t_start = time . time () print () print ( f \"METHOD: { type ( method ) . __name__ } \" ) # get new params from a specific sampler new_params = method . sample ( self . param_grid , self . params_samp , self . losses_samp , ) t_eval = time . time () # simulate an ensemble of models for different parameters new_simulated_data = self . simulate_model ( new_params ) new_losses = [] for sim_data_ensemble in new_simulated_data : new_loss = self . loss_function . compute_loss ( sim_data_ensemble , self . real_data ) new_losses . append ( new_loss ) # update arrays self . params_samp = np . vstack (( self . params_samp , new_params )) self . losses_samp = np . hstack (( self . losses_samp , new_losses )) self . series_samp = np . vstack (( self . series_samp , new_simulated_data )) self . batch_num_samp = np . hstack ( ( self . batch_num_samp , [ self . current_batch_index ] * method . batch_size , ) ) self . method_samp = np . hstack ( ( self . method_samp , [ self . samplers_id_table [ type ( method ) . __name__ ]] * method . batch_size , ) ) # logging t_end = time . time () if self . verbose : min_dist_new_points = np . round ( np . min ( new_losses ), 2 ) avg_dist_new_points = np . round ( np . average ( new_losses ), 2 ) avg_dist_existing_points = np . round ( np . average ( self . losses_samp ), 2 ) elapsed_tot = np . round ( t_end - t_start , 1 ) elapsed_eval = np . round ( t_end - t_eval , 1 ) print ( textwrap . dedent ( f \"\"\" \\ ----> sim exec elapsed time: { elapsed_eval } s ----> min loss new params: { min_dist_new_points } ----> avg loss new params: { avg_dist_new_points } ----> avg loss exist params: { avg_dist_existing_points } ----> curr min loss: { np . min ( self . losses_samp ) } ====> total elapsed time: { elapsed_tot } s \"\"\" ), end = \"\" , ) # update count of number of params sampled self . n_sampled_params = self . n_sampled_params + len ( new_params ) self . current_batch_index += 1 # check convergence for early termination if self . convergence_precision is not None : converged = self . check_convergence ( self . losses_samp , self . n_sampled_params , self . convergence_precision ) if converged and self . verbose : print ( \" \\n CONVERGENCE CHECK:\" ) print ( \"Achieved convergence loss, stopping search.\" ) break if self . saving_folder is not None : self . create_checkpoint ( self . saving_folder ) idx = np . argsort ( self . losses_samp ) return self . params_samp [ idx ], self . losses_samp [ idx ]","title":"calibrate()"},{"location":"calibrator/#black_it.calibrator.Calibrator.check_convergence","text":"Check convergence of the calibration. Parameters: Name Type Description Default losses_samp ndarray the sampled losses required n_sampled_params int the number of sampled params required convergence_precision int the required convergence precision. required Returns: Type Description bool True if the calibration converged, False otherwise. Source code in black_it/calibrator.py @staticmethod def check_convergence ( losses_samp : NDArray , n_sampled_params : int , convergence_precision : int ) -> bool : \"\"\" Check convergence of the calibration. Args: losses_samp: the sampled losses n_sampled_params: the number of sampled params convergence_precision: the required convergence precision. Returns: True if the calibration converged, False otherwise. \"\"\" converged = ( np . round ( np . min ( losses_samp [: n_sampled_params ]), convergence_precision ) == 0.0 ) return converged","title":"check_convergence()"},{"location":"calibrator/#black_it.calibrator.Calibrator.create_checkpoint","text":"Save the current state of the object. Parameters: Name Type Description Default file_name Union[str, os.PathLike] the name of the folder where the data will be saved required Source code in black_it/calibrator.py def create_checkpoint ( self , file_name : Union [ str , os . PathLike ]) -> None : \"\"\" Save the current state of the object. Args: file_name: the name of the folder where the data will be saved \"\"\" checkpoint_path : str = os . path . join ( os . path . realpath ( file_name )) t_start = time . time () model_name = self . model . __name__ save_calibrator_state ( checkpoint_path , self . param_grid . parameters_bounds , self . param_grid . parameters_precision , self . real_data , self . ensemble_size , self . N , self . D , self . convergence_precision , self . verbose , self . saving_folder , self . random_state , self . random_generator . bit_generator . state , model_name , self . samplers , self . loss_function , self . current_batch_index , self . n_sampled_params , self . n_jobs , self . params_samp , self . losses_samp , self . series_samp , self . batch_num_samp , self . method_samp , ) t_end = time . time () elapsed = np . round ( t_end - t_start , 1 ) print ( f \"Checkpoint saved in { elapsed } s\" )","title":"create_checkpoint()"},{"location":"calibrator/#black_it.calibrator.Calibrator.restore_from_checkpoint","text":"Return an instantiated class from a database file and a model simulator. Parameters: Name Type Description Default checkpoint_path str the name of the database file to read from required model Callable the model to calibrate. It must be equal to the one already calibrated required Returns: Type Description Calibrator An initialised Calibrator object. Source code in black_it/calibrator.py @classmethod def restore_from_checkpoint ( # pylint: disable=too-many-locals cls , checkpoint_path : str , model : Callable ) -> \"Calibrator\" : \"\"\" Return an instantiated class from a database file and a model simulator. Args: checkpoint_path: the name of the database file to read from model: the model to calibrate. It must be equal to the one already calibrated Returns: An initialised Calibrator object. \"\"\" ( parameters_bounds , parameters_precision , real_data , ensemble_size , _N , _D , convergence_precision , verbose , saving_file , random_state , random_generator_state , model_name , samplers , loss_function , current_batch_index , n_sampled_params , n_jobs , params_samp , losses_samp , series_samp , batch_num_samp , method_samp , ) = load_calibrator_state ( checkpoint_path , cls . STATE_VERSION ) assert_ ( model_name == model . __name__ , ( \"Error: the model provided appears to be different from the one present \" \"in the database\" ), ) calibrator = cls ( samplers , loss_function , real_data , model , parameters_bounds , parameters_precision , ensemble_size , convergence_precision , verbose , saving_file , random_state , n_jobs , ) calibrator . current_batch_index = current_batch_index calibrator . n_sampled_params = n_sampled_params calibrator . params_samp = params_samp calibrator . losses_samp = losses_samp calibrator . series_samp = series_samp calibrator . batch_num_samp = batch_num_samp calibrator . method_samp = method_samp # reset the random number generator state calibrator . random_generator . bit_generator . state = random_generator_state return calibrator","title":"restore_from_checkpoint()"},{"location":"calibrator/#black_it.calibrator.Calibrator.set_samplers","text":"Set the samplers list of the calibrator. This method overwrites the samplers of a calibrator object with a custom list of samplers. Parameters: Name Type Description Default samplers List[black_it.samplers.base.BaseSampler] a list of samplers required Source code in black_it/calibrator.py def set_samplers ( self , samplers : List [ BaseSampler ]) -> None : \"\"\"Set the samplers list of the calibrator. This method overwrites the samplers of a calibrator object with a custom list of samplers. Args: samplers: a list of samplers \"\"\" # overwrite the list of samplers self . samplers = samplers # update the samplers_id_table with the new samplers, only if necessary sampler_id = max ( self . samplers_id_table . values ()) + 1 for sampler in samplers : sampler_name = type ( sampler ) . __name__ if sampler_name in self . samplers_id_table : continue self . samplers_id_table [ sampler_name ] = sampler_id sampler_id = sampler_id + 1","title":"set_samplers()"},{"location":"calibrator/#black_it.calibrator.Calibrator.simulate_model","text":"Simulate the model. This method calls the model simulator in parallel on a given set of parameter values, a number of repeated evaluations are performed for each parameter to average out random fluctuations. Parameters: Name Type Description Default params ndarray the array of parameters for which the model should be evaluated required","title":"simulate_model()"},{"location":"calibrator/#black_it.calibrator.Calibrator.simulate_model--noqa","text":"Returns: Type Description simulated_data an array of dimensions (batch_size, ensemble_size, N, D) containing all simulated time series Source code in black_it/calibrator.py def simulate_model ( self , params : NDArray ) -> NDArray : \"\"\" Simulate the model. This method calls the model simulator in parallel on a given set of parameter values, a number of repeated evaluations are performed for each parameter to average out random fluctuations. Args: params: the array of parameters for which the model should be evaluated # noqa Returns: simulated_data: an array of dimensions (batch_size, ensemble_size, N, D) containing all simulated time series \"\"\" rep_params = np . repeat ( params , self . ensemble_size , axis = 0 ) simulated_data_list = Parallel ( n_jobs = self . n_jobs )( delayed ( self . model )( param , self . N , self . _get_random_seed ()) for i , param in enumerate ( rep_params ) ) simulated_data = np . array ( simulated_data_list ) simulated_data = np . reshape ( simulated_data , ( params . shape [ 0 ], self . ensemble_size , self . N , self . D ) ) return simulated_data","title":"noqa"},{"location":"checkpointing_parallelisation/","text":"Saving and loading For each batch execution of the calibration, a checkpoint can be created ( save ) so that it can be later restored ( load ). The functions responsible for these features are the method create_checkpoint(file_name) and the class method restore_from_checkpoint(checkpoint_path, model) of the Calibrator class. The checkpoint is created automatically at each batch execution, if a saving folder is provided. To do this, when a Calibrator object is instantiated, the saving_folder field must be specified as a string which contains the path where the checkpoint must be saved. Remark : there's no need to call the save method, once the saving folder is specified. To restore the checkpoint it suffices to call the load class method with the path name and, optionally, the model which was being calibrated. Once restored, the calibration starts from where it was interrupted. An example of save and load is as follows: # initialize a Calibrator object cal = Calibrator ( samplers = [ random_sampler , halton_sampler , ], real_data = real_data , model = model , parameters_bounds = bounds , parameters_precision = bounds_step , ensemble_size = 2 , loss_function = loss , saving_folder = \"saving_folder\" , n_jobs = 1 , ) _ , _ = cal . calibrate ( 2 ) cal_restored = Calibrator . restore_from_checkpoint ( \"saving_folder\" , model = model ) This code has been extracted from the following example: tests/test_calibrator_restore_from_checkpoint.py . Remark : the saving folder where the checkpoint is saved can also be used as a parameter for the plotting functions, as shown in the plotting tutorial , to produce plots quickly. Parallelisation Since calibrating an agent-based model can be very intensive, by default the model simulation is parallelised. The number of parallel processes equals the number of cores in the computer. This number can be changed by specifying the optional parameter n_jobs in the constructor of the calibrator.","title":"Checkpointing and parallelisation"},{"location":"checkpointing_parallelisation/#saving-and-loading","text":"For each batch execution of the calibration, a checkpoint can be created ( save ) so that it can be later restored ( load ). The functions responsible for these features are the method create_checkpoint(file_name) and the class method restore_from_checkpoint(checkpoint_path, model) of the Calibrator class. The checkpoint is created automatically at each batch execution, if a saving folder is provided. To do this, when a Calibrator object is instantiated, the saving_folder field must be specified as a string which contains the path where the checkpoint must be saved. Remark : there's no need to call the save method, once the saving folder is specified. To restore the checkpoint it suffices to call the load class method with the path name and, optionally, the model which was being calibrated. Once restored, the calibration starts from where it was interrupted. An example of save and load is as follows: # initialize a Calibrator object cal = Calibrator ( samplers = [ random_sampler , halton_sampler , ], real_data = real_data , model = model , parameters_bounds = bounds , parameters_precision = bounds_step , ensemble_size = 2 , loss_function = loss , saving_folder = \"saving_folder\" , n_jobs = 1 , ) _ , _ = cal . calibrate ( 2 ) cal_restored = Calibrator . restore_from_checkpoint ( \"saving_folder\" , model = model ) This code has been extracted from the following example: tests/test_calibrator_restore_from_checkpoint.py . Remark : the saving folder where the checkpoint is saved can also be used as a parameter for the plotting functions, as shown in the plotting tutorial , to produce plots quickly.","title":"Saving and loading"},{"location":"checkpointing_parallelisation/#parallelisation","text":"Since calibrating an agent-based model can be very intensive, by default the model simulation is parallelised. The number of parallel processes equals the number of cores in the computer. This number can be changed by specifying the optional parameter n_jobs in the constructor of the calibrator.","title":"Parallelisation"},{"location":"contributing/","text":"Extending Black-it Contributions to the library are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. There are various ways to contribute: If you need support, want to report a bug or ask for features, you can check the Issues page and raise an issue, if applicable. If you would like to contribute a bug fix of feature then submit a Pull request . For other kinds of feedback, you can contact one of the authors by email. A few simple rules All pull requests should be opened against the develop branch. Do not open a Pull Request against main . Before working on a feature, reach out to one of the core developers or discuss the feature in an issue. The library caters a diverse audience and new features require upfront coordination. Include unit tests for 100% coverage when you contribute new features, as they help to a) prove that your code works correctly, and b) guard against future breaking changes to lower the maintenance cost. Bug fixes also generally require unit tests, because the presence of bugs usually indicates insufficient test coverage. Whenever possible, keep API compatibility in mind when you change code in the black_it library. Reviewers of your pull request will comment on any API compatibility issues. All files must include a license header. Before committing and opening a PR, run all tests locally. This saves CI hours and ensures you only commit clean code. Contributing code If you have improvements, send us your pull requests! A team member will be assigned to review your pull requests. All tests are run as part of CI as well as various other checks (linters, static type checkers, security checkers, etc). If there are any problems, feedback is provided via GitHub. Once the pull request is approved and passes continuous integration checks, you or a team member can merge it. If you want to contribute, start working through the codebase, navigate to the GitHub \"issues\" tab and start looking through interesting issues. If you decide to start on an issue, leave a comment so that other people know that you're working on it. If you want to help out, but not alone, use the issue comment thread to coordinate. Development setup Set up your development environment by following these steps: Install Poetry , either by running run pip install poetry or as indicated here . Get the latest version of the code by running git clone https://github.com/bancaditalia/black-it.git cd black-it Setup a Poetry environment by running poetry shell poetry install Further commands needed during development We have various commands which are helpful during development. For linting and static analysis use: make lint make static make pylint make safety make bandit To apply black and isort code formatters: make black make isort whereas, to only check compliance: make black-check make isort-check To run tests: make test . For testing black_it.{SUBMODULE} with tests/test_{TESTMODULE} use: make test-sub dir={SUBMODULE} tdir={TESTMODULE} e.g. make test-sub tdir=losses dir=loss_functions","title":"Extending black-it"},{"location":"contributing/#extending-black-it","text":"Contributions to the library are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. There are various ways to contribute: If you need support, want to report a bug or ask for features, you can check the Issues page and raise an issue, if applicable. If you would like to contribute a bug fix of feature then submit a Pull request . For other kinds of feedback, you can contact one of the authors by email.","title":"Extending Black-it"},{"location":"contributing/#a-few-simple-rules","text":"All pull requests should be opened against the develop branch. Do not open a Pull Request against main . Before working on a feature, reach out to one of the core developers or discuss the feature in an issue. The library caters a diverse audience and new features require upfront coordination. Include unit tests for 100% coverage when you contribute new features, as they help to a) prove that your code works correctly, and b) guard against future breaking changes to lower the maintenance cost. Bug fixes also generally require unit tests, because the presence of bugs usually indicates insufficient test coverage. Whenever possible, keep API compatibility in mind when you change code in the black_it library. Reviewers of your pull request will comment on any API compatibility issues. All files must include a license header. Before committing and opening a PR, run all tests locally. This saves CI hours and ensures you only commit clean code.","title":"A few simple rules"},{"location":"contributing/#contributing-code","text":"If you have improvements, send us your pull requests! A team member will be assigned to review your pull requests. All tests are run as part of CI as well as various other checks (linters, static type checkers, security checkers, etc). If there are any problems, feedback is provided via GitHub. Once the pull request is approved and passes continuous integration checks, you or a team member can merge it. If you want to contribute, start working through the codebase, navigate to the GitHub \"issues\" tab and start looking through interesting issues. If you decide to start on an issue, leave a comment so that other people know that you're working on it. If you want to help out, but not alone, use the issue comment thread to coordinate.","title":"Contributing code"},{"location":"contributing/#development-setup","text":"Set up your development environment by following these steps: Install Poetry , either by running run pip install poetry or as indicated here . Get the latest version of the code by running git clone https://github.com/bancaditalia/black-it.git cd black-it Setup a Poetry environment by running poetry shell poetry install","title":"Development setup"},{"location":"contributing/#further-commands-needed-during-development","text":"We have various commands which are helpful during development. For linting and static analysis use: make lint make static make pylint make safety make bandit To apply black and isort code formatters: make black make isort whereas, to only check compliance: make black-check make isort-check To run tests: make test . For testing black_it.{SUBMODULE} with tests/test_{TESTMODULE} use: make test-sub dir={SUBMODULE} tdir={TESTMODULE} e.g. make test-sub tdir=losses dir=loss_functions","title":"Further commands needed during development"},{"location":"description/","text":"Illustration of Black-it calibration. The calibration (black lines) is divided in a maximum of n batches (blue lines), and in each batch S samplers are sequentially deployed (green lines). Each sampler suggests a set of parameters, for which the model is simulated and the loss function is evaluated. How it works The calibrator is essentially an optimizer which works on simulated data, produced by a specified model, and searches the parametric space by chaining a set of chosen algorithms. For a complete example about this, check the Examples section. The calibrator works iteratively and each iteration consists of three steps: Search algorithms are employed sequentially to sample a set of parameters. In this sense, the parameter space is \"searched\" Data is simulated E E times for each sampled parameter set. We will refer to E E as ensemble_size A loss function is evaluated, measuring the distance between the simulated data and the real data This is repeated until the loss function is very close to 0 or the maximum number of iterations is reached. The process is illustrated in the above figure. Remark : the simulator is a distinct subsystem in this process. It can be as simple as a Python function or it can be an external simulator altogether. The calibrator simply runs it each time. Simulation The basic premise behind the calibrator is that it uses simulated data. That is why it adapts well to agent-based models . Simulated data is produced in each iteration according to a given model, using the sampled parameters. A model can be any function which produces data and which depends on one or more parameters. This can be a probability distribution (like the standard Gaussian) or a stochastic process (like an ARMA model or a Markov chain ). Some examples of these \"standard\" models are the ones found in examples/models/simple_models.py . The examples/models directory also contains other models, including agent-based ones used in epidemiology and economics. For a description of them, check the Examples section. Remark : if you need to implement your own model, check how to use and the simulator interface . Optimization After the model is defined, the simulated datasets must be compared against the real dataset. The natural choice of distance for this is the mean distance between a simulated dataset and the real dataset, i.e., for each parameter \\theta \\theta , we have: $$ \\delta(\\theta) = \\frac{1}{E} \\sum_{e=1}^E L\\Big(\\mathbf{x}, \\mathbf{x}_e(\\theta)\\Big)$$ where: \\{\\mathbf{x}_e\\}_{e=1}^E \\{\\mathbf{x}_e\\}_{e=1}^E are the E E simulated datasets which depend upon the parameter \\theta \\theta \\mathbf{x} \\mathbf{x} is the real dataset L L is the chosen loss function The loss function L L can be anything that suits the problem which is being studied. Already implemented loss functions are: MinkowskiLoss , a generalization of the Euclidean distance (see Minkowski distance ) MethodOfMomentsLoss , the squared difference between real and simulated moments, based on method of simulated moments GslDivLoss , which is the GLS-div information criterion introduced by Lamperti (2018) in An information theoretic criterion for empirical validation of simulation models . In principle one should minimize the function \\delta \\delta over all possible values of \\theta \\theta . This is not possible in practice of course and that is why a set of search algorithm is used to sample parameters and get as low a distance \\delta \\delta as we can get. The sampling procedure depends on the chosen algorithm(s). The implemented algorithms can be divided in two groups, depending on how they act: RandomUniformSampler , HaltonSampler and RSequenceSampler sample at each iteration independently from previous iterations. This is because they aim at sampling uniformly over the space. In particular, the first one is a simple uniform distribution, while the latter two try to fill the parameter space as uniformly as possible (check low-discrepancy sequences ). For this reason, they are suggested to be used as a starting point to be concatenated with other algorithms. For more information on Halton sequences and R sequence, check here and here . BestBatchSampler , GaussianProcessSampler and RandomForestSampler sample using information from previous iterations (i.e. previously calculated distance functions). The first one samples new parameters around parameters with the lowest distance functions, the second and third one use respectively a Gaussian process and a random forest classifier to predict the parameters with the lowest distance and sample those. The use of such algorithms may help against computationally intensive calibrations, which can happen when dealing, for example, with agent-based models. In this notebook you can find an overview of the different samplers.","title":"How it works"},{"location":"description/#how-it-works","text":"The calibrator is essentially an optimizer which works on simulated data, produced by a specified model, and searches the parametric space by chaining a set of chosen algorithms. For a complete example about this, check the Examples section. The calibrator works iteratively and each iteration consists of three steps: Search algorithms are employed sequentially to sample a set of parameters. In this sense, the parameter space is \"searched\" Data is simulated E E times for each sampled parameter set. We will refer to E E as ensemble_size A loss function is evaluated, measuring the distance between the simulated data and the real data This is repeated until the loss function is very close to 0 or the maximum number of iterations is reached. The process is illustrated in the above figure. Remark : the simulator is a distinct subsystem in this process. It can be as simple as a Python function or it can be an external simulator altogether. The calibrator simply runs it each time.","title":"How it works"},{"location":"description/#simulation","text":"The basic premise behind the calibrator is that it uses simulated data. That is why it adapts well to agent-based models . Simulated data is produced in each iteration according to a given model, using the sampled parameters. A model can be any function which produces data and which depends on one or more parameters. This can be a probability distribution (like the standard Gaussian) or a stochastic process (like an ARMA model or a Markov chain ). Some examples of these \"standard\" models are the ones found in examples/models/simple_models.py . The examples/models directory also contains other models, including agent-based ones used in epidemiology and economics. For a description of them, check the Examples section. Remark : if you need to implement your own model, check how to use and the simulator interface .","title":"Simulation"},{"location":"description/#optimization","text":"After the model is defined, the simulated datasets must be compared against the real dataset. The natural choice of distance for this is the mean distance between a simulated dataset and the real dataset, i.e., for each parameter \\theta \\theta , we have: $$ \\delta(\\theta) = \\frac{1}{E} \\sum_{e=1}^E L\\Big(\\mathbf{x}, \\mathbf{x}_e(\\theta)\\Big)$$ where: \\{\\mathbf{x}_e\\}_{e=1}^E \\{\\mathbf{x}_e\\}_{e=1}^E are the E E simulated datasets which depend upon the parameter \\theta \\theta \\mathbf{x} \\mathbf{x} is the real dataset L L is the chosen loss function The loss function L L can be anything that suits the problem which is being studied. Already implemented loss functions are: MinkowskiLoss , a generalization of the Euclidean distance (see Minkowski distance ) MethodOfMomentsLoss , the squared difference between real and simulated moments, based on method of simulated moments GslDivLoss , which is the GLS-div information criterion introduced by Lamperti (2018) in An information theoretic criterion for empirical validation of simulation models . In principle one should minimize the function \\delta \\delta over all possible values of \\theta \\theta . This is not possible in practice of course and that is why a set of search algorithm is used to sample parameters and get as low a distance \\delta \\delta as we can get. The sampling procedure depends on the chosen algorithm(s). The implemented algorithms can be divided in two groups, depending on how they act: RandomUniformSampler , HaltonSampler and RSequenceSampler sample at each iteration independently from previous iterations. This is because they aim at sampling uniformly over the space. In particular, the first one is a simple uniform distribution, while the latter two try to fill the parameter space as uniformly as possible (check low-discrepancy sequences ). For this reason, they are suggested to be used as a starting point to be concatenated with other algorithms. For more information on Halton sequences and R sequence, check here and here . BestBatchSampler , GaussianProcessSampler and RandomForestSampler sample using information from previous iterations (i.e. previously calculated distance functions). The first one samples new parameters around parameters with the lowest distance functions, the second and third one use respectively a Gaussian process and a random forest classifier to predict the parameters with the lowest distance and sample those. The use of such algorithms may help against computationally intensive calibrations, which can happen when dealing, for example, with agent-based models. In this notebook you can find an overview of the different samplers.","title":"Optimization"},{"location":"examples/","text":"Examples and tutorials In this section, you can read about some example models, supplied by some Jupyter notebook tutorials, to better understand and explore the package. In the menu, you can find the links for all the notebooks. The tutorials include the models explained in this page, a tutorial on the different samplers and a plotting tutorial . Toy model This is a simple Gaussian distribution with known parameters N(1,1) N(1,1) . This has been thought for tutorial purposes only, so that estimated parameters can be compared to the true ones. The chosen loss function is the MSM loss and all five built-in samplers are employed. Here you can find the tutorial . Simple shock model This is a simple example of a stock price suddenly increasing due to a shock. P(t) = \\begin{cases} p_1, \\quad t < \\tau \\\\ p_2, \\quad t \\geq \\tau \\end{cases} P(t) = \\begin{cases} p_1, \\quad t < \\tau \\\\ p_2, \\quad t \\geq \\tau \\end{cases} The model parameters are p_1 p_1 , p_2 p_2 and \\tau \\tau . The model is fit on Slack Technologies stock price data, meant to quantify the shock after the spread of rumors about Salesforce wanting to acquire Slack (check here for the news). The loss function used is the quadratic one and the samplers are Halton, random forest and best batch. Here you can find the tutorial . SIR This is an agent-based SIR model, whose parameters \\beta \\beta and \\gamma \\gamma must be estimated. In this model, each agent has a probability of being infected by having a contact with another agent and a probability of recovering. Such probabilities are modeled by the SIR parameters, while the contact network is modeled by a random graph generated by a Watts-Strogatz model . As you will notice, in this tutorial, the model simulation is not implemented directly in Python but an external simulator is called and run on a docker container . For more information on how to use this option, check the simulator interface page. The chosen loss function is the quadratic loss and the chosen samplers are Halton, random forest and best batch samplers. The tutorial is divided in two parts: in the first one we will generate synthetic data feed it to black-it, in order to retrieve the parameters that were used to generate the synthetic time series. In the second part, we will extend the simple SIR model, introducing a structural break in the \\beta \\beta parameter. This break is meant to model a lockdown or any event changing the infection rate. The calibration must retrieve the infection rates before ( \\beta_1 \\beta_1 ) and after ( \\beta_2 \\beta_2 ) the structural break, the recovery rate \\gamma \\gamma , and the moment t t in which the break happened. In this second part the model is fit on Italian lockdown data in 2020, slightly modified for didactic purposes. Here you can find the tutorial . Boltzmann wealth model This is a simple agent-based model where every agent gives one unit of wealth to a random agent if a certain criterion is met (i.e. the ratio of the agents' wealth must be above a chosen threshold). Here you can find the tutorial where the model is calibrated on the Italian Gini index in 2017.","title":"Overview"},{"location":"examples/#examples-and-tutorials","text":"In this section, you can read about some example models, supplied by some Jupyter notebook tutorials, to better understand and explore the package. In the menu, you can find the links for all the notebooks. The tutorials include the models explained in this page, a tutorial on the different samplers and a plotting tutorial .","title":"Examples and tutorials"},{"location":"examples/#toy-model","text":"This is a simple Gaussian distribution with known parameters N(1,1) N(1,1) . This has been thought for tutorial purposes only, so that estimated parameters can be compared to the true ones. The chosen loss function is the MSM loss and all five built-in samplers are employed. Here you can find the tutorial .","title":"Toy model"},{"location":"examples/#simple-shock-model","text":"This is a simple example of a stock price suddenly increasing due to a shock. P(t) = \\begin{cases} p_1, \\quad t < \\tau \\\\ p_2, \\quad t \\geq \\tau \\end{cases} P(t) = \\begin{cases} p_1, \\quad t < \\tau \\\\ p_2, \\quad t \\geq \\tau \\end{cases} The model parameters are p_1 p_1 , p_2 p_2 and \\tau \\tau . The model is fit on Slack Technologies stock price data, meant to quantify the shock after the spread of rumors about Salesforce wanting to acquire Slack (check here for the news). The loss function used is the quadratic one and the samplers are Halton, random forest and best batch. Here you can find the tutorial .","title":"Simple shock model"},{"location":"examples/#sir","text":"This is an agent-based SIR model, whose parameters \\beta \\beta and \\gamma \\gamma must be estimated. In this model, each agent has a probability of being infected by having a contact with another agent and a probability of recovering. Such probabilities are modeled by the SIR parameters, while the contact network is modeled by a random graph generated by a Watts-Strogatz model . As you will notice, in this tutorial, the model simulation is not implemented directly in Python but an external simulator is called and run on a docker container . For more information on how to use this option, check the simulator interface page. The chosen loss function is the quadratic loss and the chosen samplers are Halton, random forest and best batch samplers. The tutorial is divided in two parts: in the first one we will generate synthetic data feed it to black-it, in order to retrieve the parameters that were used to generate the synthetic time series. In the second part, we will extend the simple SIR model, introducing a structural break in the \\beta \\beta parameter. This break is meant to model a lockdown or any event changing the infection rate. The calibration must retrieve the infection rates before ( \\beta_1 \\beta_1 ) and after ( \\beta_2 \\beta_2 ) the structural break, the recovery rate \\gamma \\gamma , and the moment t t in which the break happened. In this second part the model is fit on Italian lockdown data in 2020, slightly modified for didactic purposes. Here you can find the tutorial .","title":"SIR"},{"location":"examples/#boltzmann-wealth-model","text":"This is a simple agent-based model where every agent gives one unit of wealth to a random agent if a certain criterion is met (i.e. the ratio of the agents' wealth must be above a chosen threshold). Here you can find the tutorial where the model is calibrated on the Italian Gini index in 2017.","title":"Boltzmann wealth model"},{"location":"finding_the_parameters_of_a_SIR_model/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Finding the parameters of a SIR model Basic elements of a SIR model In our model, each agent transitions among 3 states: Susceptible , Infectious and Recovered . At each epoch, an Infectious agent has a probability \u03b2 of infecting its Susceptible neighbours, and a probability \u03b3 to transition to the Recovered state. From that moment on, it will no longer participate in the spreading of the disease. The connectivity between agents is modeled as a Watts-Strogatz small world random graph, a regular ring lattice of mean degree K where each node has a probability r of being randomly rewired. In our model, these parameters will be input-calibrated (i.e., fixed). # preparatory imports import numpy as np import matplotlib.pyplot as plt import matplotlib from black_it.calibrator import Calibrator from black_it.loss_functions.minkowski import MinkowskiLoss from black_it.plot.plot_results import ( plot_convergence , plot_losses , plot_losses_interact , plot_sampling , plot_sampling_interact , ) from black_it.samplers.best_batch import BestBatchSampler from black_it.samplers.halton import HaltonSampler from black_it.samplers.random_forest import RandomForestSampler cmap = matplotlib . cm . get_cmap ( \"tab10\" ) . colors def plotSeries ( title , SIR1 , SIR2 = None ): fig , ax1 = plt . subplots () ax1 . plot ( SIR1 [:, 0 ], \"-\" , label = \"susceptible\" , color = cmap [ 0 ]) ax1 . plot ( SIR1 [:, 1 ], \"-\" , label = \"infected\" , color = cmap [ 1 ]) ax1 . plot ( SIR1 [:, 2 ], \"-\" , label = \"recovered\" , color = cmap [ 2 ]) ax1 . tick_params ( axis = \"y\" , labelcolor = cmap [ 0 ]) ax1 . set_ylabel ( \"susceptible per 1000 inhabitants\" , color = cmap [ 0 ]) ax1 . set_xlabel ( \"weeks\" ) ax1 . legend ( loc = 5 ) if SIR2 is not None : ax1 . plot ( SIR2 [:, 0 ], \"--\" , label = \"susceptible\" , color = cmap [ 0 ]) ax1 . plot ( SIR2 [:, 1 ], \"--\" , label = \"infected\" , color = cmap [ 1 ]) ax1 . plot ( SIR2 [:, 2 ], \"--\" , label = \"recovered\" , color = cmap [ 2 ]) ax1 . title . set_text ( title ) fig . tight_layout () plt . show () def printBestParams ( params ): with np . printoptions ( suppress = True , formatter = { \"float_kind\" : \" {:.3f} \" . format }): print ( f \" brktime beta1 beta2 gamma\" ) print ( f \"Best parameters: { params [ 0 ] } \" ) Simple calibration over synthetic data Let's start by using black-it to recover the \\beta \\beta and \\gamma \\gamma parameter of a SIR model from synthetic data. Initialize a calibrator object To set up a calibration one needs to define the following components first: a model to be calibrated a loss function to measure the distance between the real time series and the simulated time series a set of samplers that iteratively suggest a set of parameter values to explore the parameter space that should be explored 1. Model simulator In order to use the SIR simulator, we need to download its docker image: Install Docker following the instructions given here Open Docker on your computer Run the following command in your terminal: docker pull bancaditalia/abmsimulator We can then proceed to generate the data we are going to try to reproduce via calibration. from models.sir.sir_docker import SIR true_params = [ 0.1 , 0.1 ] # in general not known! synth_data = SIR ( true_params , 50 , 0 ) plotSeries ( \"Synthetic data\" , synth_data ) var element = $('#32d7b93f-9d74-4d29-ae08-2edcce331bba'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); } 2. Loss function # import a quadratic loss, a simple squared difference bewteen the two series from black_it.loss_functions.minkowski import MinkowskiLoss loss = MinkowskiLoss () 3. Samplers from black_it.samplers.best_batch import BestBatchSampler from black_it.samplers.halton import HaltonSampler from black_it.samplers.random_forest import RandomForestSampler batch_size = 4 halton_sampler = HaltonSampler ( batch_size = batch_size ) random_forest_sampler = RandomForestSampler ( batch_size = batch_size ) best_batch_sampler = BestBatchSampler ( batch_size = batch_size ) samplers = [ halton_sampler , random_forest_sampler , best_batch_sampler ] 4. Parameter space (bounds and precision) bounds = [[ 0.001 , 0.001 ], [ 1.00 , 1.00 ]] precisions = [ 0.001 , 0.001 ] Finally, initialize the Calibrator from black_it.calibrator import Calibrator saving_folder = 'sir-test' # initialize a Calibrator object cal = Calibrator ( samplers = samplers , real_data = synth_data , model = SIR , parameters_bounds = bounds , parameters_precision = precisions , ensemble_size = 1 , loss_function = loss , saving_folder = saving_folder , ) *** Number of free params: 2. Explorable param space size: 1000000. *** Selecting 4 processes for the parallel evaluation of the model Calibration Calibrate the model for five batches params , losses = cal . calibrate ( 5 ) BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: HaltonSampler ----> sim exec elapsed time: 3.1s ----> min loss new params: 1093.27 ----> avg loss new params: 1387.94 ----> avg loss exist params: 1387.94 ----> curr min loss: 1093.2679706997856 ====> total elapsed time: 3.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 2.6s ----> min loss new params: 994.25 ----> avg loss new params: 1401.16 ----> avg loss exist params: 1394.55 ----> curr min loss: 994.2479459016207 ====> total elapsed time: 3.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 3.1s ----> min loss new params: 1091.99 ----> avg loss new params: 1218.39 ----> avg loss exist params: 1335.83 ----> curr min loss: 994.2479459016207 ====> total elapsed time: 3.1s Checkpoint saved in 0.0s BATCH NUMBER: 2 PARAMS SAMPLED: 12 METHOD: HaltonSampler ----> sim exec elapsed time: 7.1s ----> min loss new params: 1401.9 ----> avg loss new params: 2014.58 ----> avg loss exist params: 1505.52 ----> curr min loss: 994.2479459016207 ====> total elapsed time: 7.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 4.9s ----> min loss new params: 1413.63 ----> avg loss new params: 2200.89 ----> avg loss exist params: 1644.59 ----> curr min loss: 994.2479459016207 ====> total elapsed time: 6.2s METHOD: BestBatchSampler ----> sim exec elapsed time: 4.7s ----> min loss new params: 1084.36 ----> avg loss new params: 1109.2 ----> avg loss exist params: 1555.36 ----> curr min loss: 994.2479459016207 ====> total elapsed time: 4.7s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 4.4s ----> min loss new params: 880.29 ----> avg loss new params: 1508.88 ----> avg loss exist params: 1548.72 ----> curr min loss: 880.2915915967067 ====> total elapsed time: 4.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 3.5s ----> min loss new params: 850.56 ----> avg loss new params: 1041.11 ----> avg loss exist params: 1485.27 ----> curr min loss: 850.5637796224285 ====> total elapsed time: 4.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 6.4s ----> min loss new params: 881.79 ----> avg loss new params: 934.11 ----> avg loss exist params: 1424.03 ----> curr min loss: 850.5637796224285 ====> total elapsed time: 6.5s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 36 METHOD: HaltonSampler ----> sim exec elapsed time: 4.0s ----> min loss new params: 1670.77 ----> avg loss new params: 2426.46 ----> avg loss exist params: 1524.27 ----> curr min loss: 850.5637796224285 ====> total elapsed time: 4.0s METHOD: RandomForestSampler ----> sim exec elapsed time: 3.5s ----> min loss new params: 331.47 ----> avg loss new params: 683.43 ----> avg loss exist params: 1447.83 ----> curr min loss: 331.4650895275124 ====> total elapsed time: 4.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 3.6s ----> min loss new params: 315.78 ----> avg loss new params: 675.06 ----> avg loss exist params: 1383.44 ----> curr min loss: 315.7767534283539 ====> total elapsed time: 3.6s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 2.9s ----> min loss new params: 745.54 ----> avg loss new params: 1471.68 ----> avg loss exist params: 1390.22 ----> curr min loss: 315.7767534283539 ====> total elapsed time: 2.9s METHOD: RandomForestSampler ----> sim exec elapsed time: 2.5s ----> min loss new params: 943.59 ----> avg loss new params: 1157.78 ----> avg loss exist params: 1373.62 ----> curr min loss: 315.7767534283539 ====> total elapsed time: 3.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 4.7s ----> min loss new params: 498.19 ----> avg loss new params: 574.39 ----> avg loss exist params: 1320.34 ----> curr min loss: 315.7767534283539 ====> total elapsed time: 4.7s Checkpoint saved in 0.0s # best parameters obtained so far params [ 0 ] array([0.088, 0.136]) # index of the best fitting series idxmin = np . argmin ( cal . losses_samp ) Compare the synthetic and calibrated series plotSeries ( \"Synthetic vs calibrated series\" , synth_data , cal . series_samp [ idxmin , 0 ]) var element = $('#a1e256f3-053f-41e5-a705-76f6504bd47d'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); } Calibration of a more advanced SIR model against realistic data In this part of the tutorial we will use black-it to find the parameters of a SIR model fitted on the italian Covid-19 epidemiological data. We will see that a proper modelling of the first wave of the epidemic requires the introduction of a structural break in the SIR simulator i.e., a specific point in time in which an abrupt change in the parameters occurs. This is useful to model the effect of the lockdown over the spreading of the epidemic. Load reference data For didactic puposes, let's load a previously prepared dataset containing a very rough estimate of the SIR data for the first 20 weeks of the italian Covid-19 epidemic. As the official data underestimates the number of cases, Susceptible and Recovered were rescaled by a constant factor. real_data = np . loadtxt ( \"data/italy_20_weeks.txt\" ) # plot the real time series we want to reproduce plotSeries ( \"Real data\" , real_data ) var element = $('#9cc5b778-f8ed-45f7-9449-ebf27ad43e37'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); } Initialize a calibrator object 1. Model simulator from models.sir.sir_docker import SIR_w_breaks 2. Loss function # we'll use a quadratic loss, a simple squared difference bewteen the two series loss = MinkowskiLoss () 3. Samplers sampler_batch_size = 16 samplers = [ HaltonSampler ( batch_size = sampler_batch_size ), RandomForestSampler ( batch_size = sampler_batch_size ), BestBatchSampler ( batch_size = sampler_batch_size ), ] 4. Parameter space (bounds and precision) # brktime, beta1, beta2, gamma bounds_w_breaks = [ [ 2 , 0.1 , 0 , 0.1 ], [ 7 , 0.2 , 0.1 , 0.3 ], ] precisions_w_breaks = [ 1 , 0.0005 , 0.0005 , 0.0005 ] Initialize the Calibrator saving_folder = \"output\" # initialize the Calibrator cal = Calibrator ( samplers = samplers , real_data = real_data , model = SIR_w_breaks , parameters_bounds = bounds_w_breaks , parameters_precision = precisions_w_breaks , ensemble_size = 1 , loss_function = loss , saving_folder = saving_folder , ) *** Number of free params: 4. Explorable param space size: 97204806. *** Selecting 4 processes for the parallel evaluation of the model Calibration Perform 5 calibration rounds. Note that, with these parameters, you would be able to achieve a much lower loss in 30 epochs. params , losses = cal . calibrate ( 5 ) BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: HaltonSampler ----> sim exec elapsed time: 10.0s ----> min loss new params: 78.97 ----> avg loss new params: 127.93 ----> avg loss exist params: 127.93 ----> curr min loss: 78.96522708183643 ====> total elapsed time: 10.0s METHOD: RandomForestSampler ----> sim exec elapsed time: 12.5s ----> min loss new params: 69.4 ----> avg loss new params: 95.8 ----> avg loss exist params: 111.87 ----> curr min loss: 69.39561568592492 ====> total elapsed time: 14.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 12.9s ----> min loss new params: 67.18 ----> avg loss new params: 90.8 ----> avg loss exist params: 104.85 ----> curr min loss: 67.1802120840003 ====> total elapsed time: 12.9s Checkpoint saved in 0.0s BATCH NUMBER: 2 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 15.2s ----> min loss new params: 58.32 ----> avg loss new params: 122.98 ----> avg loss exist params: 109.38 ----> curr min loss: 58.32156435411211 ====> total elapsed time: 15.2s METHOD: RandomForestSampler ----> sim exec elapsed time: 10.4s ----> min loss new params: 57.7 ----> avg loss new params: 85.93 ----> avg loss exist params: 104.69 ----> curr min loss: 57.70356830875495 ====> total elapsed time: 12.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 11.2s ----> min loss new params: 58.89 ----> avg loss new params: 86.32 ----> avg loss exist params: 101.63 ----> curr min loss: 57.70356830875495 ====> total elapsed time: 11.2s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 96 METHOD: HaltonSampler ----> sim exec elapsed time: 13.0s ----> min loss new params: 64.77 ----> avg loss new params: 113.03 ----> avg loss exist params: 103.26 ----> curr min loss: 57.70356830875495 ====> total elapsed time: 13.0s METHOD: RandomForestSampler ----> sim exec elapsed time: 11.7s ----> min loss new params: 42.16 ----> avg loss new params: 69.24 ----> avg loss exist params: 99.01 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 14.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 9.3s ----> min loss new params: 47.7 ----> avg loss new params: 80.67 ----> avg loss exist params: 96.97 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 9.3s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 144 METHOD: HaltonSampler ----> sim exec elapsed time: 8.6s ----> min loss new params: 78.91 ----> avg loss new params: 131.24 ----> avg loss exist params: 100.4 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 8.6s METHOD: RandomForestSampler ----> sim exec elapsed time: 8.2s ----> min loss new params: 50.61 ----> avg loss new params: 69.1 ----> avg loss exist params: 97.55 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 9.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 15.5s ----> min loss new params: 42.16 ----> avg loss new params: 82.51 ----> avg loss exist params: 96.3 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 15.5s Checkpoint saved in 0.1s BATCH NUMBER: 5 PARAMS SAMPLED: 192 METHOD: HaltonSampler ----> sim exec elapsed time: 10.6s ----> min loss new params: 77.07 ----> avg loss new params: 124.54 ----> avg loss exist params: 98.47 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 10.7s METHOD: RandomForestSampler ----> sim exec elapsed time: 10.5s ----> min loss new params: 53.1 ----> avg loss new params: 65.98 ----> avg loss exist params: 96.15 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 12.4s METHOD: BestBatchSampler ----> sim exec elapsed time: 7.7s ----> min loss new params: 41.11 ----> avg loss new params: 72.03 ----> avg loss exist params: 94.54 ----> curr min loss: 41.11389045820134 ====> total elapsed time: 7.7s Checkpoint saved in 0.1s # best parameters obtained so far printBestParams ( params ) brktime beta1 beta2 gamma Best parameters: [7.000 0.175 0.036 0.234 ] Compare the original and the calibrated time series idxmin = np . argmin ( cal . losses_samp ) plotSeries ( \"real vs calibrated\" , real_data , cal . series_samp [ idxmin , 0 ]) var element = $('#83ce087e-39b1-446f-a71f-0c38c68c9a0f'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); } Plots plot_sampling ( saving_folder ) var element = $('#fa5a3df7-3984-4e80-b21a-dfe6db4755c4'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); } plot_sampling_interact ( saving_folder ) interactive(children=(Dropdown(description='batch_nums', options={'from 0 to 1': [0, 1], 'from 2 to 3': [2, 3]\u2026 plot_losses ( saving_folder ) var element = $('#e482cbed-b2a5-4e90-9877-f94941bac33b'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); } plot_losses_interact ( saving_folder ) interactive(children=(Dropdown(description='method_num', options={'HaltonSampler': 0, 'RandomForestSampler': 1\u2026 plot_convergence ( saving_folder ) var element = $('#e533c418-ec8f-4c59-9a70-5af89e41e640'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); }","title":"SIR model"},{"location":"finding_the_parameters_of_a_SIR_model/#finding-the-parameters-of-a-sir-model","text":"","title":"Finding the parameters of a SIR model"},{"location":"finding_the_parameters_of_a_SIR_model/#basic-elements-of-a-sir-model","text":"In our model, each agent transitions among 3 states: Susceptible , Infectious and Recovered . At each epoch, an Infectious agent has a probability \u03b2 of infecting its Susceptible neighbours, and a probability \u03b3 to transition to the Recovered state. From that moment on, it will no longer participate in the spreading of the disease. The connectivity between agents is modeled as a Watts-Strogatz small world random graph, a regular ring lattice of mean degree K where each node has a probability r of being randomly rewired. In our model, these parameters will be input-calibrated (i.e., fixed). # preparatory imports import numpy as np import matplotlib.pyplot as plt import matplotlib from black_it.calibrator import Calibrator from black_it.loss_functions.minkowski import MinkowskiLoss from black_it.plot.plot_results import ( plot_convergence , plot_losses , plot_losses_interact , plot_sampling , plot_sampling_interact , ) from black_it.samplers.best_batch import BestBatchSampler from black_it.samplers.halton import HaltonSampler from black_it.samplers.random_forest import RandomForestSampler cmap = matplotlib . cm . get_cmap ( \"tab10\" ) . colors def plotSeries ( title , SIR1 , SIR2 = None ): fig , ax1 = plt . subplots () ax1 . plot ( SIR1 [:, 0 ], \"-\" , label = \"susceptible\" , color = cmap [ 0 ]) ax1 . plot ( SIR1 [:, 1 ], \"-\" , label = \"infected\" , color = cmap [ 1 ]) ax1 . plot ( SIR1 [:, 2 ], \"-\" , label = \"recovered\" , color = cmap [ 2 ]) ax1 . tick_params ( axis = \"y\" , labelcolor = cmap [ 0 ]) ax1 . set_ylabel ( \"susceptible per 1000 inhabitants\" , color = cmap [ 0 ]) ax1 . set_xlabel ( \"weeks\" ) ax1 . legend ( loc = 5 ) if SIR2 is not None : ax1 . plot ( SIR2 [:, 0 ], \"--\" , label = \"susceptible\" , color = cmap [ 0 ]) ax1 . plot ( SIR2 [:, 1 ], \"--\" , label = \"infected\" , color = cmap [ 1 ]) ax1 . plot ( SIR2 [:, 2 ], \"--\" , label = \"recovered\" , color = cmap [ 2 ]) ax1 . title . set_text ( title ) fig . tight_layout () plt . show () def printBestParams ( params ): with np . printoptions ( suppress = True , formatter = { \"float_kind\" : \" {:.3f} \" . format }): print ( f \" brktime beta1 beta2 gamma\" ) print ( f \"Best parameters: { params [ 0 ] } \" )","title":"Basic elements of a SIR model"},{"location":"finding_the_parameters_of_a_SIR_model/#simple-calibration-over-synthetic-data","text":"Let's start by using black-it to recover the \\beta \\beta and \\gamma \\gamma parameter of a SIR model from synthetic data.","title":"Simple calibration over synthetic data"},{"location":"finding_the_parameters_of_a_SIR_model/#initialize-a-calibrator-object","text":"To set up a calibration one needs to define the following components first: a model to be calibrated a loss function to measure the distance between the real time series and the simulated time series a set of samplers that iteratively suggest a set of parameter values to explore the parameter space that should be explored","title":"Initialize a calibrator object"},{"location":"finding_the_parameters_of_a_SIR_model/#1-model-simulator","text":"In order to use the SIR simulator, we need to download its docker image: Install Docker following the instructions given here Open Docker on your computer Run the following command in your terminal: docker pull bancaditalia/abmsimulator We can then proceed to generate the data we are going to try to reproduce via calibration. from models.sir.sir_docker import SIR true_params = [ 0.1 , 0.1 ] # in general not known! synth_data = SIR ( true_params , 50 , 0 ) plotSeries ( \"Synthetic data\" , synth_data ) var element = $('#32d7b93f-9d74-4d29-ae08-2edcce331bba'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); }","title":"1. Model simulator"},{"location":"finding_the_parameters_of_a_SIR_model/#2-loss-function","text":"# import a quadratic loss, a simple squared difference bewteen the two series from black_it.loss_functions.minkowski import MinkowskiLoss loss = MinkowskiLoss ()","title":"2. Loss function"},{"location":"finding_the_parameters_of_a_SIR_model/#3-samplers","text":"from black_it.samplers.best_batch import BestBatchSampler from black_it.samplers.halton import HaltonSampler from black_it.samplers.random_forest import RandomForestSampler batch_size = 4 halton_sampler = HaltonSampler ( batch_size = batch_size ) random_forest_sampler = RandomForestSampler ( batch_size = batch_size ) best_batch_sampler = BestBatchSampler ( batch_size = batch_size ) samplers = [ halton_sampler , random_forest_sampler , best_batch_sampler ]","title":"3. Samplers"},{"location":"finding_the_parameters_of_a_SIR_model/#4-parameter-space-bounds-and-precision","text":"bounds = [[ 0.001 , 0.001 ], [ 1.00 , 1.00 ]] precisions = [ 0.001 , 0.001 ]","title":"4. Parameter space (bounds and precision)"},{"location":"finding_the_parameters_of_a_SIR_model/#finally-initialize-the-calibrator","text":"from black_it.calibrator import Calibrator saving_folder = 'sir-test' # initialize a Calibrator object cal = Calibrator ( samplers = samplers , real_data = synth_data , model = SIR , parameters_bounds = bounds , parameters_precision = precisions , ensemble_size = 1 , loss_function = loss , saving_folder = saving_folder , ) *** Number of free params: 2. Explorable param space size: 1000000. *** Selecting 4 processes for the parallel evaluation of the model","title":"Finally, initialize the Calibrator"},{"location":"finding_the_parameters_of_a_SIR_model/#calibration","text":"Calibrate the model for five batches params , losses = cal . calibrate ( 5 ) BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: HaltonSampler ----> sim exec elapsed time: 3.1s ----> min loss new params: 1093.27 ----> avg loss new params: 1387.94 ----> avg loss exist params: 1387.94 ----> curr min loss: 1093.2679706997856 ====> total elapsed time: 3.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 2.6s ----> min loss new params: 994.25 ----> avg loss new params: 1401.16 ----> avg loss exist params: 1394.55 ----> curr min loss: 994.2479459016207 ====> total elapsed time: 3.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 3.1s ----> min loss new params: 1091.99 ----> avg loss new params: 1218.39 ----> avg loss exist params: 1335.83 ----> curr min loss: 994.2479459016207 ====> total elapsed time: 3.1s Checkpoint saved in 0.0s BATCH NUMBER: 2 PARAMS SAMPLED: 12 METHOD: HaltonSampler ----> sim exec elapsed time: 7.1s ----> min loss new params: 1401.9 ----> avg loss new params: 2014.58 ----> avg loss exist params: 1505.52 ----> curr min loss: 994.2479459016207 ====> total elapsed time: 7.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 4.9s ----> min loss new params: 1413.63 ----> avg loss new params: 2200.89 ----> avg loss exist params: 1644.59 ----> curr min loss: 994.2479459016207 ====> total elapsed time: 6.2s METHOD: BestBatchSampler ----> sim exec elapsed time: 4.7s ----> min loss new params: 1084.36 ----> avg loss new params: 1109.2 ----> avg loss exist params: 1555.36 ----> curr min loss: 994.2479459016207 ====> total elapsed time: 4.7s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 24 METHOD: HaltonSampler ----> sim exec elapsed time: 4.4s ----> min loss new params: 880.29 ----> avg loss new params: 1508.88 ----> avg loss exist params: 1548.72 ----> curr min loss: 880.2915915967067 ====> total elapsed time: 4.4s METHOD: RandomForestSampler ----> sim exec elapsed time: 3.5s ----> min loss new params: 850.56 ----> avg loss new params: 1041.11 ----> avg loss exist params: 1485.27 ----> curr min loss: 850.5637796224285 ====> total elapsed time: 4.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 6.4s ----> min loss new params: 881.79 ----> avg loss new params: 934.11 ----> avg loss exist params: 1424.03 ----> curr min loss: 850.5637796224285 ====> total elapsed time: 6.5s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 36 METHOD: HaltonSampler ----> sim exec elapsed time: 4.0s ----> min loss new params: 1670.77 ----> avg loss new params: 2426.46 ----> avg loss exist params: 1524.27 ----> curr min loss: 850.5637796224285 ====> total elapsed time: 4.0s METHOD: RandomForestSampler ----> sim exec elapsed time: 3.5s ----> min loss new params: 331.47 ----> avg loss new params: 683.43 ----> avg loss exist params: 1447.83 ----> curr min loss: 331.4650895275124 ====> total elapsed time: 4.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 3.6s ----> min loss new params: 315.78 ----> avg loss new params: 675.06 ----> avg loss exist params: 1383.44 ----> curr min loss: 315.7767534283539 ====> total elapsed time: 3.6s Checkpoint saved in 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 2.9s ----> min loss new params: 745.54 ----> avg loss new params: 1471.68 ----> avg loss exist params: 1390.22 ----> curr min loss: 315.7767534283539 ====> total elapsed time: 2.9s METHOD: RandomForestSampler ----> sim exec elapsed time: 2.5s ----> min loss new params: 943.59 ----> avg loss new params: 1157.78 ----> avg loss exist params: 1373.62 ----> curr min loss: 315.7767534283539 ====> total elapsed time: 3.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 4.7s ----> min loss new params: 498.19 ----> avg loss new params: 574.39 ----> avg loss exist params: 1320.34 ----> curr min loss: 315.7767534283539 ====> total elapsed time: 4.7s Checkpoint saved in 0.0s # best parameters obtained so far params [ 0 ] array([0.088, 0.136]) # index of the best fitting series idxmin = np . argmin ( cal . losses_samp )","title":"Calibration"},{"location":"finding_the_parameters_of_a_SIR_model/#compare-the-synthetic-and-calibrated-series","text":"plotSeries ( \"Synthetic vs calibrated series\" , synth_data , cal . series_samp [ idxmin , 0 ]) var element = $('#a1e256f3-053f-41e5-a705-76f6504bd47d'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); }","title":"Compare the synthetic and calibrated series"},{"location":"finding_the_parameters_of_a_SIR_model/#calibration-of-a-more-advanced-sir-model-against-realistic-data","text":"In this part of the tutorial we will use black-it to find the parameters of a SIR model fitted on the italian Covid-19 epidemiological data. We will see that a proper modelling of the first wave of the epidemic requires the introduction of a structural break in the SIR simulator i.e., a specific point in time in which an abrupt change in the parameters occurs. This is useful to model the effect of the lockdown over the spreading of the epidemic.","title":"Calibration of a more advanced SIR model against realistic data"},{"location":"finding_the_parameters_of_a_SIR_model/#load-reference-data","text":"For didactic puposes, let's load a previously prepared dataset containing a very rough estimate of the SIR data for the first 20 weeks of the italian Covid-19 epidemic. As the official data underestimates the number of cases, Susceptible and Recovered were rescaled by a constant factor. real_data = np . loadtxt ( \"data/italy_20_weeks.txt\" ) # plot the real time series we want to reproduce plotSeries ( \"Real data\" , real_data ) var element = $('#9cc5b778-f8ed-45f7-9449-ebf27ad43e37'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); }","title":"Load reference data"},{"location":"finding_the_parameters_of_a_SIR_model/#initialize-a-calibrator-object_1","text":"","title":"Initialize a calibrator object"},{"location":"finding_the_parameters_of_a_SIR_model/#1-model-simulator_1","text":"from models.sir.sir_docker import SIR_w_breaks","title":"1. Model simulator"},{"location":"finding_the_parameters_of_a_SIR_model/#2-loss-function_1","text":"# we'll use a quadratic loss, a simple squared difference bewteen the two series loss = MinkowskiLoss ()","title":"2. Loss function"},{"location":"finding_the_parameters_of_a_SIR_model/#3-samplers_1","text":"sampler_batch_size = 16 samplers = [ HaltonSampler ( batch_size = sampler_batch_size ), RandomForestSampler ( batch_size = sampler_batch_size ), BestBatchSampler ( batch_size = sampler_batch_size ), ]","title":"3. Samplers"},{"location":"finding_the_parameters_of_a_SIR_model/#4-parameter-space-bounds-and-precision_1","text":"# brktime, beta1, beta2, gamma bounds_w_breaks = [ [ 2 , 0.1 , 0 , 0.1 ], [ 7 , 0.2 , 0.1 , 0.3 ], ] precisions_w_breaks = [ 1 , 0.0005 , 0.0005 , 0.0005 ]","title":"4. Parameter space (bounds and precision)"},{"location":"finding_the_parameters_of_a_SIR_model/#initialize-the-calibrator","text":"saving_folder = \"output\" # initialize the Calibrator cal = Calibrator ( samplers = samplers , real_data = real_data , model = SIR_w_breaks , parameters_bounds = bounds_w_breaks , parameters_precision = precisions_w_breaks , ensemble_size = 1 , loss_function = loss , saving_folder = saving_folder , ) *** Number of free params: 4. Explorable param space size: 97204806. *** Selecting 4 processes for the parallel evaluation of the model","title":"Initialize the Calibrator"},{"location":"finding_the_parameters_of_a_SIR_model/#calibration_1","text":"Perform 5 calibration rounds. Note that, with these parameters, you would be able to achieve a much lower loss in 30 epochs. params , losses = cal . calibrate ( 5 ) BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: HaltonSampler ----> sim exec elapsed time: 10.0s ----> min loss new params: 78.97 ----> avg loss new params: 127.93 ----> avg loss exist params: 127.93 ----> curr min loss: 78.96522708183643 ====> total elapsed time: 10.0s METHOD: RandomForestSampler ----> sim exec elapsed time: 12.5s ----> min loss new params: 69.4 ----> avg loss new params: 95.8 ----> avg loss exist params: 111.87 ----> curr min loss: 69.39561568592492 ====> total elapsed time: 14.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 12.9s ----> min loss new params: 67.18 ----> avg loss new params: 90.8 ----> avg loss exist params: 104.85 ----> curr min loss: 67.1802120840003 ====> total elapsed time: 12.9s Checkpoint saved in 0.0s BATCH NUMBER: 2 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 15.2s ----> min loss new params: 58.32 ----> avg loss new params: 122.98 ----> avg loss exist params: 109.38 ----> curr min loss: 58.32156435411211 ====> total elapsed time: 15.2s METHOD: RandomForestSampler ----> sim exec elapsed time: 10.4s ----> min loss new params: 57.7 ----> avg loss new params: 85.93 ----> avg loss exist params: 104.69 ----> curr min loss: 57.70356830875495 ====> total elapsed time: 12.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 11.2s ----> min loss new params: 58.89 ----> avg loss new params: 86.32 ----> avg loss exist params: 101.63 ----> curr min loss: 57.70356830875495 ====> total elapsed time: 11.2s Checkpoint saved in 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 96 METHOD: HaltonSampler ----> sim exec elapsed time: 13.0s ----> min loss new params: 64.77 ----> avg loss new params: 113.03 ----> avg loss exist params: 103.26 ----> curr min loss: 57.70356830875495 ====> total elapsed time: 13.0s METHOD: RandomForestSampler ----> sim exec elapsed time: 11.7s ----> min loss new params: 42.16 ----> avg loss new params: 69.24 ----> avg loss exist params: 99.01 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 14.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 9.3s ----> min loss new params: 47.7 ----> avg loss new params: 80.67 ----> avg loss exist params: 96.97 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 9.3s Checkpoint saved in 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 144 METHOD: HaltonSampler ----> sim exec elapsed time: 8.6s ----> min loss new params: 78.91 ----> avg loss new params: 131.24 ----> avg loss exist params: 100.4 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 8.6s METHOD: RandomForestSampler ----> sim exec elapsed time: 8.2s ----> min loss new params: 50.61 ----> avg loss new params: 69.1 ----> avg loss exist params: 97.55 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 9.5s METHOD: BestBatchSampler ----> sim exec elapsed time: 15.5s ----> min loss new params: 42.16 ----> avg loss new params: 82.51 ----> avg loss exist params: 96.3 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 15.5s Checkpoint saved in 0.1s BATCH NUMBER: 5 PARAMS SAMPLED: 192 METHOD: HaltonSampler ----> sim exec elapsed time: 10.6s ----> min loss new params: 77.07 ----> avg loss new params: 124.54 ----> avg loss exist params: 98.47 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 10.7s METHOD: RandomForestSampler ----> sim exec elapsed time: 10.5s ----> min loss new params: 53.1 ----> avg loss new params: 65.98 ----> avg loss exist params: 96.15 ----> curr min loss: 42.162915251802474 ====> total elapsed time: 12.4s METHOD: BestBatchSampler ----> sim exec elapsed time: 7.7s ----> min loss new params: 41.11 ----> avg loss new params: 72.03 ----> avg loss exist params: 94.54 ----> curr min loss: 41.11389045820134 ====> total elapsed time: 7.7s Checkpoint saved in 0.1s # best parameters obtained so far printBestParams ( params ) brktime beta1 beta2 gamma Best parameters: [7.000 0.175 0.036 0.234 ]","title":"Calibration"},{"location":"finding_the_parameters_of_a_SIR_model/#compare-the-original-and-the-calibrated-time-series","text":"idxmin = np . argmin ( cal . losses_samp ) plotSeries ( \"real vs calibrated\" , real_data , cal . series_samp [ idxmin , 0 ]) var element = $('#83ce087e-39b1-446f-a71f-0c38c68c9a0f'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); }","title":"Compare the original and the calibrated time series"},{"location":"finding_the_parameters_of_a_SIR_model/#plots","text":"plot_sampling ( saving_folder ) var element = $('#fa5a3df7-3984-4e80-b21a-dfe6db4755c4'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); } plot_sampling_interact ( saving_folder ) interactive(children=(Dropdown(description='batch_nums', options={'from 0 to 1': [0, 1], 'from 2 to 3': [2, 3]\u2026 plot_losses ( saving_folder ) var element = $('#e482cbed-b2a5-4e90-9877-f94941bac33b'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); } plot_losses_interact ( saving_folder ) interactive(children=(Dropdown(description='method_num', options={'HaltonSampler': 0, 'RandomForestSampler': 1\u2026 plot_convergence ( saving_folder ) var element = $('#e533c418-ec8f-4c59-9a70-5af89e41e640'); /* Put everything inside the global mpl namespace */ /* global mpl */ window.mpl = {}; mpl.get_websocket_type = function () { if (typeof WebSocket !== 'undefined') { return WebSocket; } else if (typeof MozWebSocket !== 'undefined') { return MozWebSocket; } else { alert( 'Your browser does not have WebSocket support. ' + 'Please try Chrome, Safari or Firefox \u2265 6. ' + 'Firefox 4 and 5 are also supported but you ' + 'have to enable WebSockets in about:config.' ); } }; mpl.figure = function (figure_id, websocket, ondownload, parent_element) { this.id = figure_id; this.ws = websocket; this.supports_binary = this.ws.binaryType !== undefined; if (!this.supports_binary) { var warnings = document.getElementById('mpl-warnings'); if (warnings) { warnings.style.display = 'block'; warnings.textContent = 'This browser does not support binary websocket messages. ' + 'Performance may be slow.'; } } this.imageObj = new Image(); this.context = undefined; this.message = undefined; this.canvas = undefined; this.rubberband_canvas = undefined; this.rubberband_context = undefined; this.format_dropdown = undefined; this.image_mode = 'full'; this.root = document.createElement('div'); this.root.setAttribute('style', 'display: inline-block'); this._root_extra_style(this.root); parent_element.appendChild(this.root); this._init_header(this); this._init_canvas(this); this._init_toolbar(this); var fig = this; this.waiting = false; this.ws.onopen = function () { fig.send_message('supports_binary', { value: fig.supports_binary }); fig.send_message('send_image_mode', {}); if (fig.ratio !== 1) { fig.send_message('set_device_pixel_ratio', { device_pixel_ratio: fig.ratio, }); } fig.send_message('refresh', {}); }; this.imageObj.onload = function () { if (fig.image_mode === 'full') { // Full images could contain transparency (where diff images // almost always do), so we need to clear the canvas so that // there is no ghosting. fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height); } fig.context.drawImage(fig.imageObj, 0, 0); }; this.imageObj.onunload = function () { fig.ws.close(); }; this.ws.onmessage = this._make_on_message_function(this); this.ondownload = ondownload; }; mpl.figure.prototype._init_header = function () { var titlebar = document.createElement('div'); titlebar.classList = 'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix'; var titletext = document.createElement('div'); titletext.classList = 'ui-dialog-title'; titletext.setAttribute( 'style', 'width: 100%; text-align: center; padding: 3px;' ); titlebar.appendChild(titletext); this.root.appendChild(titlebar); this.header = titletext; }; mpl.figure.prototype._canvas_extra_style = function (_canvas_div) {}; mpl.figure.prototype._root_extra_style = function (_canvas_div) {}; mpl.figure.prototype._init_canvas = function () { var fig = this; var canvas_div = (this.canvas_div = document.createElement('div')); canvas_div.setAttribute( 'style', 'border: 1px solid #ddd;' + 'box-sizing: content-box;' + 'clear: both;' + 'min-height: 1px;' + 'min-width: 1px;' + 'outline: 0;' + 'overflow: hidden;' + 'position: relative;' + 'resize: both;' ); function on_keyboard_event_closure(name) { return function (event) { return fig.key_event(event, name); }; } canvas_div.addEventListener( 'keydown', on_keyboard_event_closure('key_press') ); canvas_div.addEventListener( 'keyup', on_keyboard_event_closure('key_release') ); this._canvas_extra_style(canvas_div); this.root.appendChild(canvas_div); var canvas = (this.canvas = document.createElement('canvas')); canvas.classList.add('mpl-canvas'); canvas.setAttribute('style', 'box-sizing: content-box;'); this.context = canvas.getContext('2d'); var backingStore = this.context.backingStorePixelRatio || this.context.webkitBackingStorePixelRatio || this.context.mozBackingStorePixelRatio || this.context.msBackingStorePixelRatio || this.context.oBackingStorePixelRatio || this.context.backingStorePixelRatio || 1; this.ratio = (window.devicePixelRatio || 1) / backingStore; var rubberband_canvas = (this.rubberband_canvas = document.createElement( 'canvas' )); rubberband_canvas.setAttribute( 'style', 'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;' ); // Apply a ponyfill if ResizeObserver is not implemented by browser. if (this.ResizeObserver === undefined) { if (window.ResizeObserver !== undefined) { this.ResizeObserver = window.ResizeObserver; } else { var obs = _JSXTOOLS_RESIZE_OBSERVER({}); this.ResizeObserver = obs.ResizeObserver; } } this.resizeObserverInstance = new this.ResizeObserver(function (entries) { var nentries = entries.length; for (var i = 0; i < nentries; i++) { var entry = entries[i]; var width, height; if (entry.contentBoxSize) { if (entry.contentBoxSize instanceof Array) { // Chrome 84 implements new version of spec. width = entry.contentBoxSize[0].inlineSize; height = entry.contentBoxSize[0].blockSize; } else { // Firefox implements old version of spec. width = entry.contentBoxSize.inlineSize; height = entry.contentBoxSize.blockSize; } } else { // Chrome <84 implements even older version of spec. width = entry.contentRect.width; height = entry.contentRect.height; } // Keep the size of the canvas and rubber band canvas in sync with // the canvas container. if (entry.devicePixelContentBoxSize) { // Chrome 84 implements new version of spec. canvas.setAttribute( 'width', entry.devicePixelContentBoxSize[0].inlineSize ); canvas.setAttribute( 'height', entry.devicePixelContentBoxSize[0].blockSize ); } else { canvas.setAttribute('width', width * fig.ratio); canvas.setAttribute('height', height * fig.ratio); } canvas.setAttribute( 'style', 'width: ' + width + 'px; height: ' + height + 'px;' ); rubberband_canvas.setAttribute('width', width); rubberband_canvas.setAttribute('height', height); // And update the size in Python. We ignore the initial 0/0 size // that occurs as the element is placed into the DOM, which should // otherwise not happen due to the minimum size styling. if (fig.ws.readyState == 1 && width != 0 && height != 0) { fig.request_resize(width, height); } } }); this.resizeObserverInstance.observe(canvas_div); function on_mouse_event_closure(name) { return function (event) { return fig.mouse_event(event, name); }; } rubberband_canvas.addEventListener( 'mousedown', on_mouse_event_closure('button_press') ); rubberband_canvas.addEventListener( 'mouseup', on_mouse_event_closure('button_release') ); rubberband_canvas.addEventListener( 'dblclick', on_mouse_event_closure('dblclick') ); // Throttle sequential mouse events to 1 every 20ms. rubberband_canvas.addEventListener( 'mousemove', on_mouse_event_closure('motion_notify') ); rubberband_canvas.addEventListener( 'mouseenter', on_mouse_event_closure('figure_enter') ); rubberband_canvas.addEventListener( 'mouseleave', on_mouse_event_closure('figure_leave') ); canvas_div.addEventListener('wheel', function (event) { if (event.deltaY < 0) { event.step = 1; } else { event.step = -1; } on_mouse_event_closure('scroll')(event); }); canvas_div.appendChild(canvas); canvas_div.appendChild(rubberband_canvas); this.rubberband_context = rubberband_canvas.getContext('2d'); this.rubberband_context.strokeStyle = '#000000'; this._resize_canvas = function (width, height, forward) { if (forward) { canvas_div.style.width = width + 'px'; canvas_div.style.height = height + 'px'; } }; // Disable right mouse context menu. this.rubberband_canvas.addEventListener('contextmenu', function (_e) { event.preventDefault(); return false; }); function set_focus() { canvas.focus(); canvas_div.focus(); } window.setTimeout(set_focus, 100); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'mpl-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'mpl-button-group'; continue; } var button = (fig.buttons[name] = document.createElement('button')); button.classList = 'mpl-widget'; button.setAttribute('role', 'button'); button.setAttribute('aria-disabled', 'false'); button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); var icon_img = document.createElement('img'); icon_img.src = '_images/' + image + '.png'; icon_img.srcset = '_images/' + image + '_large.png 2x'; icon_img.alt = tooltip; button.appendChild(icon_img); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } var fmt_picker = document.createElement('select'); fmt_picker.classList = 'mpl-widget'; toolbar.appendChild(fmt_picker); this.format_dropdown = fmt_picker; for (var ind in mpl.extensions) { var fmt = mpl.extensions[ind]; var option = document.createElement('option'); option.selected = fmt === mpl.default_extension; option.innerHTML = fmt; fmt_picker.appendChild(option); } var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message'; toolbar.appendChild(status_bar); this.message = status_bar; }; mpl.figure.prototype.request_resize = function (x_pixels, y_pixels) { // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client, // which will in turn request a refresh of the image. this.send_message('resize', { width: x_pixels, height: y_pixels }); }; mpl.figure.prototype.send_message = function (type, properties) { properties['type'] = type; properties['figure_id'] = this.id; this.ws.send(JSON.stringify(properties)); }; mpl.figure.prototype.send_draw_message = function () { if (!this.waiting) { this.waiting = true; this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id })); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { var format_dropdown = fig.format_dropdown; var format = format_dropdown.options[format_dropdown.selectedIndex].value; fig.ondownload(fig, format); }; mpl.figure.prototype.handle_resize = function (fig, msg) { var size = msg['size']; if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) { fig._resize_canvas(size[0], size[1], msg['forward']); fig.send_message('refresh', {}); } }; mpl.figure.prototype.handle_rubberband = function (fig, msg) { var x0 = msg['x0'] / fig.ratio; var y0 = (fig.canvas.height - msg['y0']) / fig.ratio; var x1 = msg['x1'] / fig.ratio; var y1 = (fig.canvas.height - msg['y1']) / fig.ratio; x0 = Math.floor(x0) + 0.5; y0 = Math.floor(y0) + 0.5; x1 = Math.floor(x1) + 0.5; y1 = Math.floor(y1) + 0.5; var min_x = Math.min(x0, x1); var min_y = Math.min(y0, y1); var width = Math.abs(x1 - x0); var height = Math.abs(y1 - y0); fig.rubberband_context.clearRect( 0, 0, fig.canvas.width / fig.ratio, fig.canvas.height / fig.ratio ); fig.rubberband_context.strokeRect(min_x, min_y, width, height); }; mpl.figure.prototype.handle_figure_label = function (fig, msg) { // Updates the figure title. fig.header.textContent = msg['label']; }; mpl.figure.prototype.handle_cursor = function (fig, msg) { fig.rubberband_canvas.style.cursor = msg['cursor']; }; mpl.figure.prototype.handle_message = function (fig, msg) { fig.message.textContent = msg['message']; }; mpl.figure.prototype.handle_draw = function (fig, _msg) { // Request the server to send over a new figure. fig.send_draw_message(); }; mpl.figure.prototype.handle_image_mode = function (fig, msg) { fig.image_mode = msg['mode']; }; mpl.figure.prototype.handle_history_buttons = function (fig, msg) { for (var key in msg) { if (!(key in fig.buttons)) { continue; } fig.buttons[key].disabled = !msg[key]; fig.buttons[key].setAttribute('aria-disabled', !msg[key]); } }; mpl.figure.prototype.handle_navigate_mode = function (fig, msg) { if (msg['mode'] === 'PAN') { fig.buttons['Pan'].classList.add('active'); fig.buttons['Zoom'].classList.remove('active'); } else if (msg['mode'] === 'ZOOM') { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.add('active'); } else { fig.buttons['Pan'].classList.remove('active'); fig.buttons['Zoom'].classList.remove('active'); } }; mpl.figure.prototype.updated_canvas_event = function () { // Called whenever the canvas gets updated. this.send_message('ack', {}); }; // A function to construct a web socket function for onmessage handling. // Called in the figure constructor. mpl.figure.prototype._make_on_message_function = function (fig) { return function socket_on_message(evt) { if (evt.data instanceof Blob) { var img = evt.data; if (img.type !== 'image/png') { /* FIXME: We get \"Resource interpreted as Image but * transferred with MIME type text/plain:\" errors on * Chrome. But how to set the MIME type? It doesn't seem * to be part of the websocket stream */ img.type = 'image/png'; } /* Free the memory for the previous frames */ if (fig.imageObj.src) { (window.URL || window.webkitURL).revokeObjectURL( fig.imageObj.src ); } fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL( img ); fig.updated_canvas_event(); fig.waiting = false; return; } else if ( typeof evt.data === 'string' && evt.data.slice(0, 21) === 'data:image/png;base64' ) { fig.imageObj.src = evt.data; fig.updated_canvas_event(); fig.waiting = false; return; } var msg = JSON.parse(evt.data); var msg_type = msg['type']; // Call the \"handle_{type}\" callback, which takes // the figure and JSON message as its only arguments. try { var callback = fig['handle_' + msg_type]; } catch (e) { console.log( \"No handler for the '\" + msg_type + \"' message type: \", msg ); return; } if (callback) { try { // console.log(\"Handling '\" + msg_type + \"' message: \", msg); callback(fig, msg); } catch (e) { console.log( \"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg ); } } }; }; // from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas mpl.findpos = function (e) { //this section is from http://www.quirksmode.org/js/events_properties.html var targ; if (!e) { e = window.event; } if (e.target) { targ = e.target; } else if (e.srcElement) { targ = e.srcElement; } if (targ.nodeType === 3) { // defeat Safari bug targ = targ.parentNode; } // pageX,Y are the mouse positions relative to the document var boundingRect = targ.getBoundingClientRect(); var x = e.pageX - (boundingRect.left + document.body.scrollLeft); var y = e.pageY - (boundingRect.top + document.body.scrollTop); return { x: x, y: y }; }; /* * return a copy of an object with only non-object keys * we need this to avoid circular references * https://stackoverflow.com/a/24161582/3208463 */ function simpleKeys(original) { return Object.keys(original).reduce(function (obj, key) { if (typeof original[key] !== 'object') { obj[key] = original[key]; } return obj; }, {}); } mpl.figure.prototype.mouse_event = function (event, name) { var canvas_pos = mpl.findpos(event); if (name === 'button_press') { this.canvas.focus(); this.canvas_div.focus(); } var x = canvas_pos.x * this.ratio; var y = canvas_pos.y * this.ratio; this.send_message(name, { x: x, y: y, button: event.button, step: event.step, guiEvent: simpleKeys(event), }); /* This prevents the web browser from automatically changing to * the text insertion cursor when the button is pressed. We want * to control all of the cursor setting manually through the * 'cursor' event from matplotlib */ event.preventDefault(); return false; }; mpl.figure.prototype._key_event_extra = function (_event, _name) { // Handle any extra behaviour associated with a key event }; mpl.figure.prototype.key_event = function (event, name) { // Prevent repeat events if (name === 'key_press') { if (event.key === this._key) { return; } else { this._key = event.key; } } if (name === 'key_release') { this._key = null; } var value = ''; if (event.ctrlKey && event.key !== 'Control') { value += 'ctrl+'; } else if (event.altKey && event.key !== 'Alt') { value += 'alt+'; } else if (event.shiftKey && event.key !== 'Shift') { value += 'shift+'; } value += 'k' + event.key; this._key_event_extra(event, name); this.send_message(name, { key: value, guiEvent: simpleKeys(event) }); return false; }; mpl.figure.prototype.toolbar_button_onclick = function (name) { if (name === 'download') { this.handle_save(this, null); } else { this.send_message('toolbar_button', { name: name }); } }; mpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) { this.message.textContent = tooltip; }; ///////////////// REMAINING CONTENT GENERATED BY embed_js.py ///////////////// // prettier-ignore var _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]]; mpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"]; mpl.default_extension = \"png\";/* global mpl */ var comm_websocket_adapter = function (comm) { // Create a \"websocket\"-like object which calls the given IPython comm // object with the appropriate methods. Currently this is a non binary // socket, so there is still some room for performance tuning. var ws = {}; ws.binaryType = comm.kernel.ws.binaryType; ws.readyState = comm.kernel.ws.readyState; function updateReadyState(_event) { if (comm.kernel.ws) { ws.readyState = comm.kernel.ws.readyState; } else { ws.readyState = 3; // Closed state. } } comm.kernel.ws.addEventListener('open', updateReadyState); comm.kernel.ws.addEventListener('close', updateReadyState); comm.kernel.ws.addEventListener('error', updateReadyState); ws.close = function () { comm.close(); }; ws.send = function (m) { //console.log('sending', m); comm.send(m); }; // Register the callback with on_msg. comm.on_msg(function (msg) { //console.log('receiving', msg['content']['data'], msg); var data = msg['content']['data']; if (data['blob'] !== undefined) { data = { data: new Blob(msg['buffers'], { type: data['blob'] }), }; } // Pass the mpl event to the overridden (by mpl) onmessage function. ws.onmessage(data); }); return ws; }; mpl.mpl_figure_comm = function (comm, msg) { // This is the function which gets called when the mpl process // starts-up an IPython Comm through the \"matplotlib\" channel. var id = msg.content.data.id; // Get hold of the div created by the display call when the Comm // socket was opened in Python. var element = document.getElementById(id); var ws_proxy = comm_websocket_adapter(comm); function ondownload(figure, _format) { window.open(figure.canvas.toDataURL()); } var fig = new mpl.figure(id, ws_proxy, ondownload, element); // Call onopen now - mpl needs it, as it is assuming we've passed it a real // web socket which is closed, not our websocket->open comm proxy. ws_proxy.onopen(); fig.parent_element = element; fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\"); if (!fig.cell_info) { console.error('Failed to find cell for figure', id, fig); return; } fig.cell_info[0].output_area.element.on( 'cleared', { fig: fig }, fig._remove_fig_handler ); }; mpl.figure.prototype.handle_close = function (fig, msg) { var width = fig.canvas.width / fig.ratio; fig.cell_info[0].output_area.element.off( 'cleared', fig._remove_fig_handler ); fig.resizeObserverInstance.unobserve(fig.canvas_div); // Update the output cell to use the data from the current canvas. fig.push_to_output(); var dataURL = fig.canvas.toDataURL(); // Re-enable the keyboard manager in IPython - without this line, in FF, // the notebook keyboard shortcuts fail. IPython.keyboard_manager.enable(); fig.parent_element.innerHTML = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; fig.close_ws(fig, msg); }; mpl.figure.prototype.close_ws = function (fig, msg) { fig.send_message('closing', msg); // fig.ws.close() }; mpl.figure.prototype.push_to_output = function (_remove_interactive) { // Turn the data on the canvas into data in the output cell. var width = this.canvas.width / this.ratio; var dataURL = this.canvas.toDataURL(); this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">'; }; mpl.figure.prototype.updated_canvas_event = function () { // Tell IPython that the notebook contents must change. IPython.notebook.set_dirty(true); this.send_message('ack', {}); var fig = this; // Wait a second, then push the new image to the DOM so // that it is saved nicely (might be nice to debounce this). setTimeout(function () { fig.push_to_output(); }, 1000); }; mpl.figure.prototype._init_toolbar = function () { var fig = this; var toolbar = document.createElement('div'); toolbar.classList = 'btn-toolbar'; this.root.appendChild(toolbar); function on_click_closure(name) { return function (_event) { return fig.toolbar_button_onclick(name); }; } function on_mouseover_closure(tooltip) { return function (event) { if (!event.currentTarget.disabled) { return fig.toolbar_button_onmouseover(tooltip); } }; } fig.buttons = {}; var buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; var button; for (var toolbar_ind in mpl.toolbar_items) { var name = mpl.toolbar_items[toolbar_ind][0]; var tooltip = mpl.toolbar_items[toolbar_ind][1]; var image = mpl.toolbar_items[toolbar_ind][2]; var method_name = mpl.toolbar_items[toolbar_ind][3]; if (!name) { /* Instead of a spacer, we start a new button group. */ if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } buttonGroup = document.createElement('div'); buttonGroup.classList = 'btn-group'; continue; } button = fig.buttons[name] = document.createElement('button'); button.classList = 'btn btn-default'; button.href = '#'; button.title = name; button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>'; button.addEventListener('click', on_click_closure(method_name)); button.addEventListener('mouseover', on_mouseover_closure(tooltip)); buttonGroup.appendChild(button); } if (buttonGroup.hasChildNodes()) { toolbar.appendChild(buttonGroup); } // Add the status bar. var status_bar = document.createElement('span'); status_bar.classList = 'mpl-message pull-right'; toolbar.appendChild(status_bar); this.message = status_bar; // Add the close button to the window. var buttongrp = document.createElement('div'); buttongrp.classList = 'btn-group inline pull-right'; button = document.createElement('button'); button.classList = 'btn btn-mini btn-primary'; button.href = '#'; button.title = 'Stop Interaction'; button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>'; button.addEventListener('click', function (_evt) { fig.handle_close(fig, {}); }); button.addEventListener( 'mouseover', on_mouseover_closure('Stop Interaction') ); buttongrp.appendChild(button); var titlebar = this.root.querySelector('.ui-dialog-titlebar'); titlebar.insertBefore(buttongrp, titlebar.firstChild); }; mpl.figure.prototype._remove_fig_handler = function (event) { var fig = event.data.fig; if (event.target !== this) { // Ignore bubbled events from children. return; } fig.close_ws(fig, {}); }; mpl.figure.prototype._root_extra_style = function (el) { el.style.boxSizing = 'content-box'; // override notebook setting of border-box. }; mpl.figure.prototype._canvas_extra_style = function (el) { // this is important to make the div 'focusable el.setAttribute('tabindex', 0); // reach out to IPython and tell the keyboard manager to turn it's self // off when our div gets focus // location in version 3 if (IPython.notebook.keyboard_manager) { IPython.notebook.keyboard_manager.register_events(el); } else { // location in version 2 IPython.keyboard_manager.register_events(el); } }; mpl.figure.prototype._key_event_extra = function (event, _name) { // Check for shift+enter if (event.shiftKey && event.which === 13) { this.canvas_div.blur(); // select the cell after this one var index = IPython.notebook.find_cell_index(this.cell_info[0]); IPython.notebook.select(index + 1); } }; mpl.figure.prototype.handle_save = function (fig, _msg) { fig.ondownload(fig, null); }; mpl.find_output_cell = function (html_output) { // Return the cell and output element which can be found *uniquely* in the notebook. // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\" // IPython event is triggered only after the cells have been serialised, which for // our purposes (turning an active figure into a static one), is too late. var cells = IPython.notebook.get_cells(); var ncells = cells.length; for (var i = 0; i < ncells; i++) { var cell = cells[i]; if (cell.cell_type === 'code') { for (var j = 0; j < cell.output_area.outputs.length; j++) { var data = cell.output_area.outputs[j]; if (data.data) { // IPython >= 3 moved mimebundle to data attribute of output data = data.data; } if (data['text/html'] === html_output) { return [cell, data, j]; } } } } }; // Register the function which deals with the matplotlib target/channel. // The kernel may be null if the page has been refreshed. if (IPython.notebook.kernel !== null) { IPython.notebook.kernel.comm_manager.register_target( 'matplotlib', mpl.mpl_figure_comm ); }","title":"Plots"},{"location":"losses/","text":"black_it.loss_functions.base.BaseLoss ( ABC ) BaseLoss interface. Source code in black_it/loss_functions/base.py class BaseLoss ( ABC ): \"\"\"BaseLoss interface.\"\"\" def __init__ ( self , coordinate_weights : Optional [ NDArray ] = None ): \"\"\" Initialize the loss function. Args: coordinate_weights: the weights of the loss coordinates. \"\"\" self . coordinate_weights = coordinate_weights def compute_loss ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Compute the loss between simulated and real data. Args: sim_data_ensemble: an ensemble of simulated data, of shape (ensemble_size, N, D) real_data: the real data, of shape (N, D) Returns: The loss value. \"\"\" num_coords = real_data . shape [ 1 ] if self . coordinate_weights is None : weights = np . ones ( num_coords ) / num_coords else : nb_coordinate_weights = len ( self . coordinate_weights ) assert_ ( nb_coordinate_weights == num_coords , ( \"the length of coordinate_weights should be equal \" f \"to the number of coordinates, got { nb_coordinate_weights } and { num_coords } \" ), exc_cls = ValueError , ) weights = self . coordinate_weights loss = 0 for i in range ( num_coords ): loss += ( self . compute_loss_1d ( sim_data_ensemble [:, :, i ], real_data [:, i ]) * weights [ i ] ) return loss @abstractmethod def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Return the loss between a specific coordinate of two time series. Concrete classes have to override this method in order to implement new loss functions. Args: sim_data_ensemble: an ensemble of simulated 1D series, shape (ensemble_size, N, 1) real_data: the real data, shape (N, 1) Returns: the computed loss over the specific coordinate \"\"\" __init__ ( self , coordinate_weights = None ) special Initialize the loss function. Parameters: Name Type Description Default coordinate_weights Optional[numpy.ndarray] the weights of the loss coordinates. None Source code in black_it/loss_functions/base.py def __init__ ( self , coordinate_weights : Optional [ NDArray ] = None ): \"\"\" Initialize the loss function. Args: coordinate_weights: the weights of the loss coordinates. \"\"\" self . coordinate_weights = coordinate_weights compute_loss ( self , sim_data_ensemble , real_data ) Compute the loss between simulated and real data. Parameters: Name Type Description Default sim_data_ensemble ndarray an ensemble of simulated data, of shape (ensemble_size, N, D) required real_data ndarray the real data, of shape (N, D) required Returns: Type Description float The loss value. Source code in black_it/loss_functions/base.py def compute_loss ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Compute the loss between simulated and real data. Args: sim_data_ensemble: an ensemble of simulated data, of shape (ensemble_size, N, D) real_data: the real data, of shape (N, D) Returns: The loss value. \"\"\" num_coords = real_data . shape [ 1 ] if self . coordinate_weights is None : weights = np . ones ( num_coords ) / num_coords else : nb_coordinate_weights = len ( self . coordinate_weights ) assert_ ( nb_coordinate_weights == num_coords , ( \"the length of coordinate_weights should be equal \" f \"to the number of coordinates, got { nb_coordinate_weights } and { num_coords } \" ), exc_cls = ValueError , ) weights = self . coordinate_weights loss = 0 for i in range ( num_coords ): loss += ( self . compute_loss_1d ( sim_data_ensemble [:, :, i ], real_data [:, i ]) * weights [ i ] ) return loss compute_loss_1d ( self , sim_data_ensemble , real_data ) Return the loss between a specific coordinate of two time series. Concrete classes have to override this method in order to implement new loss functions. Parameters: Name Type Description Default sim_data_ensemble ndarray an ensemble of simulated 1D series, shape (ensemble_size, N, 1) required real_data ndarray the real data, shape (N, 1) required Returns: Type Description float the computed loss over the specific coordinate Source code in black_it/loss_functions/base.py @abstractmethod def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Return the loss between a specific coordinate of two time series. Concrete classes have to override this method in order to implement new loss functions. Args: sim_data_ensemble: an ensemble of simulated 1D series, shape (ensemble_size, N, 1) real_data: the real data, shape (N, 1) Returns: the computed loss over the specific coordinate \"\"\" black_it.loss_functions.fourier This module contains the implementation of the Fast Fourier Transform loss. FrequencyFilter A filter that receives the signal in the frequency domain and returns its filtered version. Used by FourierLoss constructor. In this version, the filter supports a single parameter: no multi-band filtering is supported yet. FourierLoss ( BaseLoss ) Class for the Fourier loss. Source code in black_it/loss_functions/fourier.py class FourierLoss ( BaseLoss ): \"\"\"Class for the Fourier loss.\"\"\" def __init__ ( self , frequency_filter : FrequencyFilter = gaussian_low_pass_filter , f : float = 0.8 , coordinate_weights : Optional [ NDArray ] = None , ) -> None : \"\"\"Loss computed using a distance in the Fourier space of the time series. This loss is equivalent to the Euclidean loss computed on the time series after a Fourier-filter. The parameter f controls the fraction of frequencies that are kept in the Fourier series. Args: frequency_filter: the function used to filter the fourier frequencies before the distance is computed. f: fraction of fourier components to keep when computing the distance between the time series. This parameter will be passed to frequency_filter. coordinate_weights: relative weights of the losses computed over different time series coordinates. \"\"\" assert_ ( 0.0 < f <= 1.0 , \"'f' must be in the interval (0.0, 1.0]\" , ) self . frequency_filter = frequency_filter self . f = f super () . __init__ ( coordinate_weights ) def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\"Compute Euclidean distance between the Fourier transform of the two time series. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: The computed loss over the specific coordinate. \"\"\" f_real_data = np . fft . rfft ( real_data , axis = 0 ) N = f_real_data . shape [ 0 ] f_real_data = self . frequency_filter ( f_real_data , self . f ) # computer mean fft transform of simulated ensemble f_sim_data = [] for s in sim_data_ensemble : f_sim_data_ = np . fft . rfft ( s , axis = 0 ) f_sim_data_ = self . frequency_filter ( f_sim_data_ , self . f ) f_sim_data . append ( f_sim_data_ ) f_sim_data = np . array ( f_sim_data ) . mean ( 0 ) loss_1d = np . sqrt ( np . sum (( abs ( f_sim_data - f_real_data )) ** 2 ) / N ) return loss_1d __init__ ( self , frequency_filter =< function gaussian_low_pass_filter at 0x7f8153eaa700 > , f = 0.8 , coordinate_weights = None ) special Loss computed using a distance in the Fourier space of the time series. This loss is equivalent to the Euclidean loss computed on the time series after a Fourier-filter. The parameter f controls the fraction of frequencies that are kept in the Fourier series. Parameters: Name Type Description Default frequency_filter Callable[[numpy.ndarray, float], numpy.ndarray] the function used to filter the fourier frequencies before the distance is computed. <function gaussian_low_pass_filter at 0x7f8153eaa700> f float fraction of fourier components to keep when computing the distance between the time series. This parameter will be passed to frequency_filter. 0.8 coordinate_weights Optional[numpy.ndarray] relative weights of the losses computed over different time series coordinates. None Source code in black_it/loss_functions/fourier.py def __init__ ( self , frequency_filter : FrequencyFilter = gaussian_low_pass_filter , f : float = 0.8 , coordinate_weights : Optional [ NDArray ] = None , ) -> None : \"\"\"Loss computed using a distance in the Fourier space of the time series. This loss is equivalent to the Euclidean loss computed on the time series after a Fourier-filter. The parameter f controls the fraction of frequencies that are kept in the Fourier series. Args: frequency_filter: the function used to filter the fourier frequencies before the distance is computed. f: fraction of fourier components to keep when computing the distance between the time series. This parameter will be passed to frequency_filter. coordinate_weights: relative weights of the losses computed over different time series coordinates. \"\"\" assert_ ( 0.0 < f <= 1.0 , \"'f' must be in the interval (0.0, 1.0]\" , ) self . frequency_filter = frequency_filter self . f = f super () . __init__ ( coordinate_weights ) compute_loss_1d ( self , sim_data_ensemble , real_data ) Compute Euclidean distance between the Fourier transform of the two time series. Parameters: Name Type Description Default sim_data_ensemble ndarray the first operand required real_data ndarray the second operand required Returns: Type Description float The computed loss over the specific coordinate. Source code in black_it/loss_functions/fourier.py def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\"Compute Euclidean distance between the Fourier transform of the two time series. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: The computed loss over the specific coordinate. \"\"\" f_real_data = np . fft . rfft ( real_data , axis = 0 ) N = f_real_data . shape [ 0 ] f_real_data = self . frequency_filter ( f_real_data , self . f ) # computer mean fft transform of simulated ensemble f_sim_data = [] for s in sim_data_ensemble : f_sim_data_ = np . fft . rfft ( s , axis = 0 ) f_sim_data_ = self . frequency_filter ( f_sim_data_ , self . f ) f_sim_data . append ( f_sim_data_ ) f_sim_data = np . array ( f_sim_data ) . mean ( 0 ) loss_1d = np . sqrt ( np . sum (( abs ( f_sim_data - f_real_data )) ** 2 ) / N ) return loss_1d gaussian_low_pass_filter ( signal_frequencies , f ) Gaussian low-pass filter. Parameters: Name Type Description Default signal_frequencies ndarray the input signal transformed in the frequency domain. required f float the fraction of frequencies to keep, this will determine the length scale of the Gaussian filter required Returns: Type Description ndarray the filtered frequencies Source code in black_it/loss_functions/fourier.py def gaussian_low_pass_filter ( signal_frequencies : NDArray [ np . complex128 ], f : float , ) -> NDArray [ np . complex128 ]: \"\"\"Gaussian low-pass filter. Args: signal_frequencies: the input signal transformed in the frequency domain. f: the fraction of frequencies to keep, this will determine the length scale of the Gaussian filter Returns: the filtered frequencies \"\"\" # number of low-frequency component to keep sigma = np . round ( f * signal_frequencies . shape [ 0 ]) # gaussian low-pass filter mask = np . exp ( - np . arange ( signal_frequencies . shape [ 0 ]) ** 2 / ( 2 * sigma ** 2 )) filtered_frequencies = signal_frequencies * mask return filtered_frequencies ideal_low_pass_filter ( signal_frequencies , f ) Ideal low-pass filter. Parameters: Name Type Description Default signal_frequencies ndarray the input signal transformed in the frequency domain. required f float the fraction of frequencies to keep unchanged, for f=1 the filter is just the identity. required Returns: Type Description ndarray the filtered frequencies Source code in black_it/loss_functions/fourier.py def ideal_low_pass_filter ( signal_frequencies : NDArray [ np . complex128 ], f : float , ) -> NDArray [ np . complex128 ]: \"\"\"Ideal low-pass filter. Args: signal_frequencies: the input signal transformed in the frequency domain. f: the fraction of frequencies to keep unchanged, for f=1 the filter is just the identity. Returns: the filtered frequencies \"\"\" # number of low-frequency component to keep n = int ( np . round ( f * signal_frequencies . shape [ 0 ])) # ideal low-pass filter mask = np . zeros ( signal_frequencies . shape [ 0 ]) mask [: n ] = 1.0 filtered_frequencies = signal_frequencies * mask return filtered_frequencies black_it.loss_functions.minkowski.MinkowskiLoss ( BaseLoss ) Class for the Minkowski loss. Source code in black_it/loss_functions/minkowski.py class MinkowskiLoss ( BaseLoss ): \"\"\"Class for the Minkowski loss.\"\"\" def __init__ ( self , p : int = 2 , coordinate_weights : Optional [ NDArray ] = None ) -> None : \"\"\" Loss computed using a Minkowski distance. The [Minkowski distance](https://en.wikipedia.org/wiki/Minkowski_distance) is a generalization of both the Manhattan distance (p=1) and the Euclidean distance (p=2). This function computes the Minkowski distance between two series. Note: this class is a wrapper of scipy.spatial.distance.minkowski Args: p: The order of the norm used to compute the distance between real and simulated series coordinate_weights: The order of the norm used to compute the distance between real and simulated series \"\"\" self . p = p super () . __init__ ( coordinate_weights ) def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Call scipy.spatial.distance.minkowski() on its arguments. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: The computed loss over the specific coordinate. \"\"\" # average simulated time series sim_data_ensemble = sim_data_ensemble . mean ( axis = 0 ) loss_1d = minkowski ( sim_data_ensemble , real_data , p = self . p ) return loss_1d __init__ ( self , p = 2 , coordinate_weights = None ) special Loss computed using a Minkowski distance. The Minkowski distance is a generalization of both the Manhattan distance (p=1) and the Euclidean distance (p=2). This function computes the Minkowski distance between two series. Note: this class is a wrapper of scipy.spatial.distance.minkowski Parameters: Name Type Description Default p int The order of the norm used to compute the distance between real and simulated series 2 coordinate_weights Optional[numpy.ndarray] The order of the norm used to compute the distance between real and simulated series None Source code in black_it/loss_functions/minkowski.py def __init__ ( self , p : int = 2 , coordinate_weights : Optional [ NDArray ] = None ) -> None : \"\"\" Loss computed using a Minkowski distance. The [Minkowski distance](https://en.wikipedia.org/wiki/Minkowski_distance) is a generalization of both the Manhattan distance (p=1) and the Euclidean distance (p=2). This function computes the Minkowski distance between two series. Note: this class is a wrapper of scipy.spatial.distance.minkowski Args: p: The order of the norm used to compute the distance between real and simulated series coordinate_weights: The order of the norm used to compute the distance between real and simulated series \"\"\" self . p = p super () . __init__ ( coordinate_weights ) compute_loss_1d ( self , sim_data_ensemble , real_data ) Call scipy.spatial.distance.minkowski() on its arguments. Parameters: Name Type Description Default sim_data_ensemble ndarray the first operand required real_data ndarray the second operand required Returns: Type Description float The computed loss over the specific coordinate. Source code in black_it/loss_functions/minkowski.py def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Call scipy.spatial.distance.minkowski() on its arguments. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: The computed loss over the specific coordinate. \"\"\" # average simulated time series sim_data_ensemble = sim_data_ensemble . mean ( axis = 0 ) loss_1d = minkowski ( sim_data_ensemble , real_data , p = self . p ) return loss_1d black_it.loss_functions.msm.MethodOfMomentsLoss ( BaseLoss ) Class for the 'method of moments' loss. Source code in black_it/loss_functions/msm.py class MethodOfMomentsLoss ( BaseLoss ): \"\"\"Class for the 'method of moments' loss.\"\"\" def __init__ ( self , covariance_mat : Optional [ NDArray [ np . float64 ]] = None , coordinate_weights : Optional [ NDArray [ np . float64 ]] = None , moment_calculator : MomentCalculator = get_mom_ts_1d , ): \"\"\" Initialize the loss function based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. By default the loss computes the moments using black_it.utils.time_series.get_mom_ts_1d(), which computes an 18-dimensional vector of statistics. You can alter the behaviour passing a custom function to moment_calculator. Please note that there is a constraint between the moment calculator and the size of the covariance matrix. Args: covariance_mat: covariance matrix between the moments. The default is the identity matrix. The covariance matrix must be a symmetric matrix whose size must be equal to the number of elements that the moment calculator returns. coordinate_weights: importance of each coordinate. By default all coordinates are treated equally. moment_calculator: a function that takes a 1D time series and returns a series of moments. The default is black_it.utils.time_series.get_mom_ts_1d() \"\"\" MethodOfMomentsLoss . _validate_covariance_and_calculator ( moment_calculator , covariance_mat ) super () . __init__ ( coordinate_weights ) self . _covariance_mat = covariance_mat self . _moment_calculator = moment_calculator @staticmethod def _validate_covariance_and_calculator ( moment_calculator : MomentCalculator , covariance_mat : Optional [ NDArray [ np . float64 ]] = None , ) -> None : \"\"\" Validate the covariance matrix. Args: moment_calculator: the moment calculator covariance_mat: the covariance matrix, or None Returns: None Raises: ValueError: if the covariance matrix is not valid. It can be invalid if it is not symmetric or if moment_calculator is the default get_mom_ts_1d and the covariance matrix's shape is not 18. Other possible errors won't be caught by this function, and can only be detected at runtime. \"\"\" if covariance_mat is None : # if we were given no covariance matrix, then we'll use a default # one, and we can't do any further validation (without executing the # moment_calculator) return # a non null covariance_mat was given if not is_symmetric ( covariance_mat ): raise ValueError ( \"the provided covariance matrix is not valid as it is not a symmetric matrix\" ) if ( moment_calculator is get_mom_ts_1d ) and ( covariance_mat . shape [ 0 ] != 18 ): raise ValueError ( \"the provided covariance matrix is not valid as it has a wrong shape: \" f \"expected 18, got { covariance_mat . shape [ 0 ] } \" ) def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Compute the loss based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: the MSM loss over a specific coordinate. \"\"\" # compute the moments for the simulated ensemble ensemble_real_mom_1d = np . array ( [ self . _moment_calculator ( s ) for s in sim_data_ensemble ] ) # compute moments of the real time series sim_mom_1d = self . _moment_calculator ( real_data ) g = ( sim_mom_1d [ None , :] - ensemble_real_mom_1d ) . mean ( axis = 0 ) if self . _covariance_mat is None : loss_1d = g . dot ( g ) return loss_1d W = self . _covariance_mat try : loss_1d = g . dot ( W ) . dot ( g ) except ValueError as e : covariance_size = W . shape [ 0 ] moments_size = g . shape [ 0 ] if covariance_size == moments_size : # this value error is not due to a mismatch between the # covariance matrix size and the number moments. Let's raise the # original error. raise raise ValueError ( f \"The size of the covariance matrix ( { covariance_size } ) \" f \"and the number of moments ( { moments_size } ) should be identical\" ) from e return loss_1d __init__ ( self , covariance_mat = None , coordinate_weights = None , moment_calculator =< function get_mom_ts_1d at 0x7f8154460280 > ) special Initialize the loss function based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. By default the loss computes the moments using black_it.utils.time_series.get_mom_ts_1d(), which computes an 18-dimensional vector of statistics. You can alter the behaviour passing a custom function to moment_calculator. Please note that there is a constraint between the moment calculator and the size of the covariance matrix. Parameters: Name Type Description Default covariance_mat Optional[numpy.ndarray] covariance matrix between the moments. The default is the identity matrix. The covariance matrix must be a symmetric matrix whose size must be equal to the number of elements that the moment calculator returns. None coordinate_weights Optional[numpy.ndarray] importance of each coordinate. By default all coordinates are treated equally. None moment_calculator Callable[[numpy.ndarray], numpy.ndarray] a function that takes a 1D time series and returns a series of moments. The default is black_it.utils.time_series.get_mom_ts_1d() <function get_mom_ts_1d at 0x7f8154460280> Source code in black_it/loss_functions/msm.py def __init__ ( self , covariance_mat : Optional [ NDArray [ np . float64 ]] = None , coordinate_weights : Optional [ NDArray [ np . float64 ]] = None , moment_calculator : MomentCalculator = get_mom_ts_1d , ): \"\"\" Initialize the loss function based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. By default the loss computes the moments using black_it.utils.time_series.get_mom_ts_1d(), which computes an 18-dimensional vector of statistics. You can alter the behaviour passing a custom function to moment_calculator. Please note that there is a constraint between the moment calculator and the size of the covariance matrix. Args: covariance_mat: covariance matrix between the moments. The default is the identity matrix. The covariance matrix must be a symmetric matrix whose size must be equal to the number of elements that the moment calculator returns. coordinate_weights: importance of each coordinate. By default all coordinates are treated equally. moment_calculator: a function that takes a 1D time series and returns a series of moments. The default is black_it.utils.time_series.get_mom_ts_1d() \"\"\" MethodOfMomentsLoss . _validate_covariance_and_calculator ( moment_calculator , covariance_mat ) super () . __init__ ( coordinate_weights ) self . _covariance_mat = covariance_mat self . _moment_calculator = moment_calculator compute_loss_1d ( self , sim_data_ensemble , real_data ) Compute the loss based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. Parameters: Name Type Description Default sim_data_ensemble ndarray the first operand required real_data ndarray the second operand required Returns: Type Description float the MSM loss over a specific coordinate. Source code in black_it/loss_functions/msm.py def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Compute the loss based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: the MSM loss over a specific coordinate. \"\"\" # compute the moments for the simulated ensemble ensemble_real_mom_1d = np . array ( [ self . _moment_calculator ( s ) for s in sim_data_ensemble ] ) # compute moments of the real time series sim_mom_1d = self . _moment_calculator ( real_data ) g = ( sim_mom_1d [ None , :] - ensemble_real_mom_1d ) . mean ( axis = 0 ) if self . _covariance_mat is None : loss_1d = g . dot ( g ) return loss_1d W = self . _covariance_mat try : loss_1d = g . dot ( W ) . dot ( g ) except ValueError as e : covariance_size = W . shape [ 0 ] moments_size = g . shape [ 0 ] if covariance_size == moments_size : # this value error is not due to a mismatch between the # covariance matrix size and the number moments. Let's raise the # original error. raise raise ValueError ( f \"The size of the covariance matrix ( { covariance_size } ) \" f \"and the number of moments ( { moments_size } ) should be identical\" ) from e return loss_1d black_it.loss_functions.gsl_div.GslDivLoss ( BaseLoss ) Class for the Gsl-div loss. Examples: >>> expected_loss = 0.39737637181336855 >>> np . random . seed ( 11 ) >>> series1 = np . random . normal ( 0 , 1 , ( 100 , 3 )) >>> series2 = np . random . normal ( 0 , 1 , ( 100 , 3 )) >>> loss_func = GslDivLoss () >>> loss = loss_func . compute_loss ( series1 [ None , :, :], series2 ) >>> assert np . isclose ( expected_loss , loss ) Source code in black_it/loss_functions/gsl_div.py class GslDivLoss ( BaseLoss ): \"\"\" Class for the Gsl-div loss. Example: >>> expected_loss = 0.39737637181336855 >>> np.random.seed(11) >>> series1 = np.random.normal(0, 1, (100, 3)) >>> series2 = np.random.normal(0, 1, (100, 3)) >>> loss_func = GslDivLoss() >>> loss = loss_func.compute_loss(series1[None, :, :], series2) >>> assert np.isclose(expected_loss, loss) \"\"\" def __init__ ( self , nb_values : int = None , nb_word_lengths : int = None , coordinate_weights : Optional [ NDArray ] = None , ) -> None : \"\"\" Initialize the GSL-div loss object. Args: nb_values: number of values the digitised series can take nb_word_lengths: the number of word length to consider coordinate_weights: the weights of the loss coordinates \"\"\" super () . __init__ ( coordinate_weights ) self . nb_values = nb_values self . nb_word_lengths = nb_word_lengths def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Return the GSL-div measure. From (Lamperti, 2017): > The information loss about the behaviour of the stochastic process due to the symbolization becomes smaller and smaller as b increases. On the other side, low values of b would likely wash away processes\u2019 noise the modeller might not be interested in. Args: sim_data_ensemble: the ensemble of simulated data real_data: the real data Returns: the GSL loss \"\"\" N = len ( real_data ) ensemble_size = sim_data_ensemble . shape [ 0 ] if self . nb_values is None : nb_values = int (( N - 1 ) / 2.0 ) else : nb_values = self . nb_values if self . nb_word_lengths is None : nb_word_lengths = int (( N - 1 ) / 2.0 ) else : nb_word_lengths = self . nb_word_lengths # discretize real time series obs_xd = self . discretize ( real_data , nb_values , np . min ( real_data ), np . max ( real_data ), ) gsl_loss = 0.0 # average loss over the ensemble for sim_data in sim_data_ensemble : # discretize simulated series sim_xd = self . discretize ( sim_data , nb_values , np . min ( sim_data ), np . max ( sim_data ) ) loss = self . gsl_div_1d_1_sample ( sim_xd , obs_xd , nb_word_lengths , nb_values , N ) gsl_loss += loss return gsl_loss / ensemble_size def gsl_div_1d_1_sample ( self , sim_xd : NDArray , obs_xd : NDArray , nb_word_lengths : int , nb_values : int , N : int , ) -> float : \"\"\"Compute the GSL-div for a single realisation of the simulated data. Args: sim_xd: discretised simulated series obs_xd: discretised real series nb_word_lengths: the number of word length to consider nb_values: number of values the digitised series can take N: the length of real and simulated series Returns: the computed loss \"\"\" # outcome measure gsl_div = 0.0 # weight weight = 0.0 # for any word len: for word_length in range ( 1 , nb_word_lengths + 1 ): sim_xw = self . get_words ( sim_xd , word_length ) obs_xw = self . get_words ( obs_xd , word_length ) m_xw = np . concatenate (( sim_xw , obs_xw )) sim_xp = self . get_words_est_prob ( sim_xw ) m_xp = self . get_words_est_prob ( m_xw ) base = float ( nb_values ** word_length ) sim_entr = self . get_sh_entr ( sim_xp , base ) m_entr = self . get_sh_entr ( m_xp , base ) # update weight weight = weight + 2 / ( nb_word_lengths * ( nb_word_lengths + 1 )) # correction corr = (( len ( m_xp ) - 1 ) - ( len ( sim_xp ) - 1 )) / ( 2 * N ) # add to measure gsl_divl = 2 * m_entr - sim_entr + corr gsl_div = gsl_div + weight * gsl_divl # end of cycle, return return gsl_div @staticmethod def discretize ( time_series : NDArray [ np . float64 ], nb_values : int , start_index : float , stop_index : float , ) -> NDArray [ np . float64 ]: \"\"\" Discretize the TS in 'nb_values' finite states. >>> GslDivLoss.discretize( ... [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ... nb_values=3, ... start_index=1, ... stop_index=10 ... ) array([1, 1, 1, 2, 2, 2, 2, 3, 3, 3]) Args: time_series: any univariate time series nb_values: int, number of values the digitised series can take. It must be greater than 0. start_index: the starting point stop_index: the stopping point Returns: the discretised time series \"\"\" linspace = np . linspace ( start_index - EPS , stop_index + EPS , nb_values + 1 ) return np . searchsorted ( linspace , time_series , side = \"left\" ) @staticmethod def get_words ( time_series : NDArray [ np . float64 ], length : int ) -> NDArray : \"\"\" Return an overlapping array of words (int32) of 'length' given a discretised vector. >>> GslDivLoss.get_words(np.asarray([1, 2, 2, 2]), 2) array([12, 22, 22]) Args: time_series: any univariate discretised time series length: int, len of words to be returned. Must be such that (len(time_series) + 1 - length) is positive. Returns: the time series of overlapping words \"\"\" tswlen = len ( time_series ) + 1 - length assert_ ( tswlen >= 0 , \"the chosen word length is too high\" , exc_cls = ValueError ) tsw = np . zeros ( shape = ( tswlen ,), dtype = np . int32 ) for i in range ( length ): k = 10 ** ( length - i - 1 ) tsw = tsw + time_series [ i : tswlen + i ] * k return tsw @staticmethod def get_words_est_prob ( time_series : NDArray [ np . float64 ]) -> NDArray [ np . float64 ]: \"\"\" Return an array of estimated probabilities given an array of words (int32). Args: time_series: any univariate array of words Returns: estimate of probabilities \"\"\" _ , count = np . unique ( time_series , return_counts = True ) est_p = np . divide ( count , np . sum ( count )) return est_p @staticmethod def get_sh_entr ( probs : NDArray [ np . float64 ], log_base : float ) -> float : \"\"\" Return the Shannon entropy given an array of probabilities. Args: probs: an array of probabilities describing the discrete probability distribution log_base: the entropy logarithm base. Returns: the entropy of the discrete probability distribution \"\"\" log = np . log ( probs ) / np . log ( log_base ) return - np . sum ( np . multiply ( probs , log )) __init__ ( self , nb_values = None , nb_word_lengths = None , coordinate_weights = None ) special Initialize the GSL-div loss object. Parameters: Name Type Description Default nb_values int number of values the digitised series can take None nb_word_lengths int the number of word length to consider None coordinate_weights Optional[numpy.ndarray] the weights of the loss coordinates None Source code in black_it/loss_functions/gsl_div.py def __init__ ( self , nb_values : int = None , nb_word_lengths : int = None , coordinate_weights : Optional [ NDArray ] = None , ) -> None : \"\"\" Initialize the GSL-div loss object. Args: nb_values: number of values the digitised series can take nb_word_lengths: the number of word length to consider coordinate_weights: the weights of the loss coordinates \"\"\" super () . __init__ ( coordinate_weights ) self . nb_values = nb_values self . nb_word_lengths = nb_word_lengths compute_loss_1d ( self , sim_data_ensemble , real_data ) Return the GSL-div measure. From (Lamperti, 2017): The information loss about the behaviour of the stochastic process due to the symbolization becomes smaller and smaller as b increases. On the other side, low values of b would likely wash away processes\u2019 noise the modeller might not be interested in. Parameters: Name Type Description Default sim_data_ensemble ndarray the ensemble of simulated data required real_data ndarray the real data required Returns: Type Description float the GSL loss Source code in black_it/loss_functions/gsl_div.py def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Return the GSL-div measure. From (Lamperti, 2017): > The information loss about the behaviour of the stochastic process due to the symbolization becomes smaller and smaller as b increases. On the other side, low values of b would likely wash away processes\u2019 noise the modeller might not be interested in. Args: sim_data_ensemble: the ensemble of simulated data real_data: the real data Returns: the GSL loss \"\"\" N = len ( real_data ) ensemble_size = sim_data_ensemble . shape [ 0 ] if self . nb_values is None : nb_values = int (( N - 1 ) / 2.0 ) else : nb_values = self . nb_values if self . nb_word_lengths is None : nb_word_lengths = int (( N - 1 ) / 2.0 ) else : nb_word_lengths = self . nb_word_lengths # discretize real time series obs_xd = self . discretize ( real_data , nb_values , np . min ( real_data ), np . max ( real_data ), ) gsl_loss = 0.0 # average loss over the ensemble for sim_data in sim_data_ensemble : # discretize simulated series sim_xd = self . discretize ( sim_data , nb_values , np . min ( sim_data ), np . max ( sim_data ) ) loss = self . gsl_div_1d_1_sample ( sim_xd , obs_xd , nb_word_lengths , nb_values , N ) gsl_loss += loss return gsl_loss / ensemble_size discretize ( time_series , nb_values , start_index , stop_index ) staticmethod Discretize the TS in 'nb_values' finite states. GslDivLoss.discretize( ... [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ... nb_values=3, ... start_index=1, ... stop_index=10 ... ) array([1, 1, 1, 2, 2, 2, 2, 3, 3, 3]) Parameters: Name Type Description Default time_series ndarray any univariate time series required nb_values int int, number of values the digitised series can take. It must be greater than 0. required start_index float the starting point required stop_index float the stopping point required Returns: Type Description ndarray the discretised time series Source code in black_it/loss_functions/gsl_div.py @staticmethod def discretize ( time_series : NDArray [ np . float64 ], nb_values : int , start_index : float , stop_index : float , ) -> NDArray [ np . float64 ]: \"\"\" Discretize the TS in 'nb_values' finite states. >>> GslDivLoss.discretize( ... [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ... nb_values=3, ... start_index=1, ... stop_index=10 ... ) array([1, 1, 1, 2, 2, 2, 2, 3, 3, 3]) Args: time_series: any univariate time series nb_values: int, number of values the digitised series can take. It must be greater than 0. start_index: the starting point stop_index: the stopping point Returns: the discretised time series \"\"\" linspace = np . linspace ( start_index - EPS , stop_index + EPS , nb_values + 1 ) return np . searchsorted ( linspace , time_series , side = \"left\" ) get_sh_entr ( probs , log_base ) staticmethod Return the Shannon entropy given an array of probabilities. Parameters: Name Type Description Default probs ndarray an array of probabilities describing the discrete probability distribution required log_base float the entropy logarithm base. required Returns: Type Description float the entropy of the discrete probability distribution Source code in black_it/loss_functions/gsl_div.py @staticmethod def get_sh_entr ( probs : NDArray [ np . float64 ], log_base : float ) -> float : \"\"\" Return the Shannon entropy given an array of probabilities. Args: probs: an array of probabilities describing the discrete probability distribution log_base: the entropy logarithm base. Returns: the entropy of the discrete probability distribution \"\"\" log = np . log ( probs ) / np . log ( log_base ) return - np . sum ( np . multiply ( probs , log )) get_words ( time_series , length ) staticmethod Return an overlapping array of words (int32) of 'length' given a discretised vector. GslDivLoss.get_words(np.asarray([1, 2, 2, 2]), 2) array([12, 22, 22]) Parameters: Name Type Description Default time_series ndarray any univariate discretised time series required length int int, len of words to be returned. Must be such that (len(time_series) + 1 - length) is positive. required Returns: Type Description ndarray the time series of overlapping words Source code in black_it/loss_functions/gsl_div.py @staticmethod def get_words ( time_series : NDArray [ np . float64 ], length : int ) -> NDArray : \"\"\" Return an overlapping array of words (int32) of 'length' given a discretised vector. >>> GslDivLoss.get_words(np.asarray([1, 2, 2, 2]), 2) array([12, 22, 22]) Args: time_series: any univariate discretised time series length: int, len of words to be returned. Must be such that (len(time_series) + 1 - length) is positive. Returns: the time series of overlapping words \"\"\" tswlen = len ( time_series ) + 1 - length assert_ ( tswlen >= 0 , \"the chosen word length is too high\" , exc_cls = ValueError ) tsw = np . zeros ( shape = ( tswlen ,), dtype = np . int32 ) for i in range ( length ): k = 10 ** ( length - i - 1 ) tsw = tsw + time_series [ i : tswlen + i ] * k return tsw get_words_est_prob ( time_series ) staticmethod Return an array of estimated probabilities given an array of words (int32). Parameters: Name Type Description Default time_series ndarray any univariate array of words required Returns: Type Description ndarray estimate of probabilities Source code in black_it/loss_functions/gsl_div.py @staticmethod def get_words_est_prob ( time_series : NDArray [ np . float64 ]) -> NDArray [ np . float64 ]: \"\"\" Return an array of estimated probabilities given an array of words (int32). Args: time_series: any univariate array of words Returns: estimate of probabilities \"\"\" _ , count = np . unique ( time_series , return_counts = True ) est_p = np . divide ( count , np . sum ( count )) return est_p gsl_div_1d_1_sample ( self , sim_xd , obs_xd , nb_word_lengths , nb_values , N ) Compute the GSL-div for a single realisation of the simulated data. Parameters: Name Type Description Default sim_xd ndarray discretised simulated series required obs_xd ndarray discretised real series required nb_word_lengths int the number of word length to consider required nb_values int number of values the digitised series can take required N int the length of real and simulated series required Returns: Type Description float the computed loss Source code in black_it/loss_functions/gsl_div.py def gsl_div_1d_1_sample ( self , sim_xd : NDArray , obs_xd : NDArray , nb_word_lengths : int , nb_values : int , N : int , ) -> float : \"\"\"Compute the GSL-div for a single realisation of the simulated data. Args: sim_xd: discretised simulated series obs_xd: discretised real series nb_word_lengths: the number of word length to consider nb_values: number of values the digitised series can take N: the length of real and simulated series Returns: the computed loss \"\"\" # outcome measure gsl_div = 0.0 # weight weight = 0.0 # for any word len: for word_length in range ( 1 , nb_word_lengths + 1 ): sim_xw = self . get_words ( sim_xd , word_length ) obs_xw = self . get_words ( obs_xd , word_length ) m_xw = np . concatenate (( sim_xw , obs_xw )) sim_xp = self . get_words_est_prob ( sim_xw ) m_xp = self . get_words_est_prob ( m_xw ) base = float ( nb_values ** word_length ) sim_entr = self . get_sh_entr ( sim_xp , base ) m_entr = self . get_sh_entr ( m_xp , base ) # update weight weight = weight + 2 / ( nb_word_lengths * ( nb_word_lengths + 1 )) # correction corr = (( len ( m_xp ) - 1 ) - ( len ( sim_xp ) - 1 )) / ( 2 * N ) # add to measure gsl_divl = 2 * m_entr - sim_entr + corr gsl_div = gsl_div + weight * gsl_divl # end of cycle, return return gsl_div","title":"Loss functions"},{"location":"losses/#black_it.loss_functions.base.BaseLoss","text":"BaseLoss interface. Source code in black_it/loss_functions/base.py class BaseLoss ( ABC ): \"\"\"BaseLoss interface.\"\"\" def __init__ ( self , coordinate_weights : Optional [ NDArray ] = None ): \"\"\" Initialize the loss function. Args: coordinate_weights: the weights of the loss coordinates. \"\"\" self . coordinate_weights = coordinate_weights def compute_loss ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Compute the loss between simulated and real data. Args: sim_data_ensemble: an ensemble of simulated data, of shape (ensemble_size, N, D) real_data: the real data, of shape (N, D) Returns: The loss value. \"\"\" num_coords = real_data . shape [ 1 ] if self . coordinate_weights is None : weights = np . ones ( num_coords ) / num_coords else : nb_coordinate_weights = len ( self . coordinate_weights ) assert_ ( nb_coordinate_weights == num_coords , ( \"the length of coordinate_weights should be equal \" f \"to the number of coordinates, got { nb_coordinate_weights } and { num_coords } \" ), exc_cls = ValueError , ) weights = self . coordinate_weights loss = 0 for i in range ( num_coords ): loss += ( self . compute_loss_1d ( sim_data_ensemble [:, :, i ], real_data [:, i ]) * weights [ i ] ) return loss @abstractmethod def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Return the loss between a specific coordinate of two time series. Concrete classes have to override this method in order to implement new loss functions. Args: sim_data_ensemble: an ensemble of simulated 1D series, shape (ensemble_size, N, 1) real_data: the real data, shape (N, 1) Returns: the computed loss over the specific coordinate \"\"\"","title":"BaseLoss"},{"location":"losses/#black_it.loss_functions.base.BaseLoss.__init__","text":"Initialize the loss function. Parameters: Name Type Description Default coordinate_weights Optional[numpy.ndarray] the weights of the loss coordinates. None Source code in black_it/loss_functions/base.py def __init__ ( self , coordinate_weights : Optional [ NDArray ] = None ): \"\"\" Initialize the loss function. Args: coordinate_weights: the weights of the loss coordinates. \"\"\" self . coordinate_weights = coordinate_weights","title":"__init__()"},{"location":"losses/#black_it.loss_functions.base.BaseLoss.compute_loss","text":"Compute the loss between simulated and real data. Parameters: Name Type Description Default sim_data_ensemble ndarray an ensemble of simulated data, of shape (ensemble_size, N, D) required real_data ndarray the real data, of shape (N, D) required Returns: Type Description float The loss value. Source code in black_it/loss_functions/base.py def compute_loss ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Compute the loss between simulated and real data. Args: sim_data_ensemble: an ensemble of simulated data, of shape (ensemble_size, N, D) real_data: the real data, of shape (N, D) Returns: The loss value. \"\"\" num_coords = real_data . shape [ 1 ] if self . coordinate_weights is None : weights = np . ones ( num_coords ) / num_coords else : nb_coordinate_weights = len ( self . coordinate_weights ) assert_ ( nb_coordinate_weights == num_coords , ( \"the length of coordinate_weights should be equal \" f \"to the number of coordinates, got { nb_coordinate_weights } and { num_coords } \" ), exc_cls = ValueError , ) weights = self . coordinate_weights loss = 0 for i in range ( num_coords ): loss += ( self . compute_loss_1d ( sim_data_ensemble [:, :, i ], real_data [:, i ]) * weights [ i ] ) return loss","title":"compute_loss()"},{"location":"losses/#black_it.loss_functions.base.BaseLoss.compute_loss_1d","text":"Return the loss between a specific coordinate of two time series. Concrete classes have to override this method in order to implement new loss functions. Parameters: Name Type Description Default sim_data_ensemble ndarray an ensemble of simulated 1D series, shape (ensemble_size, N, 1) required real_data ndarray the real data, shape (N, 1) required Returns: Type Description float the computed loss over the specific coordinate Source code in black_it/loss_functions/base.py @abstractmethod def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Return the loss between a specific coordinate of two time series. Concrete classes have to override this method in order to implement new loss functions. Args: sim_data_ensemble: an ensemble of simulated 1D series, shape (ensemble_size, N, 1) real_data: the real data, shape (N, 1) Returns: the computed loss over the specific coordinate \"\"\"","title":"compute_loss_1d()"},{"location":"losses/#black_it.loss_functions.fourier","text":"This module contains the implementation of the Fast Fourier Transform loss.","title":"fourier"},{"location":"losses/#black_it.loss_functions.fourier.FrequencyFilter","text":"A filter that receives the signal in the frequency domain and returns its filtered version. Used by FourierLoss constructor. In this version, the filter supports a single parameter: no multi-band filtering is supported yet.","title":"FrequencyFilter"},{"location":"losses/#black_it.loss_functions.fourier.FourierLoss","text":"Class for the Fourier loss. Source code in black_it/loss_functions/fourier.py class FourierLoss ( BaseLoss ): \"\"\"Class for the Fourier loss.\"\"\" def __init__ ( self , frequency_filter : FrequencyFilter = gaussian_low_pass_filter , f : float = 0.8 , coordinate_weights : Optional [ NDArray ] = None , ) -> None : \"\"\"Loss computed using a distance in the Fourier space of the time series. This loss is equivalent to the Euclidean loss computed on the time series after a Fourier-filter. The parameter f controls the fraction of frequencies that are kept in the Fourier series. Args: frequency_filter: the function used to filter the fourier frequencies before the distance is computed. f: fraction of fourier components to keep when computing the distance between the time series. This parameter will be passed to frequency_filter. coordinate_weights: relative weights of the losses computed over different time series coordinates. \"\"\" assert_ ( 0.0 < f <= 1.0 , \"'f' must be in the interval (0.0, 1.0]\" , ) self . frequency_filter = frequency_filter self . f = f super () . __init__ ( coordinate_weights ) def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\"Compute Euclidean distance between the Fourier transform of the two time series. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: The computed loss over the specific coordinate. \"\"\" f_real_data = np . fft . rfft ( real_data , axis = 0 ) N = f_real_data . shape [ 0 ] f_real_data = self . frequency_filter ( f_real_data , self . f ) # computer mean fft transform of simulated ensemble f_sim_data = [] for s in sim_data_ensemble : f_sim_data_ = np . fft . rfft ( s , axis = 0 ) f_sim_data_ = self . frequency_filter ( f_sim_data_ , self . f ) f_sim_data . append ( f_sim_data_ ) f_sim_data = np . array ( f_sim_data ) . mean ( 0 ) loss_1d = np . sqrt ( np . sum (( abs ( f_sim_data - f_real_data )) ** 2 ) / N ) return loss_1d","title":"FourierLoss"},{"location":"losses/#black_it.loss_functions.fourier.FourierLoss.__init__","text":"Loss computed using a distance in the Fourier space of the time series. This loss is equivalent to the Euclidean loss computed on the time series after a Fourier-filter. The parameter f controls the fraction of frequencies that are kept in the Fourier series. Parameters: Name Type Description Default frequency_filter Callable[[numpy.ndarray, float], numpy.ndarray] the function used to filter the fourier frequencies before the distance is computed. <function gaussian_low_pass_filter at 0x7f8153eaa700> f float fraction of fourier components to keep when computing the distance between the time series. This parameter will be passed to frequency_filter. 0.8 coordinate_weights Optional[numpy.ndarray] relative weights of the losses computed over different time series coordinates. None Source code in black_it/loss_functions/fourier.py def __init__ ( self , frequency_filter : FrequencyFilter = gaussian_low_pass_filter , f : float = 0.8 , coordinate_weights : Optional [ NDArray ] = None , ) -> None : \"\"\"Loss computed using a distance in the Fourier space of the time series. This loss is equivalent to the Euclidean loss computed on the time series after a Fourier-filter. The parameter f controls the fraction of frequencies that are kept in the Fourier series. Args: frequency_filter: the function used to filter the fourier frequencies before the distance is computed. f: fraction of fourier components to keep when computing the distance between the time series. This parameter will be passed to frequency_filter. coordinate_weights: relative weights of the losses computed over different time series coordinates. \"\"\" assert_ ( 0.0 < f <= 1.0 , \"'f' must be in the interval (0.0, 1.0]\" , ) self . frequency_filter = frequency_filter self . f = f super () . __init__ ( coordinate_weights )","title":"__init__()"},{"location":"losses/#black_it.loss_functions.fourier.FourierLoss.compute_loss_1d","text":"Compute Euclidean distance between the Fourier transform of the two time series. Parameters: Name Type Description Default sim_data_ensemble ndarray the first operand required real_data ndarray the second operand required Returns: Type Description float The computed loss over the specific coordinate. Source code in black_it/loss_functions/fourier.py def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\"Compute Euclidean distance between the Fourier transform of the two time series. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: The computed loss over the specific coordinate. \"\"\" f_real_data = np . fft . rfft ( real_data , axis = 0 ) N = f_real_data . shape [ 0 ] f_real_data = self . frequency_filter ( f_real_data , self . f ) # computer mean fft transform of simulated ensemble f_sim_data = [] for s in sim_data_ensemble : f_sim_data_ = np . fft . rfft ( s , axis = 0 ) f_sim_data_ = self . frequency_filter ( f_sim_data_ , self . f ) f_sim_data . append ( f_sim_data_ ) f_sim_data = np . array ( f_sim_data ) . mean ( 0 ) loss_1d = np . sqrt ( np . sum (( abs ( f_sim_data - f_real_data )) ** 2 ) / N ) return loss_1d","title":"compute_loss_1d()"},{"location":"losses/#black_it.loss_functions.fourier.gaussian_low_pass_filter","text":"Gaussian low-pass filter. Parameters: Name Type Description Default signal_frequencies ndarray the input signal transformed in the frequency domain. required f float the fraction of frequencies to keep, this will determine the length scale of the Gaussian filter required Returns: Type Description ndarray the filtered frequencies Source code in black_it/loss_functions/fourier.py def gaussian_low_pass_filter ( signal_frequencies : NDArray [ np . complex128 ], f : float , ) -> NDArray [ np . complex128 ]: \"\"\"Gaussian low-pass filter. Args: signal_frequencies: the input signal transformed in the frequency domain. f: the fraction of frequencies to keep, this will determine the length scale of the Gaussian filter Returns: the filtered frequencies \"\"\" # number of low-frequency component to keep sigma = np . round ( f * signal_frequencies . shape [ 0 ]) # gaussian low-pass filter mask = np . exp ( - np . arange ( signal_frequencies . shape [ 0 ]) ** 2 / ( 2 * sigma ** 2 )) filtered_frequencies = signal_frequencies * mask return filtered_frequencies","title":"gaussian_low_pass_filter()"},{"location":"losses/#black_it.loss_functions.fourier.ideal_low_pass_filter","text":"Ideal low-pass filter. Parameters: Name Type Description Default signal_frequencies ndarray the input signal transformed in the frequency domain. required f float the fraction of frequencies to keep unchanged, for f=1 the filter is just the identity. required Returns: Type Description ndarray the filtered frequencies Source code in black_it/loss_functions/fourier.py def ideal_low_pass_filter ( signal_frequencies : NDArray [ np . complex128 ], f : float , ) -> NDArray [ np . complex128 ]: \"\"\"Ideal low-pass filter. Args: signal_frequencies: the input signal transformed in the frequency domain. f: the fraction of frequencies to keep unchanged, for f=1 the filter is just the identity. Returns: the filtered frequencies \"\"\" # number of low-frequency component to keep n = int ( np . round ( f * signal_frequencies . shape [ 0 ])) # ideal low-pass filter mask = np . zeros ( signal_frequencies . shape [ 0 ]) mask [: n ] = 1.0 filtered_frequencies = signal_frequencies * mask return filtered_frequencies","title":"ideal_low_pass_filter()"},{"location":"losses/#black_it.loss_functions.minkowski.MinkowskiLoss","text":"Class for the Minkowski loss. Source code in black_it/loss_functions/minkowski.py class MinkowskiLoss ( BaseLoss ): \"\"\"Class for the Minkowski loss.\"\"\" def __init__ ( self , p : int = 2 , coordinate_weights : Optional [ NDArray ] = None ) -> None : \"\"\" Loss computed using a Minkowski distance. The [Minkowski distance](https://en.wikipedia.org/wiki/Minkowski_distance) is a generalization of both the Manhattan distance (p=1) and the Euclidean distance (p=2). This function computes the Minkowski distance between two series. Note: this class is a wrapper of scipy.spatial.distance.minkowski Args: p: The order of the norm used to compute the distance between real and simulated series coordinate_weights: The order of the norm used to compute the distance between real and simulated series \"\"\" self . p = p super () . __init__ ( coordinate_weights ) def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Call scipy.spatial.distance.minkowski() on its arguments. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: The computed loss over the specific coordinate. \"\"\" # average simulated time series sim_data_ensemble = sim_data_ensemble . mean ( axis = 0 ) loss_1d = minkowski ( sim_data_ensemble , real_data , p = self . p ) return loss_1d","title":"MinkowskiLoss"},{"location":"losses/#black_it.loss_functions.minkowski.MinkowskiLoss.__init__","text":"Loss computed using a Minkowski distance. The Minkowski distance is a generalization of both the Manhattan distance (p=1) and the Euclidean distance (p=2). This function computes the Minkowski distance between two series. Note: this class is a wrapper of scipy.spatial.distance.minkowski Parameters: Name Type Description Default p int The order of the norm used to compute the distance between real and simulated series 2 coordinate_weights Optional[numpy.ndarray] The order of the norm used to compute the distance between real and simulated series None Source code in black_it/loss_functions/minkowski.py def __init__ ( self , p : int = 2 , coordinate_weights : Optional [ NDArray ] = None ) -> None : \"\"\" Loss computed using a Minkowski distance. The [Minkowski distance](https://en.wikipedia.org/wiki/Minkowski_distance) is a generalization of both the Manhattan distance (p=1) and the Euclidean distance (p=2). This function computes the Minkowski distance between two series. Note: this class is a wrapper of scipy.spatial.distance.minkowski Args: p: The order of the norm used to compute the distance between real and simulated series coordinate_weights: The order of the norm used to compute the distance between real and simulated series \"\"\" self . p = p super () . __init__ ( coordinate_weights )","title":"__init__()"},{"location":"losses/#black_it.loss_functions.minkowski.MinkowskiLoss.compute_loss_1d","text":"Call scipy.spatial.distance.minkowski() on its arguments. Parameters: Name Type Description Default sim_data_ensemble ndarray the first operand required real_data ndarray the second operand required Returns: Type Description float The computed loss over the specific coordinate. Source code in black_it/loss_functions/minkowski.py def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Call scipy.spatial.distance.minkowski() on its arguments. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: The computed loss over the specific coordinate. \"\"\" # average simulated time series sim_data_ensemble = sim_data_ensemble . mean ( axis = 0 ) loss_1d = minkowski ( sim_data_ensemble , real_data , p = self . p ) return loss_1d","title":"compute_loss_1d()"},{"location":"losses/#black_it.loss_functions.msm.MethodOfMomentsLoss","text":"Class for the 'method of moments' loss. Source code in black_it/loss_functions/msm.py class MethodOfMomentsLoss ( BaseLoss ): \"\"\"Class for the 'method of moments' loss.\"\"\" def __init__ ( self , covariance_mat : Optional [ NDArray [ np . float64 ]] = None , coordinate_weights : Optional [ NDArray [ np . float64 ]] = None , moment_calculator : MomentCalculator = get_mom_ts_1d , ): \"\"\" Initialize the loss function based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. By default the loss computes the moments using black_it.utils.time_series.get_mom_ts_1d(), which computes an 18-dimensional vector of statistics. You can alter the behaviour passing a custom function to moment_calculator. Please note that there is a constraint between the moment calculator and the size of the covariance matrix. Args: covariance_mat: covariance matrix between the moments. The default is the identity matrix. The covariance matrix must be a symmetric matrix whose size must be equal to the number of elements that the moment calculator returns. coordinate_weights: importance of each coordinate. By default all coordinates are treated equally. moment_calculator: a function that takes a 1D time series and returns a series of moments. The default is black_it.utils.time_series.get_mom_ts_1d() \"\"\" MethodOfMomentsLoss . _validate_covariance_and_calculator ( moment_calculator , covariance_mat ) super () . __init__ ( coordinate_weights ) self . _covariance_mat = covariance_mat self . _moment_calculator = moment_calculator @staticmethod def _validate_covariance_and_calculator ( moment_calculator : MomentCalculator , covariance_mat : Optional [ NDArray [ np . float64 ]] = None , ) -> None : \"\"\" Validate the covariance matrix. Args: moment_calculator: the moment calculator covariance_mat: the covariance matrix, or None Returns: None Raises: ValueError: if the covariance matrix is not valid. It can be invalid if it is not symmetric or if moment_calculator is the default get_mom_ts_1d and the covariance matrix's shape is not 18. Other possible errors won't be caught by this function, and can only be detected at runtime. \"\"\" if covariance_mat is None : # if we were given no covariance matrix, then we'll use a default # one, and we can't do any further validation (without executing the # moment_calculator) return # a non null covariance_mat was given if not is_symmetric ( covariance_mat ): raise ValueError ( \"the provided covariance matrix is not valid as it is not a symmetric matrix\" ) if ( moment_calculator is get_mom_ts_1d ) and ( covariance_mat . shape [ 0 ] != 18 ): raise ValueError ( \"the provided covariance matrix is not valid as it has a wrong shape: \" f \"expected 18, got { covariance_mat . shape [ 0 ] } \" ) def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Compute the loss based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: the MSM loss over a specific coordinate. \"\"\" # compute the moments for the simulated ensemble ensemble_real_mom_1d = np . array ( [ self . _moment_calculator ( s ) for s in sim_data_ensemble ] ) # compute moments of the real time series sim_mom_1d = self . _moment_calculator ( real_data ) g = ( sim_mom_1d [ None , :] - ensemble_real_mom_1d ) . mean ( axis = 0 ) if self . _covariance_mat is None : loss_1d = g . dot ( g ) return loss_1d W = self . _covariance_mat try : loss_1d = g . dot ( W ) . dot ( g ) except ValueError as e : covariance_size = W . shape [ 0 ] moments_size = g . shape [ 0 ] if covariance_size == moments_size : # this value error is not due to a mismatch between the # covariance matrix size and the number moments. Let's raise the # original error. raise raise ValueError ( f \"The size of the covariance matrix ( { covariance_size } ) \" f \"and the number of moments ( { moments_size } ) should be identical\" ) from e return loss_1d","title":"MethodOfMomentsLoss"},{"location":"losses/#black_it.loss_functions.msm.MethodOfMomentsLoss.__init__","text":"Initialize the loss function based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. By default the loss computes the moments using black_it.utils.time_series.get_mom_ts_1d(), which computes an 18-dimensional vector of statistics. You can alter the behaviour passing a custom function to moment_calculator. Please note that there is a constraint between the moment calculator and the size of the covariance matrix. Parameters: Name Type Description Default covariance_mat Optional[numpy.ndarray] covariance matrix between the moments. The default is the identity matrix. The covariance matrix must be a symmetric matrix whose size must be equal to the number of elements that the moment calculator returns. None coordinate_weights Optional[numpy.ndarray] importance of each coordinate. By default all coordinates are treated equally. None moment_calculator Callable[[numpy.ndarray], numpy.ndarray] a function that takes a 1D time series and returns a series of moments. The default is black_it.utils.time_series.get_mom_ts_1d() <function get_mom_ts_1d at 0x7f8154460280> Source code in black_it/loss_functions/msm.py def __init__ ( self , covariance_mat : Optional [ NDArray [ np . float64 ]] = None , coordinate_weights : Optional [ NDArray [ np . float64 ]] = None , moment_calculator : MomentCalculator = get_mom_ts_1d , ): \"\"\" Initialize the loss function based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. By default the loss computes the moments using black_it.utils.time_series.get_mom_ts_1d(), which computes an 18-dimensional vector of statistics. You can alter the behaviour passing a custom function to moment_calculator. Please note that there is a constraint between the moment calculator and the size of the covariance matrix. Args: covariance_mat: covariance matrix between the moments. The default is the identity matrix. The covariance matrix must be a symmetric matrix whose size must be equal to the number of elements that the moment calculator returns. coordinate_weights: importance of each coordinate. By default all coordinates are treated equally. moment_calculator: a function that takes a 1D time series and returns a series of moments. The default is black_it.utils.time_series.get_mom_ts_1d() \"\"\" MethodOfMomentsLoss . _validate_covariance_and_calculator ( moment_calculator , covariance_mat ) super () . __init__ ( coordinate_weights ) self . _covariance_mat = covariance_mat self . _moment_calculator = moment_calculator","title":"__init__()"},{"location":"losses/#black_it.loss_functions.msm.MethodOfMomentsLoss.compute_loss_1d","text":"Compute the loss based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. Parameters: Name Type Description Default sim_data_ensemble ndarray the first operand required real_data ndarray the second operand required Returns: Type Description float the MSM loss over a specific coordinate. Source code in black_it/loss_functions/msm.py def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Compute the loss based on the 'method of moments'. Returns the MSM objective function, i.e. the square difference between the moments of the two time series. Args: sim_data_ensemble: the first operand real_data: the second operand Returns: the MSM loss over a specific coordinate. \"\"\" # compute the moments for the simulated ensemble ensemble_real_mom_1d = np . array ( [ self . _moment_calculator ( s ) for s in sim_data_ensemble ] ) # compute moments of the real time series sim_mom_1d = self . _moment_calculator ( real_data ) g = ( sim_mom_1d [ None , :] - ensemble_real_mom_1d ) . mean ( axis = 0 ) if self . _covariance_mat is None : loss_1d = g . dot ( g ) return loss_1d W = self . _covariance_mat try : loss_1d = g . dot ( W ) . dot ( g ) except ValueError as e : covariance_size = W . shape [ 0 ] moments_size = g . shape [ 0 ] if covariance_size == moments_size : # this value error is not due to a mismatch between the # covariance matrix size and the number moments. Let's raise the # original error. raise raise ValueError ( f \"The size of the covariance matrix ( { covariance_size } ) \" f \"and the number of moments ( { moments_size } ) should be identical\" ) from e return loss_1d","title":"compute_loss_1d()"},{"location":"losses/#black_it.loss_functions.gsl_div.GslDivLoss","text":"Class for the Gsl-div loss. Examples: >>> expected_loss = 0.39737637181336855 >>> np . random . seed ( 11 ) >>> series1 = np . random . normal ( 0 , 1 , ( 100 , 3 )) >>> series2 = np . random . normal ( 0 , 1 , ( 100 , 3 )) >>> loss_func = GslDivLoss () >>> loss = loss_func . compute_loss ( series1 [ None , :, :], series2 ) >>> assert np . isclose ( expected_loss , loss ) Source code in black_it/loss_functions/gsl_div.py class GslDivLoss ( BaseLoss ): \"\"\" Class for the Gsl-div loss. Example: >>> expected_loss = 0.39737637181336855 >>> np.random.seed(11) >>> series1 = np.random.normal(0, 1, (100, 3)) >>> series2 = np.random.normal(0, 1, (100, 3)) >>> loss_func = GslDivLoss() >>> loss = loss_func.compute_loss(series1[None, :, :], series2) >>> assert np.isclose(expected_loss, loss) \"\"\" def __init__ ( self , nb_values : int = None , nb_word_lengths : int = None , coordinate_weights : Optional [ NDArray ] = None , ) -> None : \"\"\" Initialize the GSL-div loss object. Args: nb_values: number of values the digitised series can take nb_word_lengths: the number of word length to consider coordinate_weights: the weights of the loss coordinates \"\"\" super () . __init__ ( coordinate_weights ) self . nb_values = nb_values self . nb_word_lengths = nb_word_lengths def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Return the GSL-div measure. From (Lamperti, 2017): > The information loss about the behaviour of the stochastic process due to the symbolization becomes smaller and smaller as b increases. On the other side, low values of b would likely wash away processes\u2019 noise the modeller might not be interested in. Args: sim_data_ensemble: the ensemble of simulated data real_data: the real data Returns: the GSL loss \"\"\" N = len ( real_data ) ensemble_size = sim_data_ensemble . shape [ 0 ] if self . nb_values is None : nb_values = int (( N - 1 ) / 2.0 ) else : nb_values = self . nb_values if self . nb_word_lengths is None : nb_word_lengths = int (( N - 1 ) / 2.0 ) else : nb_word_lengths = self . nb_word_lengths # discretize real time series obs_xd = self . discretize ( real_data , nb_values , np . min ( real_data ), np . max ( real_data ), ) gsl_loss = 0.0 # average loss over the ensemble for sim_data in sim_data_ensemble : # discretize simulated series sim_xd = self . discretize ( sim_data , nb_values , np . min ( sim_data ), np . max ( sim_data ) ) loss = self . gsl_div_1d_1_sample ( sim_xd , obs_xd , nb_word_lengths , nb_values , N ) gsl_loss += loss return gsl_loss / ensemble_size def gsl_div_1d_1_sample ( self , sim_xd : NDArray , obs_xd : NDArray , nb_word_lengths : int , nb_values : int , N : int , ) -> float : \"\"\"Compute the GSL-div for a single realisation of the simulated data. Args: sim_xd: discretised simulated series obs_xd: discretised real series nb_word_lengths: the number of word length to consider nb_values: number of values the digitised series can take N: the length of real and simulated series Returns: the computed loss \"\"\" # outcome measure gsl_div = 0.0 # weight weight = 0.0 # for any word len: for word_length in range ( 1 , nb_word_lengths + 1 ): sim_xw = self . get_words ( sim_xd , word_length ) obs_xw = self . get_words ( obs_xd , word_length ) m_xw = np . concatenate (( sim_xw , obs_xw )) sim_xp = self . get_words_est_prob ( sim_xw ) m_xp = self . get_words_est_prob ( m_xw ) base = float ( nb_values ** word_length ) sim_entr = self . get_sh_entr ( sim_xp , base ) m_entr = self . get_sh_entr ( m_xp , base ) # update weight weight = weight + 2 / ( nb_word_lengths * ( nb_word_lengths + 1 )) # correction corr = (( len ( m_xp ) - 1 ) - ( len ( sim_xp ) - 1 )) / ( 2 * N ) # add to measure gsl_divl = 2 * m_entr - sim_entr + corr gsl_div = gsl_div + weight * gsl_divl # end of cycle, return return gsl_div @staticmethod def discretize ( time_series : NDArray [ np . float64 ], nb_values : int , start_index : float , stop_index : float , ) -> NDArray [ np . float64 ]: \"\"\" Discretize the TS in 'nb_values' finite states. >>> GslDivLoss.discretize( ... [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ... nb_values=3, ... start_index=1, ... stop_index=10 ... ) array([1, 1, 1, 2, 2, 2, 2, 3, 3, 3]) Args: time_series: any univariate time series nb_values: int, number of values the digitised series can take. It must be greater than 0. start_index: the starting point stop_index: the stopping point Returns: the discretised time series \"\"\" linspace = np . linspace ( start_index - EPS , stop_index + EPS , nb_values + 1 ) return np . searchsorted ( linspace , time_series , side = \"left\" ) @staticmethod def get_words ( time_series : NDArray [ np . float64 ], length : int ) -> NDArray : \"\"\" Return an overlapping array of words (int32) of 'length' given a discretised vector. >>> GslDivLoss.get_words(np.asarray([1, 2, 2, 2]), 2) array([12, 22, 22]) Args: time_series: any univariate discretised time series length: int, len of words to be returned. Must be such that (len(time_series) + 1 - length) is positive. Returns: the time series of overlapping words \"\"\" tswlen = len ( time_series ) + 1 - length assert_ ( tswlen >= 0 , \"the chosen word length is too high\" , exc_cls = ValueError ) tsw = np . zeros ( shape = ( tswlen ,), dtype = np . int32 ) for i in range ( length ): k = 10 ** ( length - i - 1 ) tsw = tsw + time_series [ i : tswlen + i ] * k return tsw @staticmethod def get_words_est_prob ( time_series : NDArray [ np . float64 ]) -> NDArray [ np . float64 ]: \"\"\" Return an array of estimated probabilities given an array of words (int32). Args: time_series: any univariate array of words Returns: estimate of probabilities \"\"\" _ , count = np . unique ( time_series , return_counts = True ) est_p = np . divide ( count , np . sum ( count )) return est_p @staticmethod def get_sh_entr ( probs : NDArray [ np . float64 ], log_base : float ) -> float : \"\"\" Return the Shannon entropy given an array of probabilities. Args: probs: an array of probabilities describing the discrete probability distribution log_base: the entropy logarithm base. Returns: the entropy of the discrete probability distribution \"\"\" log = np . log ( probs ) / np . log ( log_base ) return - np . sum ( np . multiply ( probs , log ))","title":"GslDivLoss"},{"location":"losses/#black_it.loss_functions.gsl_div.GslDivLoss.__init__","text":"Initialize the GSL-div loss object. Parameters: Name Type Description Default nb_values int number of values the digitised series can take None nb_word_lengths int the number of word length to consider None coordinate_weights Optional[numpy.ndarray] the weights of the loss coordinates None Source code in black_it/loss_functions/gsl_div.py def __init__ ( self , nb_values : int = None , nb_word_lengths : int = None , coordinate_weights : Optional [ NDArray ] = None , ) -> None : \"\"\" Initialize the GSL-div loss object. Args: nb_values: number of values the digitised series can take nb_word_lengths: the number of word length to consider coordinate_weights: the weights of the loss coordinates \"\"\" super () . __init__ ( coordinate_weights ) self . nb_values = nb_values self . nb_word_lengths = nb_word_lengths","title":"__init__()"},{"location":"losses/#black_it.loss_functions.gsl_div.GslDivLoss.compute_loss_1d","text":"Return the GSL-div measure. From (Lamperti, 2017): The information loss about the behaviour of the stochastic process due to the symbolization becomes smaller and smaller as b increases. On the other side, low values of b would likely wash away processes\u2019 noise the modeller might not be interested in. Parameters: Name Type Description Default sim_data_ensemble ndarray the ensemble of simulated data required real_data ndarray the real data required Returns: Type Description float the GSL loss Source code in black_it/loss_functions/gsl_div.py def compute_loss_1d ( self , sim_data_ensemble : NDArray [ np . float64 ], real_data : NDArray [ np . float64 ] ) -> float : \"\"\" Return the GSL-div measure. From (Lamperti, 2017): > The information loss about the behaviour of the stochastic process due to the symbolization becomes smaller and smaller as b increases. On the other side, low values of b would likely wash away processes\u2019 noise the modeller might not be interested in. Args: sim_data_ensemble: the ensemble of simulated data real_data: the real data Returns: the GSL loss \"\"\" N = len ( real_data ) ensemble_size = sim_data_ensemble . shape [ 0 ] if self . nb_values is None : nb_values = int (( N - 1 ) / 2.0 ) else : nb_values = self . nb_values if self . nb_word_lengths is None : nb_word_lengths = int (( N - 1 ) / 2.0 ) else : nb_word_lengths = self . nb_word_lengths # discretize real time series obs_xd = self . discretize ( real_data , nb_values , np . min ( real_data ), np . max ( real_data ), ) gsl_loss = 0.0 # average loss over the ensemble for sim_data in sim_data_ensemble : # discretize simulated series sim_xd = self . discretize ( sim_data , nb_values , np . min ( sim_data ), np . max ( sim_data ) ) loss = self . gsl_div_1d_1_sample ( sim_xd , obs_xd , nb_word_lengths , nb_values , N ) gsl_loss += loss return gsl_loss / ensemble_size","title":"compute_loss_1d()"},{"location":"losses/#black_it.loss_functions.gsl_div.GslDivLoss.discretize","text":"Discretize the TS in 'nb_values' finite states. GslDivLoss.discretize( ... [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ... nb_values=3, ... start_index=1, ... stop_index=10 ... ) array([1, 1, 1, 2, 2, 2, 2, 3, 3, 3]) Parameters: Name Type Description Default time_series ndarray any univariate time series required nb_values int int, number of values the digitised series can take. It must be greater than 0. required start_index float the starting point required stop_index float the stopping point required Returns: Type Description ndarray the discretised time series Source code in black_it/loss_functions/gsl_div.py @staticmethod def discretize ( time_series : NDArray [ np . float64 ], nb_values : int , start_index : float , stop_index : float , ) -> NDArray [ np . float64 ]: \"\"\" Discretize the TS in 'nb_values' finite states. >>> GslDivLoss.discretize( ... [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], ... nb_values=3, ... start_index=1, ... stop_index=10 ... ) array([1, 1, 1, 2, 2, 2, 2, 3, 3, 3]) Args: time_series: any univariate time series nb_values: int, number of values the digitised series can take. It must be greater than 0. start_index: the starting point stop_index: the stopping point Returns: the discretised time series \"\"\" linspace = np . linspace ( start_index - EPS , stop_index + EPS , nb_values + 1 ) return np . searchsorted ( linspace , time_series , side = \"left\" )","title":"discretize()"},{"location":"losses/#black_it.loss_functions.gsl_div.GslDivLoss.get_sh_entr","text":"Return the Shannon entropy given an array of probabilities. Parameters: Name Type Description Default probs ndarray an array of probabilities describing the discrete probability distribution required log_base float the entropy logarithm base. required Returns: Type Description float the entropy of the discrete probability distribution Source code in black_it/loss_functions/gsl_div.py @staticmethod def get_sh_entr ( probs : NDArray [ np . float64 ], log_base : float ) -> float : \"\"\" Return the Shannon entropy given an array of probabilities. Args: probs: an array of probabilities describing the discrete probability distribution log_base: the entropy logarithm base. Returns: the entropy of the discrete probability distribution \"\"\" log = np . log ( probs ) / np . log ( log_base ) return - np . sum ( np . multiply ( probs , log ))","title":"get_sh_entr()"},{"location":"losses/#black_it.loss_functions.gsl_div.GslDivLoss.get_words","text":"Return an overlapping array of words (int32) of 'length' given a discretised vector. GslDivLoss.get_words(np.asarray([1, 2, 2, 2]), 2) array([12, 22, 22]) Parameters: Name Type Description Default time_series ndarray any univariate discretised time series required length int int, len of words to be returned. Must be such that (len(time_series) + 1 - length) is positive. required Returns: Type Description ndarray the time series of overlapping words Source code in black_it/loss_functions/gsl_div.py @staticmethod def get_words ( time_series : NDArray [ np . float64 ], length : int ) -> NDArray : \"\"\" Return an overlapping array of words (int32) of 'length' given a discretised vector. >>> GslDivLoss.get_words(np.asarray([1, 2, 2, 2]), 2) array([12, 22, 22]) Args: time_series: any univariate discretised time series length: int, len of words to be returned. Must be such that (len(time_series) + 1 - length) is positive. Returns: the time series of overlapping words \"\"\" tswlen = len ( time_series ) + 1 - length assert_ ( tswlen >= 0 , \"the chosen word length is too high\" , exc_cls = ValueError ) tsw = np . zeros ( shape = ( tswlen ,), dtype = np . int32 ) for i in range ( length ): k = 10 ** ( length - i - 1 ) tsw = tsw + time_series [ i : tswlen + i ] * k return tsw","title":"get_words()"},{"location":"losses/#black_it.loss_functions.gsl_div.GslDivLoss.get_words_est_prob","text":"Return an array of estimated probabilities given an array of words (int32). Parameters: Name Type Description Default time_series ndarray any univariate array of words required Returns: Type Description ndarray estimate of probabilities Source code in black_it/loss_functions/gsl_div.py @staticmethod def get_words_est_prob ( time_series : NDArray [ np . float64 ]) -> NDArray [ np . float64 ]: \"\"\" Return an array of estimated probabilities given an array of words (int32). Args: time_series: any univariate array of words Returns: estimate of probabilities \"\"\" _ , count = np . unique ( time_series , return_counts = True ) est_p = np . divide ( count , np . sum ( count )) return est_p","title":"get_words_est_prob()"},{"location":"losses/#black_it.loss_functions.gsl_div.GslDivLoss.gsl_div_1d_1_sample","text":"Compute the GSL-div for a single realisation of the simulated data. Parameters: Name Type Description Default sim_xd ndarray discretised simulated series required obs_xd ndarray discretised real series required nb_word_lengths int the number of word length to consider required nb_values int number of values the digitised series can take required N int the length of real and simulated series required Returns: Type Description float the computed loss Source code in black_it/loss_functions/gsl_div.py def gsl_div_1d_1_sample ( self , sim_xd : NDArray , obs_xd : NDArray , nb_word_lengths : int , nb_values : int , N : int , ) -> float : \"\"\"Compute the GSL-div for a single realisation of the simulated data. Args: sim_xd: discretised simulated series obs_xd: discretised real series nb_word_lengths: the number of word length to consider nb_values: number of values the digitised series can take N: the length of real and simulated series Returns: the computed loss \"\"\" # outcome measure gsl_div = 0.0 # weight weight = 0.0 # for any word len: for word_length in range ( 1 , nb_word_lengths + 1 ): sim_xw = self . get_words ( sim_xd , word_length ) obs_xw = self . get_words ( obs_xd , word_length ) m_xw = np . concatenate (( sim_xw , obs_xw )) sim_xp = self . get_words_est_prob ( sim_xw ) m_xp = self . get_words_est_prob ( m_xw ) base = float ( nb_values ** word_length ) sim_entr = self . get_sh_entr ( sim_xp , base ) m_entr = self . get_sh_entr ( m_xp , base ) # update weight weight = weight + 2 / ( nb_word_lengths * ( nb_word_lengths + 1 )) # correction corr = (( len ( m_xp ) - 1 ) - ( len ( sim_xp ) - 1 )) / ( 2 * N ) # add to measure gsl_divl = 2 * m_entr - sim_entr + corr gsl_div = gsl_div + weight * gsl_divl # end of cycle, return return gsl_div","title":"gsl_div_1d_1_sample()"},{"location":"overview_of_plotting_functions/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Overview of the plotting tools of black-it import numpy as np import matplotlib.pyplot as plt Let us assume we have performed a calibration and we have stored our results in a given folder. In this tutotial we will go through the black-it tools to quickly analyse the calibration results. saving_folder = \"saving_folder\" Analyse the action of the different samplers from black_it.plot.plot_results import plot_sampling plot_sampling ( saving_folder ) from black_it.plot.plot_results import plot_sampling_interact plot_sampling_interact ( saving_folder ) interactive(children=(Dropdown(description='batch_nums', options={'from 0 to 3': [0, 1, 2, 3], 'from 4 to 6': \u2026 Analyse the loss landscape explored from black_it.plot.plot_results import plot_losses plot_losses ( saving_folder ) from black_it.plot.plot_results import plot_losses_interact plot_losses_interact ( saving_folder ) interactive(children=(Dropdown(description='method_num', options={'RandomUniformSampler': 0, 'RSequenceSampler\u2026 Analyse the calibration convergence from black_it.plot.plot_results import plot_convergence plot_convergence ( saving_folder )","title":"Plotting tutorial"},{"location":"overview_of_plotting_functions/#overview-of-the-plotting-tools-of-black-it","text":"import numpy as np import matplotlib.pyplot as plt Let us assume we have performed a calibration and we have stored our results in a given folder. In this tutotial we will go through the black-it tools to quickly analyse the calibration results. saving_folder = \"saving_folder\"","title":"Overview of the plotting tools of black-it"},{"location":"overview_of_plotting_functions/#analyse-the-action-of-the-different-samplers","text":"from black_it.plot.plot_results import plot_sampling plot_sampling ( saving_folder ) from black_it.plot.plot_results import plot_sampling_interact plot_sampling_interact ( saving_folder ) interactive(children=(Dropdown(description='batch_nums', options={'from 0 to 3': [0, 1, 2, 3], 'from 4 to 6': \u2026","title":"Analyse the action of the different samplers"},{"location":"overview_of_plotting_functions/#analyse-the-loss-landscape-explored","text":"from black_it.plot.plot_results import plot_losses plot_losses ( saving_folder ) from black_it.plot.plot_results import plot_losses_interact plot_losses_interact ( saving_folder ) interactive(children=(Dropdown(description='method_num', options={'RandomUniformSampler': 0, 'RSequenceSampler\u2026","title":"Analyse the loss landscape explored"},{"location":"overview_of_plotting_functions/#analyse-the-calibration-convergence","text":"from black_it.plot.plot_results import plot_convergence plot_convergence ( saving_folder )","title":"Analyse the calibration convergence"},{"location":"overview_of_the_different_samplers/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Overvieview of the different samplers of the package import numpy as np from black_it.search_space import SearchSpace from black_it.samplers.random_uniform import RandomUniformSampler from black_it.samplers.halton import HaltonSampler from black_it.samplers.r_sequence import RSequenceSampler from black_it.samplers.random_forest import RandomForestSampler from black_it.samplers.gaussian_process import GaussianProcessSampler from black_it.samplers.best_batch import BestBatchSampler import matplotlib.pyplot as plt In this notebook we will illustrate the inner working of the samplers of the package. For ease of visualization we will focus exclusively on a simple two-dimensional parameter space. # define a 2-dimensional grid of possible parameter values between 0 and 1. param_grid = SearchSpace ( parameters_bounds = np . array ([[ 0 , 1 ], [ 0 , 1 ]]) . T , parameters_precision = [ 0.01 , 0.01 ], verbose = False , ) Random Uniform (Trivial) Sampler The simplest sampler is a sampler that proposes completely random parameters. sampler = RandomUniformSampler ( batch_size = 50 , random_state = 0 ) new_params = sampler . sample ( param_grid , np . zeros (( 0 , 2 )), np . zeros (( 0 , 2 ))) plt . figure ( figsize = ( 5 , 5 )) for i in range ( 5 ): plt . scatter ( new_params [ i * 10 : ( i + 1 ) * 10 , 0 ], new_params [ i * 10 : ( i + 1 ) * 10 , 1 ], label = \"iter. \" + str ( i * 10 ) + \" - \" + str (( i + 1 ) * 10 ), ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1bdb93610> Low discrepancy samplers As you can see from the graph above, random uniform sampling is not very effective at covering the parameter space uniformly (in spite of the name). To address this problem one can use a series of samplers designed to provide low discrepancy . These are discussed in the folling. Halton Sampler sampler = HaltonSampler ( batch_size = 50 , random_state = 0 ) new_params = sampler . sample ( param_grid , np . zeros (( 0 , 2 )), np . zeros (( 0 , 2 ))) plt . figure ( figsize = ( 5 , 5 )) for i in range ( 5 ): plt . scatter ( new_params [ i * 10 : ( i + 1 ) * 10 , 0 ], new_params [ i * 10 : ( i + 1 ) * 10 , 1 ], label = \"iter. \" + str ( i * 10 ) + \" - \" + str (( i + 1 ) * 10 ), ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1bddc5e20> R-Sequence Sampler sampler = RSequenceSampler ( batch_size = 50 , random_state = 0 ) new_params = sampler . sample ( param_grid , np . zeros (( 0 , 2 )), np . zeros (( 0 , 2 ))) plt . figure ( figsize = ( 5 , 5 )) for i in range ( 5 ): plt . scatter ( new_params [ i * 10 : ( i + 1 ) * 10 , 0 ], new_params [ i * 10 : ( i + 1 ) * 10 , 1 ], label = \"iter. \" + str ( i * 10 ) + \" - \" + str (( i + 1 ) * 10 ), ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1bde3d640> Adaptive samplers Certain samplers exploit the information collected during previous calibration steps to adaptively propose optimal sampling regions to explore. These adaptive samplers are discussed in the following. # In the folliwing we will assume that the value of the loss function # is known on a grid of points in parameter space xs = np . linspace ( 0 , 1 , 6 ) ys = np . linspace ( 0 , 1 , 6 ) xys = [] losses = [] for x in xs : for y in ys : # a small noise is needed to avoid # unrealistically simmetric sampling x = x + np . random . normal ( 0 , 1e-2 ) y = y + np . random . normal ( 0 , 1e-2 ) xys . append ([ x , y ]) losses . append ( 5 * ( x ** 2 + y ** 2 )) xys = np . array ( xys ) losses = np . array ( losses ) plt . title ( \"loss function values\" ) plt . scatter ( xys [:, 0 ], xys [:, 1 ], c = losses ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . colorbar () <matplotlib.colorbar.Colorbar at 0x7fd1be01f3a0> Random Forest Sampler sampler = RandomForestSampler ( batch_size = 16 , random_state = 0 ) new_params = sampler . sample ( param_grid , xys , losses ) Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. plt . figure ( figsize = ( 5 , 5 )) plt . scatter ( xys [:, 0 ], xys [:, 1 ], c = \"0.8\" , label = \"previously sampled\" ) plt . scatter ( new_params [:, 0 ], new_params [:, 1 ], label = \"random forest sampling\" ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1be0c8a00> Gaussian Process Sampler (\"Bayesian Optimisation\") sampler = GaussianProcessSampler ( batch_size = 8 , random_state = 0 , acquisition = \"mean\" ) new_params_mean_acquisition = sampler . sample ( param_grid , xys , losses ) /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:581: RuntimeWarning:overflow encountered in square /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:581: RuntimeWarning:invalid value encountered in multiply /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:584: RuntimeWarning:overflow encountered in square /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:584: RuntimeWarning:invalid value encountered in multiply /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:168: RuntimeWarning:overflow encountered in true_divide /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:581: RuntimeWarning:overflow encountered in multiply /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:584: RuntimeWarning:overflow encountered in multiply /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:584: RuntimeWarning:invalid value encountered in subtract Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. sampler = GaussianProcessSampler ( batch_size = 8 , random_state = 0 , acquisition = \"expected_improvement\" ) new_params_EI_acquisition = sampler . sample ( param_grid , xys , losses ) Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. # note that the expected_improvement acquisition function automatically # tries to strike a balance between \"exploration\" and \"exploitation\" plt . figure ( figsize = ( 5 , 5 )) plt . scatter ( xys [:, 0 ], xys [:, 1 ], c = \"0.8\" , label = \"previously sampled\" ) plt . scatter ( new_params_mean_acquisition [:, 0 ], new_params_mean_acquisition [:, 1 ], label = \"mean acq. func.\" , ) plt . scatter ( new_params_EI_acquisition [:, 0 ], new_params_EI_acquisition [:, 1 ], label = \"EI acq. func.\" , ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1be787220> Best Batch (\"Genetic\") Sampler sampler = BestBatchSampler ( batch_size = 16 , random_state = 0 ) new_params = sampler . sample ( param_grid , xys , losses ) plt . figure ( figsize = ( 5 , 5 )) plt . scatter ( xys [:, 0 ], xys [:, 1 ], c = \"0.8\" , label = \"previously sampled\" ) plt . scatter ( new_params [:, 0 ], new_params [:, 1 ], label = \"best batch sampling\" ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1be0b14c0>","title":"Different samplers"},{"location":"overview_of_the_different_samplers/#overvieview-of-the-different-samplers-of-the-package","text":"import numpy as np from black_it.search_space import SearchSpace from black_it.samplers.random_uniform import RandomUniformSampler from black_it.samplers.halton import HaltonSampler from black_it.samplers.r_sequence import RSequenceSampler from black_it.samplers.random_forest import RandomForestSampler from black_it.samplers.gaussian_process import GaussianProcessSampler from black_it.samplers.best_batch import BestBatchSampler import matplotlib.pyplot as plt In this notebook we will illustrate the inner working of the samplers of the package. For ease of visualization we will focus exclusively on a simple two-dimensional parameter space. # define a 2-dimensional grid of possible parameter values between 0 and 1. param_grid = SearchSpace ( parameters_bounds = np . array ([[ 0 , 1 ], [ 0 , 1 ]]) . T , parameters_precision = [ 0.01 , 0.01 ], verbose = False , )","title":"Overvieview of the different samplers of the package"},{"location":"overview_of_the_different_samplers/#random-uniform-trivial-sampler","text":"The simplest sampler is a sampler that proposes completely random parameters. sampler = RandomUniformSampler ( batch_size = 50 , random_state = 0 ) new_params = sampler . sample ( param_grid , np . zeros (( 0 , 2 )), np . zeros (( 0 , 2 ))) plt . figure ( figsize = ( 5 , 5 )) for i in range ( 5 ): plt . scatter ( new_params [ i * 10 : ( i + 1 ) * 10 , 0 ], new_params [ i * 10 : ( i + 1 ) * 10 , 1 ], label = \"iter. \" + str ( i * 10 ) + \" - \" + str (( i + 1 ) * 10 ), ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1bdb93610>","title":"Random Uniform (Trivial) Sampler"},{"location":"overview_of_the_different_samplers/#low-discrepancy-samplers","text":"As you can see from the graph above, random uniform sampling is not very effective at covering the parameter space uniformly (in spite of the name). To address this problem one can use a series of samplers designed to provide low discrepancy . These are discussed in the folling.","title":"Low discrepancy samplers"},{"location":"overview_of_the_different_samplers/#halton-sampler","text":"sampler = HaltonSampler ( batch_size = 50 , random_state = 0 ) new_params = sampler . sample ( param_grid , np . zeros (( 0 , 2 )), np . zeros (( 0 , 2 ))) plt . figure ( figsize = ( 5 , 5 )) for i in range ( 5 ): plt . scatter ( new_params [ i * 10 : ( i + 1 ) * 10 , 0 ], new_params [ i * 10 : ( i + 1 ) * 10 , 1 ], label = \"iter. \" + str ( i * 10 ) + \" - \" + str (( i + 1 ) * 10 ), ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1bddc5e20>","title":"Halton Sampler"},{"location":"overview_of_the_different_samplers/#r-sequence-sampler","text":"sampler = RSequenceSampler ( batch_size = 50 , random_state = 0 ) new_params = sampler . sample ( param_grid , np . zeros (( 0 , 2 )), np . zeros (( 0 , 2 ))) plt . figure ( figsize = ( 5 , 5 )) for i in range ( 5 ): plt . scatter ( new_params [ i * 10 : ( i + 1 ) * 10 , 0 ], new_params [ i * 10 : ( i + 1 ) * 10 , 1 ], label = \"iter. \" + str ( i * 10 ) + \" - \" + str (( i + 1 ) * 10 ), ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1bde3d640>","title":"R-Sequence Sampler"},{"location":"overview_of_the_different_samplers/#adaptive-samplers","text":"Certain samplers exploit the information collected during previous calibration steps to adaptively propose optimal sampling regions to explore. These adaptive samplers are discussed in the following. # In the folliwing we will assume that the value of the loss function # is known on a grid of points in parameter space xs = np . linspace ( 0 , 1 , 6 ) ys = np . linspace ( 0 , 1 , 6 ) xys = [] losses = [] for x in xs : for y in ys : # a small noise is needed to avoid # unrealistically simmetric sampling x = x + np . random . normal ( 0 , 1e-2 ) y = y + np . random . normal ( 0 , 1e-2 ) xys . append ([ x , y ]) losses . append ( 5 * ( x ** 2 + y ** 2 )) xys = np . array ( xys ) losses = np . array ( losses ) plt . title ( \"loss function values\" ) plt . scatter ( xys [:, 0 ], xys [:, 1 ], c = losses ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . colorbar () <matplotlib.colorbar.Colorbar at 0x7fd1be01f3a0>","title":"Adaptive samplers"},{"location":"overview_of_the_different_samplers/#random-forest-sampler","text":"sampler = RandomForestSampler ( batch_size = 16 , random_state = 0 ) new_params = sampler . sample ( param_grid , xys , losses ) Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. plt . figure ( figsize = ( 5 , 5 )) plt . scatter ( xys [:, 0 ], xys [:, 1 ], c = \"0.8\" , label = \"previously sampled\" ) plt . scatter ( new_params [:, 0 ], new_params [:, 1 ], label = \"random forest sampling\" ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1be0c8a00>","title":"Random Forest Sampler"},{"location":"overview_of_the_different_samplers/#gaussian-process-sampler-bayesian-optimisation","text":"sampler = GaussianProcessSampler ( batch_size = 8 , random_state = 0 , acquisition = \"mean\" ) new_params_mean_acquisition = sampler . sample ( param_grid , xys , losses ) /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:581: RuntimeWarning:overflow encountered in square /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:581: RuntimeWarning:invalid value encountered in multiply /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:584: RuntimeWarning:overflow encountered in square /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:584: RuntimeWarning:invalid value encountered in multiply /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:168: RuntimeWarning:overflow encountered in true_divide /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:581: RuntimeWarning:overflow encountered in multiply /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:584: RuntimeWarning:overflow encountered in multiply /Users/aldoglielmo/Library/Caches/pypoetry/virtualenvs/black-it-3F5nO-b3-py3.8/lib/python3.8/site-packages/GPy/kern/src/stationary.py:584: RuntimeWarning:invalid value encountered in subtract Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. sampler = GaussianProcessSampler ( batch_size = 8 , random_state = 0 , acquisition = \"expected_improvement\" ) new_params_EI_acquisition = sampler . sample ( param_grid , xys , losses ) Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. # note that the expected_improvement acquisition function automatically # tries to strike a balance between \"exploration\" and \"exploitation\" plt . figure ( figsize = ( 5 , 5 )) plt . scatter ( xys [:, 0 ], xys [:, 1 ], c = \"0.8\" , label = \"previously sampled\" ) plt . scatter ( new_params_mean_acquisition [:, 0 ], new_params_mean_acquisition [:, 1 ], label = \"mean acq. func.\" , ) plt . scatter ( new_params_EI_acquisition [:, 0 ], new_params_EI_acquisition [:, 1 ], label = \"EI acq. func.\" , ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1be787220>","title":"Gaussian Process Sampler (\"Bayesian Optimisation\")"},{"location":"overview_of_the_different_samplers/#best-batch-genetic-sampler","text":"sampler = BestBatchSampler ( batch_size = 16 , random_state = 0 ) new_params = sampler . sample ( param_grid , xys , losses ) plt . figure ( figsize = ( 5 , 5 )) plt . scatter ( xys [:, 0 ], xys [:, 1 ], c = \"0.8\" , label = \"previously sampled\" ) plt . scatter ( new_params [:, 0 ], new_params [:, 1 ], label = \"best batch sampling\" ) plt . xlabel ( \"param. 1\" ) plt . ylabel ( \"param. 2\" ) plt . legend () <matplotlib.legend.Legend at 0x7fd1be0b14c0>","title":"Best Batch (\"Genetic\") Sampler"},{"location":"samplers/","text":"black_it.samplers.base.BaseSampler ( ABC ) BaseSampler interface. This is the base class for all samplers. Source code in black_it/samplers/base.py class BaseSampler ( ABC ): \"\"\" BaseSampler interface. This is the base class for all samplers. \"\"\" def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_duplication_passes : int = 5 , ) -> None : \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the internal state of the sampler, fixing this numbers the sampler behaves deterministically max_duplication_passes: maximum number of duplication passes done to avoid sampling repeated parameters \"\"\" self . random_state : Optional [ int ] = random_state self . batch_size : int = batch_size self . max_duplication_passes = max_duplication_passes @property def random_state ( self ) -> Optional [ int ]: \"\"\"Get the random state.\"\"\" return self . _random_state @random_state . setter def random_state ( self , random_state : Optional [ int ]) -> None : \"\"\"Set the random state.\"\"\" self . _random_state = random_state self . _random_generator = default_rng ( self . random_state ) @property def random_generator ( self ) -> np . random . Generator : \"\"\"Get the random generator.\"\"\" return self . _random_generator def _get_random_seed ( self ) -> int : \"\"\"Get new random seed from the current random generator.\"\"\" return get_random_seed ( self . _random_generator ) @abstractmethod def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample a number of new parameters fixed by the 'batch_size' attribute. Args: batch_size: number of samples to collect search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the new parameters \"\"\" def sample ( self , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" samples = self . sample_batch ( self . batch_size , search_space , existing_points , existing_losses ) for n in range ( self . max_duplication_passes ): duplicates = self . find_and_get_duplicates ( samples , existing_points ) num_duplicates = len ( duplicates ) if num_duplicates == 0 : break new_samples = self . sample_batch ( num_duplicates , search_space , existing_points , existing_losses ) samples [ duplicates ] = new_samples if n == self . max_duplication_passes - 1 : print ( f \"Warning: Repeated samples still found after { self . max_duplication_passes } duplication passes.\" \" This is probably due to a small search space.\" ) return samples @staticmethod def find_and_get_duplicates ( new_points : NDArray [ np . float64 ], existing_points : NDArray [ np . float64 ] ) -> List : \"\"\"Find the points in 'new_points' that are already present in 'existing_points'. Args: new_points: candidates points for the sampler existing_points: previously sampled points Returns: the location of the duplicates in 'new_points' \"\"\" all_points = np . concatenate (( existing_points , new_points )) unq , count = np . unique ( all_points , axis = 0 , return_counts = True ) repeated_groups = unq [ count > 1 ] repeated_pos = [] if len ( repeated_groups ) > 0 : for repeated_group in repeated_groups : repeated_idx = np . argwhere ( np . all ( new_points == repeated_group , axis = 1 )) for index in repeated_idx : repeated_pos . append ( index [ 0 ]) return repeated_pos random_generator : Generator property readonly Get the random generator. random_state : Optional [ int ] property writable Get the random state. __init__ ( self , batch_size , random_state = None , max_duplication_passes = 5 ) special Initialize the sampler. Parameters: Name Type Description Default batch_size int the number of points sampled every time the sampler is called required random_state Optional[int] the internal state of the sampler, fixing this numbers the sampler behaves deterministically None max_duplication_passes int maximum number of duplication passes done to avoid sampling repeated parameters 5 Source code in black_it/samplers/base.py def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_duplication_passes : int = 5 , ) -> None : \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the internal state of the sampler, fixing this numbers the sampler behaves deterministically max_duplication_passes: maximum number of duplication passes done to avoid sampling repeated parameters \"\"\" self . random_state : Optional [ int ] = random_state self . batch_size : int = batch_size self . max_duplication_passes = max_duplication_passes find_and_get_duplicates ( new_points , existing_points ) staticmethod Find the points in 'new_points' that are already present in 'existing_points'. Parameters: Name Type Description Default new_points ndarray candidates points for the sampler required existing_points ndarray previously sampled points required Returns: Type Description List the location of the duplicates in 'new_points' Source code in black_it/samplers/base.py @staticmethod def find_and_get_duplicates ( new_points : NDArray [ np . float64 ], existing_points : NDArray [ np . float64 ] ) -> List : \"\"\"Find the points in 'new_points' that are already present in 'existing_points'. Args: new_points: candidates points for the sampler existing_points: previously sampled points Returns: the location of the duplicates in 'new_points' \"\"\" all_points = np . concatenate (( existing_points , new_points )) unq , count = np . unique ( all_points , axis = 0 , return_counts = True ) repeated_groups = unq [ count > 1 ] repeated_pos = [] if len ( repeated_groups ) > 0 : for repeated_group in repeated_groups : repeated_idx = np . argwhere ( np . all ( new_points == repeated_group , axis = 1 )) for index in repeated_idx : repeated_pos . append ( index [ 0 ]) return repeated_pos sample ( self , search_space , existing_points , existing_losses ) Sample from the search space. Parameters: Name Type Description Default search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the sampled parameters Source code in black_it/samplers/base.py def sample ( self , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" samples = self . sample_batch ( self . batch_size , search_space , existing_points , existing_losses ) for n in range ( self . max_duplication_passes ): duplicates = self . find_and_get_duplicates ( samples , existing_points ) num_duplicates = len ( duplicates ) if num_duplicates == 0 : break new_samples = self . sample_batch ( num_duplicates , search_space , existing_points , existing_losses ) samples [ duplicates ] = new_samples if n == self . max_duplication_passes - 1 : print ( f \"Warning: Repeated samples still found after { self . max_duplication_passes } duplication passes.\" \" This is probably due to a small search space.\" ) return samples sample_batch ( self , batch_size , search_space , existing_points , existing_losses ) Sample a number of new parameters fixed by the 'batch_size' attribute. Parameters: Name Type Description Default batch_size int number of samples to collect required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the new parameters Source code in black_it/samplers/base.py @abstractmethod def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample a number of new parameters fixed by the 'batch_size' attribute. Args: batch_size: number of samples to collect search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the new parameters \"\"\" black_it.samplers.random_uniform.RandomUniformSampler ( BaseSampler ) Random uniform sampling. sample_batch ( self , batch_size , search_space , existing_points , existing_losses ) Sample uniformly from the search space. Parameters: Name Type Description Default batch_size int the number of points to sample required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the sampled parameters (an array of shape (self.batch_size, search_space.dims) ) black_it.samplers.halton.HaltonSampler ( BaseSampler ) Halton low discrepancy sequence. This snippet implements the Halton sequence following the generalization of a sequence of Van der Corput in n-dimensions. random_state : Optional [ int ] property writable Get the random state. __init__ ( self , batch_size , random_state = None , max_deduplication_passes = 5 ) special Initialize the sampler. Parameters: Name Type Description Default batch_size int the number of points sampled every time the sampler is called required random_state Optional[int] the random state of the sampler, fixing this number the sampler behaves deterministically None max_deduplication_passes int the maximum number of sample deduplication passes. 5 sample_batch ( self , batch_size , search_space , existing_points , existing_losses ) Sample points using Halton sequence. Parameters: Name Type Description Default batch_size int the number of samples required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled (not used) required existing_losses ndarray the loss corresponding to the sampled parameters (not used) required Returns: Type Description ndarray the parameter sampled black_it.samplers.r_sequence.RSequenceSampler ( BaseSampler ) The R-sequence sampler. Source code in black_it/samplers/r_sequence.py class RSequenceSampler ( BaseSampler ): \"\"\"The R-sequence sampler.\"\"\" def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , ) -> None : \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: (non-negative integer) the maximum number of deduplication passes that are made after every batch sampling. Default: 0, i.e. no deduplication happens. \"\"\" super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . _sequence_index : int self . _sequence_start : float self . _reset () @classmethod def compute_phi ( cls , nb_dims : int ) -> float : \"\"\" Get an approximation of phi^nb_dims. Args: nb_dims: the number of dimensions. Returns: phi^nb_dims \"\"\" check_arg ( 1 <= nb_dims , f \"nb_dims should be greater than 0, got { nb_dims } \" ) phi : float = 2.0 old_phi = None while old_phi != phi : old_phi = phi phi = pow ( 1 + phi , 1.0 / ( nb_dims + 1 )) return phi @property def random_state ( self ) -> Optional [ int ]: \"\"\"Get the random state.\"\"\" return self . _random_state @random_state . setter def random_state ( self , random_state : Optional [ int ]) -> None : \"\"\"Set the random state.\"\"\" self . _random_state = random_state self . _random_generator = default_rng ( self . random_state ) self . _reset () def _reset ( self ) -> None : \"\"\"Reset the index of the sequence.\"\"\" self . _sequence_index = self . random_generator . integers ( _MIN_SEQUENCE_START_INDEX , _MAX_SEQUENCE_START_INDEX ) self . _sequence_start = self . random_generator . random () def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample points using the R-sequence. Args: batch_size: the number of samples search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled (not used) existing_losses: the loss corresponding to the sampled parameters (not used) Returns: the parameter sampled \"\"\" unit_cube_points : NDArray [ np . float64 ] = self . _r_sequence ( batch_size , search_space . dims ) p_bounds : NDArray [ np . float64 ] = search_space . parameters_bounds sampled_points = p_bounds [ 0 ] + unit_cube_points * ( p_bounds [ 1 ] - p_bounds [ 0 ]) return digitize_data ( sampled_points , search_space . param_grid ) def _r_sequence ( self , nb_samples : int , dims : int ) -> NDArray [ np . float64 ]: \"\"\" Compute the R-sequence (http://extremelearning.com.au/unreasonable-effectiveness-of-quasirandom-sequences/). Args: nb_samples: number of points to sample dims: the number of dimensions Returns: Set of params uniformly placed in d-dimensional unit cube. \"\"\" phi = self . compute_phi ( dims ) alpha : NDArray [ np . float64 ] = np . power ( 1 / phi , np . arange ( 1 , dims + 1 )) . reshape ( ( 1 , - 1 ) ) end_index = self . _sequence_index + nb_samples indexes = np . arange ( self . _sequence_index , end_index ) . reshape (( - 1 , 1 )) points : NDArray [ np . float64 ] = ( self . _sequence_start + indexes . dot ( alpha )) % 1 self . _sequence_index = end_index return points random_state : Optional [ int ] property writable Get the random state. __init__ ( self , batch_size , random_state = None , max_deduplication_passes = 5 ) special Initialize the sampler. Parameters: Name Type Description Default batch_size int the number of points sampled every time the sampler is called required random_state Optional[int] the random state of the sampler, fixing this number the sampler behaves deterministically None max_deduplication_passes int (non-negative integer) the maximum number of deduplication passes that are made after every batch sampling. Default: 0, i.e. no deduplication happens. 5 Source code in black_it/samplers/r_sequence.py def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , ) -> None : \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: (non-negative integer) the maximum number of deduplication passes that are made after every batch sampling. Default: 0, i.e. no deduplication happens. \"\"\" super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . _sequence_index : int self . _sequence_start : float self . _reset () compute_phi ( nb_dims ) classmethod Get an approximation of phi^nb_dims. Parameters: Name Type Description Default nb_dims int the number of dimensions. required Returns: Type Description float phi^nb_dims Source code in black_it/samplers/r_sequence.py @classmethod def compute_phi ( cls , nb_dims : int ) -> float : \"\"\" Get an approximation of phi^nb_dims. Args: nb_dims: the number of dimensions. Returns: phi^nb_dims \"\"\" check_arg ( 1 <= nb_dims , f \"nb_dims should be greater than 0, got { nb_dims } \" ) phi : float = 2.0 old_phi = None while old_phi != phi : old_phi = phi phi = pow ( 1 + phi , 1.0 / ( nb_dims + 1 )) return phi sample_batch ( self , batch_size , search_space , existing_points , existing_losses ) Sample points using the R-sequence. Parameters: Name Type Description Default batch_size int the number of samples required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled (not used) required existing_losses ndarray the loss corresponding to the sampled parameters (not used) required Returns: Type Description ndarray the parameter sampled Source code in black_it/samplers/r_sequence.py def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample points using the R-sequence. Args: batch_size: the number of samples search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled (not used) existing_losses: the loss corresponding to the sampled parameters (not used) Returns: the parameter sampled \"\"\" unit_cube_points : NDArray [ np . float64 ] = self . _r_sequence ( batch_size , search_space . dims ) p_bounds : NDArray [ np . float64 ] = search_space . parameters_bounds sampled_points = p_bounds [ 0 ] + unit_cube_points * ( p_bounds [ 1 ] - p_bounds [ 0 ]) return digitize_data ( sampled_points , search_space . param_grid ) black_it.samplers.best_batch.BestBatchSampler ( BaseSampler ) This class implements the best-batch sampler. Source code in black_it/samplers/best_batch.py class BestBatchSampler ( BaseSampler ): \"\"\"This class implements the best-batch sampler.\"\"\" def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space using a genetic algorithm. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters (an array of shape `(self.batch_size, search_space.dims)`) \"\"\" if len ( existing_points ) < batch_size : raise ValueError ( \"best-batch sampler requires a number of existing points \" f \"which is at least the batch size { batch_size } , \" f \"got { len ( existing_points ) } \" ) # sort existing params candidate_points : NDArray [ np . float64 ] = existing_points [ np . argsort ( existing_losses ) ][: batch_size , :] candidate_point_indexes : NDArray [ np . int64 ] = self . random_generator . integers ( 0 , batch_size , size = batch_size ) sampled_points : NDArray [ np . float64 ] = np . copy ( candidate_points [ candidate_point_indexes ] ) beta_binom_rv = betabinom ( n = search_space . dims - 1 , a = 3.0 , b = 1.0 ) beta_binom_rv . random_state = self . random_generator for sampled_point in sampled_points : num_shocks : NDArray [ np . int64 ] = beta_binom_rv . rvs ( size = 1 ) + 1 params_shocked : NDArray [ np . int64 ] = self . random_generator . choice ( search_space . dims , tuple ( num_shocks ), replace = False ) for index in params_shocked : shock_size : int = self . random_generator . integers ( 1 , 6 ) shock_sign : int = ( self . random_generator . integers ( 0 , 2 ) * 2 ) - 1 delta : float = search_space . parameters_precision [ index ] shift : float = delta * shock_sign * shock_size sampled_point [ index ] += shift sampled_point [ index ] = np . clip ( sampled_point [ index ], search_space . parameters_bounds [ 0 ][ index ], search_space . parameters_bounds [ 1 ][ index ], ) return sampled_points sample_batch ( self , batch_size , search_space , existing_points , existing_losses ) Sample from the search space using a genetic algorithm. Parameters: Name Type Description Default batch_size int the number of points to sample required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the sampled parameters (an array of shape (self.batch_size, search_space.dims) ) Source code in black_it/samplers/best_batch.py def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space using a genetic algorithm. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters (an array of shape `(self.batch_size, search_space.dims)`) \"\"\" if len ( existing_points ) < batch_size : raise ValueError ( \"best-batch sampler requires a number of existing points \" f \"which is at least the batch size { batch_size } , \" f \"got { len ( existing_points ) } \" ) # sort existing params candidate_points : NDArray [ np . float64 ] = existing_points [ np . argsort ( existing_losses ) ][: batch_size , :] candidate_point_indexes : NDArray [ np . int64 ] = self . random_generator . integers ( 0 , batch_size , size = batch_size ) sampled_points : NDArray [ np . float64 ] = np . copy ( candidate_points [ candidate_point_indexes ] ) beta_binom_rv = betabinom ( n = search_space . dims - 1 , a = 3.0 , b = 1.0 ) beta_binom_rv . random_state = self . random_generator for sampled_point in sampled_points : num_shocks : NDArray [ np . int64 ] = beta_binom_rv . rvs ( size = 1 ) + 1 params_shocked : NDArray [ np . int64 ] = self . random_generator . choice ( search_space . dims , tuple ( num_shocks ), replace = False ) for index in params_shocked : shock_size : int = self . random_generator . integers ( 1 , 6 ) shock_sign : int = ( self . random_generator . integers ( 0 , 2 ) * 2 ) - 1 delta : float = search_space . parameters_precision [ index ] shift : float = delta * shock_sign * shock_size sampled_point [ index ] += shift sampled_point [ index ] = np . clip ( sampled_point [ index ], search_space . parameters_bounds [ 0 ][ index ], search_space . parameters_bounds [ 1 ][ index ], ) return sampled_points black_it.samplers.gaussian_process.GaussianProcessSampler ( BaseSampler ) This class implements the Gaussian process-based sampler. In particular, the sampling is based on a Gaussian Process interpolation of the loss function. Note: this class is a wrapper of the GPRegression model of the GPy package. Source code in black_it/samplers/gaussian_process.py class GaussianProcessSampler ( BaseSampler ): \"\"\" This class implements the Gaussian process-based sampler. In particular, the sampling is based on a Gaussian Process interpolation of the loss function. Note: this class is a wrapper of the GPRegression model of the GPy package. \"\"\" def __init__ ( # pylint: disable=too-many-arguments self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , candidate_pool_size : Optional [ int ] = None , max_iters : int = 1000 , optimize_restarts : int = 5 , acquisition : str = \"expected_improvement\" , ): \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: the maximum number of deduplication passes that are made candidate_pool_size: number of randomly sampled points on which the random forest predictions are evaluated max_iters: maximum number of iteration in the optimization of the GP hyperparameters optimize_restarts: number of independent random trials of the optimization of the GP hyperparameters acquisition: type of acquisition function, it can be 'expected_improvement' of simply 'mean' \"\"\" self . _validate_acquisition ( acquisition ) super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . max_iters = max_iters self . optimize_restarts = optimize_restarts self . acquisition = acquisition self . _gpmodel : Optional [ GPRegression ] = None self . _candidate_pool_size = candidate_pool_size def _get_candidate_pool_size ( self , nb_samples : int ) -> int : \"\"\" Get the candidate pool size according to the object configuration. If the candidate pool size has been fixed at initialization time, by passing it as argument of the constructor, then return it. Otherwise, return the number of samples requested times 1000. Args: nb_samples: the number of samples required by sample_batch. Returns: the size of the candidate pool \"\"\" candidate_pool_size = ( self . _candidate_pool_size if self . _candidate_pool_size is not None else 1000 * nb_samples ) return candidate_pool_size def _get_candidate_pool ( self , nb_samples : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\"Get the candidate pool for sampling a batch.\"\"\" candidate_pool_size = self . _get_candidate_pool_size ( nb_samples ) sampler = RandomUniformSampler ( batch_size = candidate_pool_size , random_state = self . _get_random_seed () ) # note the \"sample_batch\" method does not remove duplicates while the \"sample\" method does candidates = sampler . sample_batch ( candidate_pool_size , search_space , existing_points , existing_losses ) return candidates @staticmethod def _validate_acquisition ( acquisition : str ) -> None : \"\"\" Check that the required acquisition is among the supported ones. Args: acquisition: the acquisition provided as input of the constructor. Raises ValueError: if the provided acquisition type is not among the allowed ones. \"\"\" try : _AcquisitionTypes ( acquisition ) except ValueError as e : raise ValueError ( \"expected one of the following acquisition types: \" f \"[ { ' ' . join ( map ( str , _AcquisitionTypes )) } ], \" f \"got { acquisition } \" ) from e def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" X , Y = existing_points , np . atleast_2d ( existing_losses ) . T if X . shape [ 0 ] > 500 : raise RuntimeWarning ( \"Standard GP evaluations can be expensive for large datasets, consider implementing a sparse GP\" ) # initialize GP class from GPy with a Matern kernel by default kern = GPy . kern . Matern52 ( search_space . dims , variance = 1.0 , ARD = False ) noise_var = Y . var () * 0.01 self . _gpmodel = GPRegression ( X , Y , kernel = kern , noise_var = noise_var , mean_function = None ) # Make sure we do not get ridiculously small residual noise variance self . _gpmodel . Gaussian_noise . constrain_bounded ( 1e-9 , 1e6 , warning = False ) # constrain_positive(warning=False) # we need to set the seed globally for GPy optimisations # to give reproducible results np . random . seed ( self . _get_random_seed ()) random . seed ( self . _get_random_seed ()) if self . max_iters > 0 : # --- update the model maximizing the marginal likelihood. if self . optimize_restarts == 1 : self . _gpmodel . optimize ( optimizer = \"bfgs\" , max_iters = self . max_iters , messages = False , ipython_notebook = False , ) else : self . _gpmodel . optimize_restarts ( num_restarts = self . optimize_restarts , optimizer = \"bfgs\" , max_iters = self . max_iters , verbose = False , ) # Get large candidate pool candidates : NDArray [ np . float64 ] = self . _get_candidate_pool ( batch_size , search_space , existing_points , existing_losses ) # predict mean or expected improvement on the full sample set if self . acquisition == _AcquisitionTypes . EI . value : # minus sign needed for subsequent sorting candidates_score = - self . _predict_EI ( candidates )[:, 0 ] else : # acquisition is \"mean\" candidates_score = self . _predict_mean_std ( candidates )[ 0 ][:, 0 ] sorting_indices = np . argsort ( candidates_score ) sampled_points = candidates [ sorting_indices ][: batch_size , :] return digitize_data ( sampled_points , search_space . param_grid ) def _predict_mean_std ( self , X : NDArray [ np . float64 ] ) -> Tuple [ NDArray [ np . float64 ], NDArray [ np . float64 ]]: \"\"\" Predict mean and standard deviation of a fitted GP. Args: X: the points on which the predictions should be performed Returns: The pair (mean, std). \"\"\" gpmodel = cast ( GPRegression , self . _gpmodel ) X = X [ None , :] if X . ndim == 1 else X m , v = gpmodel . predict ( X , full_cov = False , include_likelihood = True ) v = np . clip ( v , 1e-10 , np . inf ) return m , np . sqrt ( v ) def _get_fmin ( self ) -> float : \"\"\"Return the location where the posterior mean is takes its minimal value.\"\"\" gpmodel = cast ( GPRegression , self . _gpmodel ) return gpmodel . predict ( gpmodel . X )[ 0 ] . min () def _predict_EI ( self , X : NDArray [ np . float64 ], jitter : float = 0.1 ) -> NDArray [ np . float64 ]: \"\"\" Compute the Expected Improvement per unit of cost. Args: X: the points on which the predictions should be performed jitter: positive value to make the acquisition more explorative. Returns: the expected improvement. \"\"\" m , s = self . _predict_mean_std ( X ) fmin = self . _get_fmin () phi , Phi , u = get_quantiles ( jitter , fmin , m , s ) f_acqu = s * ( u * Phi + phi ) return f_acqu __init__ ( self , batch_size , random_state = None , max_deduplication_passes = 5 , candidate_pool_size = None , max_iters = 1000 , optimize_restarts = 5 , acquisition = 'expected_improvement' ) special Initialize the sampler. Parameters: Name Type Description Default batch_size int the number of points sampled every time the sampler is called required random_state Optional[int] the random state of the sampler, fixing this number the sampler behaves deterministically None max_deduplication_passes int the maximum number of deduplication passes that are made 5 candidate_pool_size Optional[int] number of randomly sampled points on which the random forest predictions are evaluated None max_iters int maximum number of iteration in the optimization of the GP hyperparameters 1000 optimize_restarts int number of independent random trials of the optimization of the GP hyperparameters 5 acquisition str type of acquisition function, it can be 'expected_improvement' of simply 'mean' 'expected_improvement' Source code in black_it/samplers/gaussian_process.py def __init__ ( # pylint: disable=too-many-arguments self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , candidate_pool_size : Optional [ int ] = None , max_iters : int = 1000 , optimize_restarts : int = 5 , acquisition : str = \"expected_improvement\" , ): \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: the maximum number of deduplication passes that are made candidate_pool_size: number of randomly sampled points on which the random forest predictions are evaluated max_iters: maximum number of iteration in the optimization of the GP hyperparameters optimize_restarts: number of independent random trials of the optimization of the GP hyperparameters acquisition: type of acquisition function, it can be 'expected_improvement' of simply 'mean' \"\"\" self . _validate_acquisition ( acquisition ) super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . max_iters = max_iters self . optimize_restarts = optimize_restarts self . acquisition = acquisition self . _gpmodel : Optional [ GPRegression ] = None self . _candidate_pool_size = candidate_pool_size sample_batch ( self , batch_size , search_space , existing_points , existing_losses ) Sample from the search space. Parameters: Name Type Description Default batch_size int the number of points to sample required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the sampled parameters Source code in black_it/samplers/gaussian_process.py def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" X , Y = existing_points , np . atleast_2d ( existing_losses ) . T if X . shape [ 0 ] > 500 : raise RuntimeWarning ( \"Standard GP evaluations can be expensive for large datasets, consider implementing a sparse GP\" ) # initialize GP class from GPy with a Matern kernel by default kern = GPy . kern . Matern52 ( search_space . dims , variance = 1.0 , ARD = False ) noise_var = Y . var () * 0.01 self . _gpmodel = GPRegression ( X , Y , kernel = kern , noise_var = noise_var , mean_function = None ) # Make sure we do not get ridiculously small residual noise variance self . _gpmodel . Gaussian_noise . constrain_bounded ( 1e-9 , 1e6 , warning = False ) # constrain_positive(warning=False) # we need to set the seed globally for GPy optimisations # to give reproducible results np . random . seed ( self . _get_random_seed ()) random . seed ( self . _get_random_seed ()) if self . max_iters > 0 : # --- update the model maximizing the marginal likelihood. if self . optimize_restarts == 1 : self . _gpmodel . optimize ( optimizer = \"bfgs\" , max_iters = self . max_iters , messages = False , ipython_notebook = False , ) else : self . _gpmodel . optimize_restarts ( num_restarts = self . optimize_restarts , optimizer = \"bfgs\" , max_iters = self . max_iters , verbose = False , ) # Get large candidate pool candidates : NDArray [ np . float64 ] = self . _get_candidate_pool ( batch_size , search_space , existing_points , existing_losses ) # predict mean or expected improvement on the full sample set if self . acquisition == _AcquisitionTypes . EI . value : # minus sign needed for subsequent sorting candidates_score = - self . _predict_EI ( candidates )[:, 0 ] else : # acquisition is \"mean\" candidates_score = self . _predict_mean_std ( candidates )[ 0 ][:, 0 ] sorting_indices = np . argsort ( candidates_score ) sampled_points = candidates [ sorting_indices ][: batch_size , :] return digitize_data ( sampled_points , search_space . param_grid ) black_it.samplers.random_forest.RandomForestSampler ( BaseSampler ) This class implements random forest sampling. Source code in black_it/samplers/random_forest.py class RandomForestSampler ( BaseSampler ): \"\"\"This class implements random forest sampling.\"\"\" def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , candidate_pool_size : Optional [ int ] = None , n_estimators : int = 500 , criterion : str = \"gini\" , ) -> None : \"\"\" Random forest sampling. Note: this class is a wrapper of sklearn.ensemble.RandomForestClassifier. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: the maximum number of deduplication passes candidate_pool_size: number of randomly sampled points on which the random forest predictions are evaluated n_estimators: number of trees in the forest criterion: The function to measure the quality of a split. \"\"\" super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . _n_estimators = n_estimators self . _criterion = criterion if candidate_pool_size is not None : self . _candidate_pool_size = candidate_pool_size else : self . _candidate_pool_size = 1000 * batch_size @property def n_estimators ( self ) -> int : \"\"\"Get the number of estimators.\"\"\" return self . _n_estimators @property def criterion ( self ) -> str : \"\"\"Get the criterion.\"\"\" return self . _criterion @property def candidate_pool_size ( self ) -> int : \"\"\"Get the candidate pool size.\"\"\" return self . _candidate_pool_size def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" # Get large candidate pool candidates = RandomUniformSampler ( self . candidate_pool_size , random_state = self . _get_random_seed () ) . sample_batch ( self . candidate_pool_size , search_space , existing_points , existing_losses ) # Train surrogate x : NDArray [ np . float64 ] y : NDArray [ np . int64 ] x , y , _existing_points_quantiles = self . prepare_data_for_classifier ( existing_points , existing_losses ) classifier : RandomForestClassifier = RandomForestClassifier ( n_estimators = self . n_estimators , criterion = self . criterion , n_jobs =- 1 , random_state = self . _get_random_seed (), ) classifier . fit ( x , y ) # Predict quantiles predicted_points_quantiles : NDArray [ np . float64 ] = classifier . predict ( candidates ) # Sort params by predicted quantile sorting_indices : NDArray [ np . float64 ] = np . argsort ( predicted_points_quantiles ) sampled_points : NDArray [ np . float64 ] = candidates [ sorting_indices ][: batch_size ] return digitize_data ( sampled_points , search_space . param_grid ) @staticmethod def prepare_data_for_classifier ( existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], num_bins : int = 10 , ) -> Tuple [ NDArray [ np . float64 ], NDArray [ np . int64 ], NDArray [ np . float64 ]]: \"\"\" Prepare data for the classifier. Args: existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters num_bins: the number of bins Returns: A triple (x, y, quantiles), where - x is the vector of training data - y is the vector of targets - the quantiles \"\"\" x : NDArray [ np . float64 ] = existing_points y : NDArray [ np . float64 ] = existing_losses cutoffs : NDArray [ np . float64 ] = np . linspace ( 0 , 1 , num_bins + 1 ) quantiles : NDArray [ np . float64 ] = np . zeros ( num_bins + 1 ) for i in range ( num_bins - 1 ): quantiles [ i + 1 ] = np . quantile ( y , cutoffs [ i + 1 ]) quantiles [ - 1 ] = np . max ( y ) y_cat : NDArray [ np . int64 ] = np . digitize ( y , quantiles , right = True ) y_cat = y_cat - 1 return x , y_cat , quantiles candidate_pool_size : int property readonly Get the candidate pool size. criterion : str property readonly Get the criterion. n_estimators : int property readonly Get the number of estimators. __init__ ( self , batch_size , random_state = None , max_deduplication_passes = 5 , candidate_pool_size = None , n_estimators = 500 , criterion = 'gini' ) special Random forest sampling. Note: this class is a wrapper of sklearn.ensemble.RandomForestClassifier. Parameters: Name Type Description Default batch_size int the number of points sampled every time the sampler is called required random_state Optional[int] the random state of the sampler, fixing this number the sampler behaves deterministically None max_deduplication_passes int the maximum number of deduplication passes 5 candidate_pool_size Optional[int] number of randomly sampled points on which the random forest predictions are evaluated None n_estimators int number of trees in the forest 500 criterion str The function to measure the quality of a split. 'gini' Source code in black_it/samplers/random_forest.py def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , candidate_pool_size : Optional [ int ] = None , n_estimators : int = 500 , criterion : str = \"gini\" , ) -> None : \"\"\" Random forest sampling. Note: this class is a wrapper of sklearn.ensemble.RandomForestClassifier. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: the maximum number of deduplication passes candidate_pool_size: number of randomly sampled points on which the random forest predictions are evaluated n_estimators: number of trees in the forest criterion: The function to measure the quality of a split. \"\"\" super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . _n_estimators = n_estimators self . _criterion = criterion if candidate_pool_size is not None : self . _candidate_pool_size = candidate_pool_size else : self . _candidate_pool_size = 1000 * batch_size prepare_data_for_classifier ( existing_points , existing_losses , num_bins = 10 ) staticmethod Prepare data for the classifier. Parameters: Name Type Description Default existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required num_bins int the number of bins 10 Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray] A triple (x, y, quantiles), where - x is the vector of training data - y is the vector of targets - the quantiles Source code in black_it/samplers/random_forest.py @staticmethod def prepare_data_for_classifier ( existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], num_bins : int = 10 , ) -> Tuple [ NDArray [ np . float64 ], NDArray [ np . int64 ], NDArray [ np . float64 ]]: \"\"\" Prepare data for the classifier. Args: existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters num_bins: the number of bins Returns: A triple (x, y, quantiles), where - x is the vector of training data - y is the vector of targets - the quantiles \"\"\" x : NDArray [ np . float64 ] = existing_points y : NDArray [ np . float64 ] = existing_losses cutoffs : NDArray [ np . float64 ] = np . linspace ( 0 , 1 , num_bins + 1 ) quantiles : NDArray [ np . float64 ] = np . zeros ( num_bins + 1 ) for i in range ( num_bins - 1 ): quantiles [ i + 1 ] = np . quantile ( y , cutoffs [ i + 1 ]) quantiles [ - 1 ] = np . max ( y ) y_cat : NDArray [ np . int64 ] = np . digitize ( y , quantiles , right = True ) y_cat = y_cat - 1 return x , y_cat , quantiles sample_batch ( self , batch_size , search_space , existing_points , existing_losses ) Sample from the search space. Parameters: Name Type Description Default batch_size int the number of points to sample required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the sampled parameters Source code in black_it/samplers/random_forest.py def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" # Get large candidate pool candidates = RandomUniformSampler ( self . candidate_pool_size , random_state = self . _get_random_seed () ) . sample_batch ( self . candidate_pool_size , search_space , existing_points , existing_losses ) # Train surrogate x : NDArray [ np . float64 ] y : NDArray [ np . int64 ] x , y , _existing_points_quantiles = self . prepare_data_for_classifier ( existing_points , existing_losses ) classifier : RandomForestClassifier = RandomForestClassifier ( n_estimators = self . n_estimators , criterion = self . criterion , n_jobs =- 1 , random_state = self . _get_random_seed (), ) classifier . fit ( x , y ) # Predict quantiles predicted_points_quantiles : NDArray [ np . float64 ] = classifier . predict ( candidates ) # Sort params by predicted quantile sorting_indices : NDArray [ np . float64 ] = np . argsort ( predicted_points_quantiles ) sampled_points : NDArray [ np . float64 ] = candidates [ sorting_indices ][: batch_size ] return digitize_data ( sampled_points , search_space . param_grid )","title":"Samplers"},{"location":"samplers/#black_it.samplers.base.BaseSampler","text":"BaseSampler interface. This is the base class for all samplers. Source code in black_it/samplers/base.py class BaseSampler ( ABC ): \"\"\" BaseSampler interface. This is the base class for all samplers. \"\"\" def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_duplication_passes : int = 5 , ) -> None : \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the internal state of the sampler, fixing this numbers the sampler behaves deterministically max_duplication_passes: maximum number of duplication passes done to avoid sampling repeated parameters \"\"\" self . random_state : Optional [ int ] = random_state self . batch_size : int = batch_size self . max_duplication_passes = max_duplication_passes @property def random_state ( self ) -> Optional [ int ]: \"\"\"Get the random state.\"\"\" return self . _random_state @random_state . setter def random_state ( self , random_state : Optional [ int ]) -> None : \"\"\"Set the random state.\"\"\" self . _random_state = random_state self . _random_generator = default_rng ( self . random_state ) @property def random_generator ( self ) -> np . random . Generator : \"\"\"Get the random generator.\"\"\" return self . _random_generator def _get_random_seed ( self ) -> int : \"\"\"Get new random seed from the current random generator.\"\"\" return get_random_seed ( self . _random_generator ) @abstractmethod def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample a number of new parameters fixed by the 'batch_size' attribute. Args: batch_size: number of samples to collect search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the new parameters \"\"\" def sample ( self , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" samples = self . sample_batch ( self . batch_size , search_space , existing_points , existing_losses ) for n in range ( self . max_duplication_passes ): duplicates = self . find_and_get_duplicates ( samples , existing_points ) num_duplicates = len ( duplicates ) if num_duplicates == 0 : break new_samples = self . sample_batch ( num_duplicates , search_space , existing_points , existing_losses ) samples [ duplicates ] = new_samples if n == self . max_duplication_passes - 1 : print ( f \"Warning: Repeated samples still found after { self . max_duplication_passes } duplication passes.\" \" This is probably due to a small search space.\" ) return samples @staticmethod def find_and_get_duplicates ( new_points : NDArray [ np . float64 ], existing_points : NDArray [ np . float64 ] ) -> List : \"\"\"Find the points in 'new_points' that are already present in 'existing_points'. Args: new_points: candidates points for the sampler existing_points: previously sampled points Returns: the location of the duplicates in 'new_points' \"\"\" all_points = np . concatenate (( existing_points , new_points )) unq , count = np . unique ( all_points , axis = 0 , return_counts = True ) repeated_groups = unq [ count > 1 ] repeated_pos = [] if len ( repeated_groups ) > 0 : for repeated_group in repeated_groups : repeated_idx = np . argwhere ( np . all ( new_points == repeated_group , axis = 1 )) for index in repeated_idx : repeated_pos . append ( index [ 0 ]) return repeated_pos","title":"BaseSampler"},{"location":"samplers/#black_it.samplers.base.BaseSampler.random_generator","text":"Get the random generator.","title":"random_generator"},{"location":"samplers/#black_it.samplers.base.BaseSampler.random_state","text":"Get the random state.","title":"random_state"},{"location":"samplers/#black_it.samplers.base.BaseSampler.__init__","text":"Initialize the sampler. Parameters: Name Type Description Default batch_size int the number of points sampled every time the sampler is called required random_state Optional[int] the internal state of the sampler, fixing this numbers the sampler behaves deterministically None max_duplication_passes int maximum number of duplication passes done to avoid sampling repeated parameters 5 Source code in black_it/samplers/base.py def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_duplication_passes : int = 5 , ) -> None : \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the internal state of the sampler, fixing this numbers the sampler behaves deterministically max_duplication_passes: maximum number of duplication passes done to avoid sampling repeated parameters \"\"\" self . random_state : Optional [ int ] = random_state self . batch_size : int = batch_size self . max_duplication_passes = max_duplication_passes","title":"__init__()"},{"location":"samplers/#black_it.samplers.base.BaseSampler.find_and_get_duplicates","text":"Find the points in 'new_points' that are already present in 'existing_points'. Parameters: Name Type Description Default new_points ndarray candidates points for the sampler required existing_points ndarray previously sampled points required Returns: Type Description List the location of the duplicates in 'new_points' Source code in black_it/samplers/base.py @staticmethod def find_and_get_duplicates ( new_points : NDArray [ np . float64 ], existing_points : NDArray [ np . float64 ] ) -> List : \"\"\"Find the points in 'new_points' that are already present in 'existing_points'. Args: new_points: candidates points for the sampler existing_points: previously sampled points Returns: the location of the duplicates in 'new_points' \"\"\" all_points = np . concatenate (( existing_points , new_points )) unq , count = np . unique ( all_points , axis = 0 , return_counts = True ) repeated_groups = unq [ count > 1 ] repeated_pos = [] if len ( repeated_groups ) > 0 : for repeated_group in repeated_groups : repeated_idx = np . argwhere ( np . all ( new_points == repeated_group , axis = 1 )) for index in repeated_idx : repeated_pos . append ( index [ 0 ]) return repeated_pos","title":"find_and_get_duplicates()"},{"location":"samplers/#black_it.samplers.base.BaseSampler.sample","text":"Sample from the search space. Parameters: Name Type Description Default search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the sampled parameters Source code in black_it/samplers/base.py def sample ( self , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" samples = self . sample_batch ( self . batch_size , search_space , existing_points , existing_losses ) for n in range ( self . max_duplication_passes ): duplicates = self . find_and_get_duplicates ( samples , existing_points ) num_duplicates = len ( duplicates ) if num_duplicates == 0 : break new_samples = self . sample_batch ( num_duplicates , search_space , existing_points , existing_losses ) samples [ duplicates ] = new_samples if n == self . max_duplication_passes - 1 : print ( f \"Warning: Repeated samples still found after { self . max_duplication_passes } duplication passes.\" \" This is probably due to a small search space.\" ) return samples","title":"sample()"},{"location":"samplers/#black_it.samplers.base.BaseSampler.sample_batch","text":"Sample a number of new parameters fixed by the 'batch_size' attribute. Parameters: Name Type Description Default batch_size int number of samples to collect required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the new parameters Source code in black_it/samplers/base.py @abstractmethod def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample a number of new parameters fixed by the 'batch_size' attribute. Args: batch_size: number of samples to collect search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the new parameters \"\"\"","title":"sample_batch()"},{"location":"samplers/#black_it.samplers.random_uniform.RandomUniformSampler","text":"Random uniform sampling.","title":"RandomUniformSampler"},{"location":"samplers/#black_it.samplers.random_uniform.RandomUniformSampler.sample_batch","text":"Sample uniformly from the search space. Parameters: Name Type Description Default batch_size int the number of points to sample required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the sampled parameters (an array of shape (self.batch_size, search_space.dims) )","title":"sample_batch()"},{"location":"samplers/#black_it.samplers.halton.HaltonSampler","text":"Halton low discrepancy sequence. This snippet implements the Halton sequence following the generalization of a sequence of Van der Corput in n-dimensions.","title":"HaltonSampler"},{"location":"samplers/#black_it.samplers.halton.HaltonSampler.random_state","text":"Get the random state.","title":"random_state"},{"location":"samplers/#black_it.samplers.halton.HaltonSampler.__init__","text":"Initialize the sampler. Parameters: Name Type Description Default batch_size int the number of points sampled every time the sampler is called required random_state Optional[int] the random state of the sampler, fixing this number the sampler behaves deterministically None max_deduplication_passes int the maximum number of sample deduplication passes. 5","title":"__init__()"},{"location":"samplers/#black_it.samplers.halton.HaltonSampler.sample_batch","text":"Sample points using Halton sequence. Parameters: Name Type Description Default batch_size int the number of samples required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled (not used) required existing_losses ndarray the loss corresponding to the sampled parameters (not used) required Returns: Type Description ndarray the parameter sampled","title":"sample_batch()"},{"location":"samplers/#black_it.samplers.r_sequence.RSequenceSampler","text":"The R-sequence sampler. Source code in black_it/samplers/r_sequence.py class RSequenceSampler ( BaseSampler ): \"\"\"The R-sequence sampler.\"\"\" def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , ) -> None : \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: (non-negative integer) the maximum number of deduplication passes that are made after every batch sampling. Default: 0, i.e. no deduplication happens. \"\"\" super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . _sequence_index : int self . _sequence_start : float self . _reset () @classmethod def compute_phi ( cls , nb_dims : int ) -> float : \"\"\" Get an approximation of phi^nb_dims. Args: nb_dims: the number of dimensions. Returns: phi^nb_dims \"\"\" check_arg ( 1 <= nb_dims , f \"nb_dims should be greater than 0, got { nb_dims } \" ) phi : float = 2.0 old_phi = None while old_phi != phi : old_phi = phi phi = pow ( 1 + phi , 1.0 / ( nb_dims + 1 )) return phi @property def random_state ( self ) -> Optional [ int ]: \"\"\"Get the random state.\"\"\" return self . _random_state @random_state . setter def random_state ( self , random_state : Optional [ int ]) -> None : \"\"\"Set the random state.\"\"\" self . _random_state = random_state self . _random_generator = default_rng ( self . random_state ) self . _reset () def _reset ( self ) -> None : \"\"\"Reset the index of the sequence.\"\"\" self . _sequence_index = self . random_generator . integers ( _MIN_SEQUENCE_START_INDEX , _MAX_SEQUENCE_START_INDEX ) self . _sequence_start = self . random_generator . random () def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample points using the R-sequence. Args: batch_size: the number of samples search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled (not used) existing_losses: the loss corresponding to the sampled parameters (not used) Returns: the parameter sampled \"\"\" unit_cube_points : NDArray [ np . float64 ] = self . _r_sequence ( batch_size , search_space . dims ) p_bounds : NDArray [ np . float64 ] = search_space . parameters_bounds sampled_points = p_bounds [ 0 ] + unit_cube_points * ( p_bounds [ 1 ] - p_bounds [ 0 ]) return digitize_data ( sampled_points , search_space . param_grid ) def _r_sequence ( self , nb_samples : int , dims : int ) -> NDArray [ np . float64 ]: \"\"\" Compute the R-sequence (http://extremelearning.com.au/unreasonable-effectiveness-of-quasirandom-sequences/). Args: nb_samples: number of points to sample dims: the number of dimensions Returns: Set of params uniformly placed in d-dimensional unit cube. \"\"\" phi = self . compute_phi ( dims ) alpha : NDArray [ np . float64 ] = np . power ( 1 / phi , np . arange ( 1 , dims + 1 )) . reshape ( ( 1 , - 1 ) ) end_index = self . _sequence_index + nb_samples indexes = np . arange ( self . _sequence_index , end_index ) . reshape (( - 1 , 1 )) points : NDArray [ np . float64 ] = ( self . _sequence_start + indexes . dot ( alpha )) % 1 self . _sequence_index = end_index return points","title":"RSequenceSampler"},{"location":"samplers/#black_it.samplers.r_sequence.RSequenceSampler.random_state","text":"Get the random state.","title":"random_state"},{"location":"samplers/#black_it.samplers.r_sequence.RSequenceSampler.__init__","text":"Initialize the sampler. Parameters: Name Type Description Default batch_size int the number of points sampled every time the sampler is called required random_state Optional[int] the random state of the sampler, fixing this number the sampler behaves deterministically None max_deduplication_passes int (non-negative integer) the maximum number of deduplication passes that are made after every batch sampling. Default: 0, i.e. no deduplication happens. 5 Source code in black_it/samplers/r_sequence.py def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , ) -> None : \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: (non-negative integer) the maximum number of deduplication passes that are made after every batch sampling. Default: 0, i.e. no deduplication happens. \"\"\" super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . _sequence_index : int self . _sequence_start : float self . _reset ()","title":"__init__()"},{"location":"samplers/#black_it.samplers.r_sequence.RSequenceSampler.compute_phi","text":"Get an approximation of phi^nb_dims. Parameters: Name Type Description Default nb_dims int the number of dimensions. required Returns: Type Description float phi^nb_dims Source code in black_it/samplers/r_sequence.py @classmethod def compute_phi ( cls , nb_dims : int ) -> float : \"\"\" Get an approximation of phi^nb_dims. Args: nb_dims: the number of dimensions. Returns: phi^nb_dims \"\"\" check_arg ( 1 <= nb_dims , f \"nb_dims should be greater than 0, got { nb_dims } \" ) phi : float = 2.0 old_phi = None while old_phi != phi : old_phi = phi phi = pow ( 1 + phi , 1.0 / ( nb_dims + 1 )) return phi","title":"compute_phi()"},{"location":"samplers/#black_it.samplers.r_sequence.RSequenceSampler.sample_batch","text":"Sample points using the R-sequence. Parameters: Name Type Description Default batch_size int the number of samples required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled (not used) required existing_losses ndarray the loss corresponding to the sampled parameters (not used) required Returns: Type Description ndarray the parameter sampled Source code in black_it/samplers/r_sequence.py def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample points using the R-sequence. Args: batch_size: the number of samples search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled (not used) existing_losses: the loss corresponding to the sampled parameters (not used) Returns: the parameter sampled \"\"\" unit_cube_points : NDArray [ np . float64 ] = self . _r_sequence ( batch_size , search_space . dims ) p_bounds : NDArray [ np . float64 ] = search_space . parameters_bounds sampled_points = p_bounds [ 0 ] + unit_cube_points * ( p_bounds [ 1 ] - p_bounds [ 0 ]) return digitize_data ( sampled_points , search_space . param_grid )","title":"sample_batch()"},{"location":"samplers/#black_it.samplers.best_batch.BestBatchSampler","text":"This class implements the best-batch sampler. Source code in black_it/samplers/best_batch.py class BestBatchSampler ( BaseSampler ): \"\"\"This class implements the best-batch sampler.\"\"\" def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space using a genetic algorithm. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters (an array of shape `(self.batch_size, search_space.dims)`) \"\"\" if len ( existing_points ) < batch_size : raise ValueError ( \"best-batch sampler requires a number of existing points \" f \"which is at least the batch size { batch_size } , \" f \"got { len ( existing_points ) } \" ) # sort existing params candidate_points : NDArray [ np . float64 ] = existing_points [ np . argsort ( existing_losses ) ][: batch_size , :] candidate_point_indexes : NDArray [ np . int64 ] = self . random_generator . integers ( 0 , batch_size , size = batch_size ) sampled_points : NDArray [ np . float64 ] = np . copy ( candidate_points [ candidate_point_indexes ] ) beta_binom_rv = betabinom ( n = search_space . dims - 1 , a = 3.0 , b = 1.0 ) beta_binom_rv . random_state = self . random_generator for sampled_point in sampled_points : num_shocks : NDArray [ np . int64 ] = beta_binom_rv . rvs ( size = 1 ) + 1 params_shocked : NDArray [ np . int64 ] = self . random_generator . choice ( search_space . dims , tuple ( num_shocks ), replace = False ) for index in params_shocked : shock_size : int = self . random_generator . integers ( 1 , 6 ) shock_sign : int = ( self . random_generator . integers ( 0 , 2 ) * 2 ) - 1 delta : float = search_space . parameters_precision [ index ] shift : float = delta * shock_sign * shock_size sampled_point [ index ] += shift sampled_point [ index ] = np . clip ( sampled_point [ index ], search_space . parameters_bounds [ 0 ][ index ], search_space . parameters_bounds [ 1 ][ index ], ) return sampled_points","title":"BestBatchSampler"},{"location":"samplers/#black_it.samplers.best_batch.BestBatchSampler.sample_batch","text":"Sample from the search space using a genetic algorithm. Parameters: Name Type Description Default batch_size int the number of points to sample required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the sampled parameters (an array of shape (self.batch_size, search_space.dims) ) Source code in black_it/samplers/best_batch.py def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space using a genetic algorithm. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters (an array of shape `(self.batch_size, search_space.dims)`) \"\"\" if len ( existing_points ) < batch_size : raise ValueError ( \"best-batch sampler requires a number of existing points \" f \"which is at least the batch size { batch_size } , \" f \"got { len ( existing_points ) } \" ) # sort existing params candidate_points : NDArray [ np . float64 ] = existing_points [ np . argsort ( existing_losses ) ][: batch_size , :] candidate_point_indexes : NDArray [ np . int64 ] = self . random_generator . integers ( 0 , batch_size , size = batch_size ) sampled_points : NDArray [ np . float64 ] = np . copy ( candidate_points [ candidate_point_indexes ] ) beta_binom_rv = betabinom ( n = search_space . dims - 1 , a = 3.0 , b = 1.0 ) beta_binom_rv . random_state = self . random_generator for sampled_point in sampled_points : num_shocks : NDArray [ np . int64 ] = beta_binom_rv . rvs ( size = 1 ) + 1 params_shocked : NDArray [ np . int64 ] = self . random_generator . choice ( search_space . dims , tuple ( num_shocks ), replace = False ) for index in params_shocked : shock_size : int = self . random_generator . integers ( 1 , 6 ) shock_sign : int = ( self . random_generator . integers ( 0 , 2 ) * 2 ) - 1 delta : float = search_space . parameters_precision [ index ] shift : float = delta * shock_sign * shock_size sampled_point [ index ] += shift sampled_point [ index ] = np . clip ( sampled_point [ index ], search_space . parameters_bounds [ 0 ][ index ], search_space . parameters_bounds [ 1 ][ index ], ) return sampled_points","title":"sample_batch()"},{"location":"samplers/#black_it.samplers.gaussian_process.GaussianProcessSampler","text":"This class implements the Gaussian process-based sampler. In particular, the sampling is based on a Gaussian Process interpolation of the loss function. Note: this class is a wrapper of the GPRegression model of the GPy package. Source code in black_it/samplers/gaussian_process.py class GaussianProcessSampler ( BaseSampler ): \"\"\" This class implements the Gaussian process-based sampler. In particular, the sampling is based on a Gaussian Process interpolation of the loss function. Note: this class is a wrapper of the GPRegression model of the GPy package. \"\"\" def __init__ ( # pylint: disable=too-many-arguments self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , candidate_pool_size : Optional [ int ] = None , max_iters : int = 1000 , optimize_restarts : int = 5 , acquisition : str = \"expected_improvement\" , ): \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: the maximum number of deduplication passes that are made candidate_pool_size: number of randomly sampled points on which the random forest predictions are evaluated max_iters: maximum number of iteration in the optimization of the GP hyperparameters optimize_restarts: number of independent random trials of the optimization of the GP hyperparameters acquisition: type of acquisition function, it can be 'expected_improvement' of simply 'mean' \"\"\" self . _validate_acquisition ( acquisition ) super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . max_iters = max_iters self . optimize_restarts = optimize_restarts self . acquisition = acquisition self . _gpmodel : Optional [ GPRegression ] = None self . _candidate_pool_size = candidate_pool_size def _get_candidate_pool_size ( self , nb_samples : int ) -> int : \"\"\" Get the candidate pool size according to the object configuration. If the candidate pool size has been fixed at initialization time, by passing it as argument of the constructor, then return it. Otherwise, return the number of samples requested times 1000. Args: nb_samples: the number of samples required by sample_batch. Returns: the size of the candidate pool \"\"\" candidate_pool_size = ( self . _candidate_pool_size if self . _candidate_pool_size is not None else 1000 * nb_samples ) return candidate_pool_size def _get_candidate_pool ( self , nb_samples : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\"Get the candidate pool for sampling a batch.\"\"\" candidate_pool_size = self . _get_candidate_pool_size ( nb_samples ) sampler = RandomUniformSampler ( batch_size = candidate_pool_size , random_state = self . _get_random_seed () ) # note the \"sample_batch\" method does not remove duplicates while the \"sample\" method does candidates = sampler . sample_batch ( candidate_pool_size , search_space , existing_points , existing_losses ) return candidates @staticmethod def _validate_acquisition ( acquisition : str ) -> None : \"\"\" Check that the required acquisition is among the supported ones. Args: acquisition: the acquisition provided as input of the constructor. Raises ValueError: if the provided acquisition type is not among the allowed ones. \"\"\" try : _AcquisitionTypes ( acquisition ) except ValueError as e : raise ValueError ( \"expected one of the following acquisition types: \" f \"[ { ' ' . join ( map ( str , _AcquisitionTypes )) } ], \" f \"got { acquisition } \" ) from e def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" X , Y = existing_points , np . atleast_2d ( existing_losses ) . T if X . shape [ 0 ] > 500 : raise RuntimeWarning ( \"Standard GP evaluations can be expensive for large datasets, consider implementing a sparse GP\" ) # initialize GP class from GPy with a Matern kernel by default kern = GPy . kern . Matern52 ( search_space . dims , variance = 1.0 , ARD = False ) noise_var = Y . var () * 0.01 self . _gpmodel = GPRegression ( X , Y , kernel = kern , noise_var = noise_var , mean_function = None ) # Make sure we do not get ridiculously small residual noise variance self . _gpmodel . Gaussian_noise . constrain_bounded ( 1e-9 , 1e6 , warning = False ) # constrain_positive(warning=False) # we need to set the seed globally for GPy optimisations # to give reproducible results np . random . seed ( self . _get_random_seed ()) random . seed ( self . _get_random_seed ()) if self . max_iters > 0 : # --- update the model maximizing the marginal likelihood. if self . optimize_restarts == 1 : self . _gpmodel . optimize ( optimizer = \"bfgs\" , max_iters = self . max_iters , messages = False , ipython_notebook = False , ) else : self . _gpmodel . optimize_restarts ( num_restarts = self . optimize_restarts , optimizer = \"bfgs\" , max_iters = self . max_iters , verbose = False , ) # Get large candidate pool candidates : NDArray [ np . float64 ] = self . _get_candidate_pool ( batch_size , search_space , existing_points , existing_losses ) # predict mean or expected improvement on the full sample set if self . acquisition == _AcquisitionTypes . EI . value : # minus sign needed for subsequent sorting candidates_score = - self . _predict_EI ( candidates )[:, 0 ] else : # acquisition is \"mean\" candidates_score = self . _predict_mean_std ( candidates )[ 0 ][:, 0 ] sorting_indices = np . argsort ( candidates_score ) sampled_points = candidates [ sorting_indices ][: batch_size , :] return digitize_data ( sampled_points , search_space . param_grid ) def _predict_mean_std ( self , X : NDArray [ np . float64 ] ) -> Tuple [ NDArray [ np . float64 ], NDArray [ np . float64 ]]: \"\"\" Predict mean and standard deviation of a fitted GP. Args: X: the points on which the predictions should be performed Returns: The pair (mean, std). \"\"\" gpmodel = cast ( GPRegression , self . _gpmodel ) X = X [ None , :] if X . ndim == 1 else X m , v = gpmodel . predict ( X , full_cov = False , include_likelihood = True ) v = np . clip ( v , 1e-10 , np . inf ) return m , np . sqrt ( v ) def _get_fmin ( self ) -> float : \"\"\"Return the location where the posterior mean is takes its minimal value.\"\"\" gpmodel = cast ( GPRegression , self . _gpmodel ) return gpmodel . predict ( gpmodel . X )[ 0 ] . min () def _predict_EI ( self , X : NDArray [ np . float64 ], jitter : float = 0.1 ) -> NDArray [ np . float64 ]: \"\"\" Compute the Expected Improvement per unit of cost. Args: X: the points on which the predictions should be performed jitter: positive value to make the acquisition more explorative. Returns: the expected improvement. \"\"\" m , s = self . _predict_mean_std ( X ) fmin = self . _get_fmin () phi , Phi , u = get_quantiles ( jitter , fmin , m , s ) f_acqu = s * ( u * Phi + phi ) return f_acqu","title":"GaussianProcessSampler"},{"location":"samplers/#black_it.samplers.gaussian_process.GaussianProcessSampler.__init__","text":"Initialize the sampler. Parameters: Name Type Description Default batch_size int the number of points sampled every time the sampler is called required random_state Optional[int] the random state of the sampler, fixing this number the sampler behaves deterministically None max_deduplication_passes int the maximum number of deduplication passes that are made 5 candidate_pool_size Optional[int] number of randomly sampled points on which the random forest predictions are evaluated None max_iters int maximum number of iteration in the optimization of the GP hyperparameters 1000 optimize_restarts int number of independent random trials of the optimization of the GP hyperparameters 5 acquisition str type of acquisition function, it can be 'expected_improvement' of simply 'mean' 'expected_improvement' Source code in black_it/samplers/gaussian_process.py def __init__ ( # pylint: disable=too-many-arguments self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , candidate_pool_size : Optional [ int ] = None , max_iters : int = 1000 , optimize_restarts : int = 5 , acquisition : str = \"expected_improvement\" , ): \"\"\" Initialize the sampler. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: the maximum number of deduplication passes that are made candidate_pool_size: number of randomly sampled points on which the random forest predictions are evaluated max_iters: maximum number of iteration in the optimization of the GP hyperparameters optimize_restarts: number of independent random trials of the optimization of the GP hyperparameters acquisition: type of acquisition function, it can be 'expected_improvement' of simply 'mean' \"\"\" self . _validate_acquisition ( acquisition ) super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . max_iters = max_iters self . optimize_restarts = optimize_restarts self . acquisition = acquisition self . _gpmodel : Optional [ GPRegression ] = None self . _candidate_pool_size = candidate_pool_size","title":"__init__()"},{"location":"samplers/#black_it.samplers.gaussian_process.GaussianProcessSampler.sample_batch","text":"Sample from the search space. Parameters: Name Type Description Default batch_size int the number of points to sample required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the sampled parameters Source code in black_it/samplers/gaussian_process.py def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" X , Y = existing_points , np . atleast_2d ( existing_losses ) . T if X . shape [ 0 ] > 500 : raise RuntimeWarning ( \"Standard GP evaluations can be expensive for large datasets, consider implementing a sparse GP\" ) # initialize GP class from GPy with a Matern kernel by default kern = GPy . kern . Matern52 ( search_space . dims , variance = 1.0 , ARD = False ) noise_var = Y . var () * 0.01 self . _gpmodel = GPRegression ( X , Y , kernel = kern , noise_var = noise_var , mean_function = None ) # Make sure we do not get ridiculously small residual noise variance self . _gpmodel . Gaussian_noise . constrain_bounded ( 1e-9 , 1e6 , warning = False ) # constrain_positive(warning=False) # we need to set the seed globally for GPy optimisations # to give reproducible results np . random . seed ( self . _get_random_seed ()) random . seed ( self . _get_random_seed ()) if self . max_iters > 0 : # --- update the model maximizing the marginal likelihood. if self . optimize_restarts == 1 : self . _gpmodel . optimize ( optimizer = \"bfgs\" , max_iters = self . max_iters , messages = False , ipython_notebook = False , ) else : self . _gpmodel . optimize_restarts ( num_restarts = self . optimize_restarts , optimizer = \"bfgs\" , max_iters = self . max_iters , verbose = False , ) # Get large candidate pool candidates : NDArray [ np . float64 ] = self . _get_candidate_pool ( batch_size , search_space , existing_points , existing_losses ) # predict mean or expected improvement on the full sample set if self . acquisition == _AcquisitionTypes . EI . value : # minus sign needed for subsequent sorting candidates_score = - self . _predict_EI ( candidates )[:, 0 ] else : # acquisition is \"mean\" candidates_score = self . _predict_mean_std ( candidates )[ 0 ][:, 0 ] sorting_indices = np . argsort ( candidates_score ) sampled_points = candidates [ sorting_indices ][: batch_size , :] return digitize_data ( sampled_points , search_space . param_grid )","title":"sample_batch()"},{"location":"samplers/#black_it.samplers.random_forest.RandomForestSampler","text":"This class implements random forest sampling. Source code in black_it/samplers/random_forest.py class RandomForestSampler ( BaseSampler ): \"\"\"This class implements random forest sampling.\"\"\" def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , candidate_pool_size : Optional [ int ] = None , n_estimators : int = 500 , criterion : str = \"gini\" , ) -> None : \"\"\" Random forest sampling. Note: this class is a wrapper of sklearn.ensemble.RandomForestClassifier. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: the maximum number of deduplication passes candidate_pool_size: number of randomly sampled points on which the random forest predictions are evaluated n_estimators: number of trees in the forest criterion: The function to measure the quality of a split. \"\"\" super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . _n_estimators = n_estimators self . _criterion = criterion if candidate_pool_size is not None : self . _candidate_pool_size = candidate_pool_size else : self . _candidate_pool_size = 1000 * batch_size @property def n_estimators ( self ) -> int : \"\"\"Get the number of estimators.\"\"\" return self . _n_estimators @property def criterion ( self ) -> str : \"\"\"Get the criterion.\"\"\" return self . _criterion @property def candidate_pool_size ( self ) -> int : \"\"\"Get the candidate pool size.\"\"\" return self . _candidate_pool_size def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" # Get large candidate pool candidates = RandomUniformSampler ( self . candidate_pool_size , random_state = self . _get_random_seed () ) . sample_batch ( self . candidate_pool_size , search_space , existing_points , existing_losses ) # Train surrogate x : NDArray [ np . float64 ] y : NDArray [ np . int64 ] x , y , _existing_points_quantiles = self . prepare_data_for_classifier ( existing_points , existing_losses ) classifier : RandomForestClassifier = RandomForestClassifier ( n_estimators = self . n_estimators , criterion = self . criterion , n_jobs =- 1 , random_state = self . _get_random_seed (), ) classifier . fit ( x , y ) # Predict quantiles predicted_points_quantiles : NDArray [ np . float64 ] = classifier . predict ( candidates ) # Sort params by predicted quantile sorting_indices : NDArray [ np . float64 ] = np . argsort ( predicted_points_quantiles ) sampled_points : NDArray [ np . float64 ] = candidates [ sorting_indices ][: batch_size ] return digitize_data ( sampled_points , search_space . param_grid ) @staticmethod def prepare_data_for_classifier ( existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], num_bins : int = 10 , ) -> Tuple [ NDArray [ np . float64 ], NDArray [ np . int64 ], NDArray [ np . float64 ]]: \"\"\" Prepare data for the classifier. Args: existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters num_bins: the number of bins Returns: A triple (x, y, quantiles), where - x is the vector of training data - y is the vector of targets - the quantiles \"\"\" x : NDArray [ np . float64 ] = existing_points y : NDArray [ np . float64 ] = existing_losses cutoffs : NDArray [ np . float64 ] = np . linspace ( 0 , 1 , num_bins + 1 ) quantiles : NDArray [ np . float64 ] = np . zeros ( num_bins + 1 ) for i in range ( num_bins - 1 ): quantiles [ i + 1 ] = np . quantile ( y , cutoffs [ i + 1 ]) quantiles [ - 1 ] = np . max ( y ) y_cat : NDArray [ np . int64 ] = np . digitize ( y , quantiles , right = True ) y_cat = y_cat - 1 return x , y_cat , quantiles","title":"RandomForestSampler"},{"location":"samplers/#black_it.samplers.random_forest.RandomForestSampler.candidate_pool_size","text":"Get the candidate pool size.","title":"candidate_pool_size"},{"location":"samplers/#black_it.samplers.random_forest.RandomForestSampler.criterion","text":"Get the criterion.","title":"criterion"},{"location":"samplers/#black_it.samplers.random_forest.RandomForestSampler.n_estimators","text":"Get the number of estimators.","title":"n_estimators"},{"location":"samplers/#black_it.samplers.random_forest.RandomForestSampler.__init__","text":"Random forest sampling. Note: this class is a wrapper of sklearn.ensemble.RandomForestClassifier. Parameters: Name Type Description Default batch_size int the number of points sampled every time the sampler is called required random_state Optional[int] the random state of the sampler, fixing this number the sampler behaves deterministically None max_deduplication_passes int the maximum number of deduplication passes 5 candidate_pool_size Optional[int] number of randomly sampled points on which the random forest predictions are evaluated None n_estimators int number of trees in the forest 500 criterion str The function to measure the quality of a split. 'gini' Source code in black_it/samplers/random_forest.py def __init__ ( self , batch_size : int , random_state : Optional [ int ] = None , max_deduplication_passes : int = 5 , candidate_pool_size : Optional [ int ] = None , n_estimators : int = 500 , criterion : str = \"gini\" , ) -> None : \"\"\" Random forest sampling. Note: this class is a wrapper of sklearn.ensemble.RandomForestClassifier. Args: batch_size: the number of points sampled every time the sampler is called random_state: the random state of the sampler, fixing this number the sampler behaves deterministically max_deduplication_passes: the maximum number of deduplication passes candidate_pool_size: number of randomly sampled points on which the random forest predictions are evaluated n_estimators: number of trees in the forest criterion: The function to measure the quality of a split. \"\"\" super () . __init__ ( batch_size , random_state , max_deduplication_passes ) self . _n_estimators = n_estimators self . _criterion = criterion if candidate_pool_size is not None : self . _candidate_pool_size = candidate_pool_size else : self . _candidate_pool_size = 1000 * batch_size","title":"__init__()"},{"location":"samplers/#black_it.samplers.random_forest.RandomForestSampler.prepare_data_for_classifier","text":"Prepare data for the classifier. Parameters: Name Type Description Default existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required num_bins int the number of bins 10 Returns: Type Description Tuple[numpy.ndarray, numpy.ndarray, numpy.ndarray] A triple (x, y, quantiles), where - x is the vector of training data - y is the vector of targets - the quantiles Source code in black_it/samplers/random_forest.py @staticmethod def prepare_data_for_classifier ( existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], num_bins : int = 10 , ) -> Tuple [ NDArray [ np . float64 ], NDArray [ np . int64 ], NDArray [ np . float64 ]]: \"\"\" Prepare data for the classifier. Args: existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters num_bins: the number of bins Returns: A triple (x, y, quantiles), where - x is the vector of training data - y is the vector of targets - the quantiles \"\"\" x : NDArray [ np . float64 ] = existing_points y : NDArray [ np . float64 ] = existing_losses cutoffs : NDArray [ np . float64 ] = np . linspace ( 0 , 1 , num_bins + 1 ) quantiles : NDArray [ np . float64 ] = np . zeros ( num_bins + 1 ) for i in range ( num_bins - 1 ): quantiles [ i + 1 ] = np . quantile ( y , cutoffs [ i + 1 ]) quantiles [ - 1 ] = np . max ( y ) y_cat : NDArray [ np . int64 ] = np . digitize ( y , quantiles , right = True ) y_cat = y_cat - 1 return x , y_cat , quantiles","title":"prepare_data_for_classifier()"},{"location":"samplers/#black_it.samplers.random_forest.RandomForestSampler.sample_batch","text":"Sample from the search space. Parameters: Name Type Description Default batch_size int the number of points to sample required search_space SearchSpace an object containing the details of the parameter search space required existing_points ndarray the parameters already sampled required existing_losses ndarray the loss corresponding to the sampled parameters required Returns: Type Description ndarray the sampled parameters Source code in black_it/samplers/random_forest.py def sample_batch ( self , batch_size : int , search_space : SearchSpace , existing_points : NDArray [ np . float64 ], existing_losses : NDArray [ np . float64 ], ) -> NDArray [ np . float64 ]: \"\"\" Sample from the search space. Args: batch_size: the number of points to sample search_space: an object containing the details of the parameter search space existing_points: the parameters already sampled existing_losses: the loss corresponding to the sampled parameters Returns: the sampled parameters \"\"\" # Get large candidate pool candidates = RandomUniformSampler ( self . candidate_pool_size , random_state = self . _get_random_seed () ) . sample_batch ( self . candidate_pool_size , search_space , existing_points , existing_losses ) # Train surrogate x : NDArray [ np . float64 ] y : NDArray [ np . int64 ] x , y , _existing_points_quantiles = self . prepare_data_for_classifier ( existing_points , existing_losses ) classifier : RandomForestClassifier = RandomForestClassifier ( n_estimators = self . n_estimators , criterion = self . criterion , n_jobs =- 1 , random_state = self . _get_random_seed (), ) classifier . fit ( x , y ) # Predict quantiles predicted_points_quantiles : NDArray [ np . float64 ] = classifier . predict ( candidates ) # Sort params by predicted quantile sorting_indices : NDArray [ np . float64 ] = np . argsort ( predicted_points_quantiles ) sampled_points : NDArray [ np . float64 ] = candidates [ sorting_indices ][: batch_size ] return digitize_data ( sampled_points , search_space . param_grid )","title":"sample_batch()"},{"location":"search_space/","text":"black_it.search_space.SearchSpace A class that contains information on the search grid of explorable parameters. Source code in black_it/search_space.py class SearchSpace : # pylint: disable=too-few-public-methods \"\"\"A class that contains information on the search grid of explorable parameters.\"\"\" def __init__ ( self , parameters_bounds : Union [ NDArray [ np . float64 ], List [ List [ float ]]], parameters_precision : Union [ NDArray [ np . float64 ], List [ float ]], verbose : bool , ): \"\"\" Initialize the SearchSpace object. The values of parameters_bounds and parameters_precision parameters have to satisfy the following constraints, otherwise an exception (subclass of SearchSpaceError) is raised: - parameters_bounds must be a two-elements array/list (or BoundsNotOfSizeTwoError is raised) - the two sub-arrays/lists of parameter_bounds must have the same length (or BoundsOfDifferentLengthError is raised) - parameters_precision array/list must have the same number of elements than the two sub-arrays/lists in parameters_bounds (or BadPrecisionLengthError is raised) - lower bounds and upper bounds cannot have the same value (or SameLowerAndUpperBoundError is raised) - every lower bound must be lower than the corresponding upper bound (or LowerBoundGreaterThanUpperBoundError) - 0 is an invalid value for a precision (or PrecisionZeroError is raised) - any given parameter precision has to be strictly lower than the allowed parameter span (or PrecisionGreaterThanBoundsRangeError is raised) Args: parameters_bounds: lower and upper bounds of the parameters. parameters_precision: resolution of the grid of parameters. verbose: whether to print or not the information on the search space. \"\"\" SearchSpace . _check_bounds ( parameters_bounds , parameters_precision ) # The bounds we were given are well formed. Save them. self . _parameters_bounds = np . array ( parameters_bounds ) self . _parameters_precision = np . array ( parameters_precision ) # Initialize search grid self . _param_grid : List [ NDArray [ np . float64 ]] = [] self . _space_size = 1 for i in range ( self . dims ): new_col = np . arange ( parameters_bounds [ 0 ][ i ], parameters_bounds [ 1 ][ i ] + 0.0000001 , parameters_precision [ i ], dtype = np . float64 , ) new_col = np . round ( new_col , - int ( np . log10 ( parameters_precision [ i ]))) self . _param_grid . append ( new_col ) self . _space_size *= len ( new_col ) if verbose : print ( \" \\n ***\" ) print ( f \"Number of free params: { self . dims } .\" ) print ( f \"Explorable param space size: { self . space_size } .\" ) print ( \"*** \\n \" ) @staticmethod def _check_bounds ( parameters_bounds : Union [ NDArray [ np . float64 ], List [ List [ float ]]], parameters_precision : Union [ NDArray [ np . float64 ], List [ float ]], ) -> None : \"\"\" Ensure parameter_bounds and parameter_precision have acceptable values. This is an helper function for SearchSpace.__init__(). Args: parameters_bounds: lower and upper bounds of the parameters parameters_precision: resolution of the grid of parameters \"\"\" # ensure parameters_bounds is a two-elements array if len ( parameters_bounds ) != 2 : raise BoundsNotOfSizeTwoError ( len ( parameters_bounds )) # ensure the two sub-arrays of parameter_bounds (which are the min and # max bounds for each parameter) have the same length if len ( parameters_bounds [ 0 ]) != len ( parameters_bounds [ 1 ]): raise BoundsOfDifferentLengthError ( len ( parameters_bounds [ 0 ]), len ( parameters_bounds [ 1 ]), ) # ensure parameters_precision array has as many elements as either one # of parameters_bounds sub-array if len ( parameters_precision ) != len ( parameters_bounds [ 0 ]): raise BadPrecisionLengthError ( len ( parameters_precision ), len ( parameters_bounds [ 0 ]), ) for i , ( lower_bound , upper_bound , precision ) in enumerate ( zip ( parameters_bounds [ 0 ], parameters_bounds [ 1 ], parameters_precision ) ): # ensure lower bounds and upper bounds do not have the same value if lower_bound == upper_bound : raise SameLowerAndUpperBoundError ( i , lower_bound ) # ensure each lower bound is lower than the corresponding upper one if lower_bound > upper_bound : raise LowerBoundGreaterThanUpperBoundError ( i , lower_bound , upper_bound ) # a precision of 0 is not meaningful if precision == 0 : raise PrecisionZeroError ( i ) # any given parameter precision has to be strictly lower than the # allowed parameter span if precision > ( upper_bound - lower_bound ): raise PrecisionGreaterThanBoundsRangeError ( i , lower_bound , upper_bound , precision ) @property def param_grid ( self ) -> List [ NDArray [ np . float64 ]]: \"\"\"Discretized parameter space containing all possible candidates for calibration.\"\"\" return self . _param_grid @property def parameters_bounds ( self ) -> NDArray [ np . float64 ]: \"\"\"Two dimensional array containing lower and upper bounds for each parameter.\"\"\" return self . _parameters_bounds @property def parameters_precision ( self ) -> NDArray [ np . float64 ]: \"\"\"One dimensional array containing the precisions for each parameter.\"\"\" return self . _parameters_precision @property def dims ( self ) -> int : \"\"\"Return the number of model parameters configured for calibration.\"\"\" return len ( self . _parameters_precision ) @property def space_size ( self ) -> int : \"\"\"Cardinality of the potential parameter space to be searched.\"\"\" return self . _space_size dims : int property readonly Return the number of model parameters configured for calibration. param_grid : List [ numpy . ndarray ] property readonly Discretized parameter space containing all possible candidates for calibration. parameters_bounds : ndarray property readonly Two dimensional array containing lower and upper bounds for each parameter. parameters_precision : ndarray property readonly One dimensional array containing the precisions for each parameter. space_size : int property readonly Cardinality of the potential parameter space to be searched. __init__ ( self , parameters_bounds , parameters_precision , verbose ) special Initialize the SearchSpace object. The values of parameters_bounds and parameters_precision parameters have to satisfy the following constraints, otherwise an exception (subclass of SearchSpaceError) is raised: parameters_bounds must be a two-elements array/list (or BoundsNotOfSizeTwoError is raised) the two sub-arrays/lists of parameter_bounds must have the same length (or BoundsOfDifferentLengthError is raised) parameters_precision array/list must have the same number of elements than the two sub-arrays/lists in parameters_bounds (or BadPrecisionLengthError is raised) lower bounds and upper bounds cannot have the same value (or SameLowerAndUpperBoundError is raised) every lower bound must be lower than the corresponding upper bound (or LowerBoundGreaterThanUpperBoundError) 0 is an invalid value for a precision (or PrecisionZeroError is raised) any given parameter precision has to be strictly lower than the allowed parameter span (or PrecisionGreaterThanBoundsRangeError is raised) Parameters: Name Type Description Default parameters_bounds Union[numpy.ndarray, List[List[float]]] lower and upper bounds of the parameters. required parameters_precision Union[numpy.ndarray, List[float]] resolution of the grid of parameters. required verbose bool whether to print or not the information on the search space. required Source code in black_it/search_space.py def __init__ ( self , parameters_bounds : Union [ NDArray [ np . float64 ], List [ List [ float ]]], parameters_precision : Union [ NDArray [ np . float64 ], List [ float ]], verbose : bool , ): \"\"\" Initialize the SearchSpace object. The values of parameters_bounds and parameters_precision parameters have to satisfy the following constraints, otherwise an exception (subclass of SearchSpaceError) is raised: - parameters_bounds must be a two-elements array/list (or BoundsNotOfSizeTwoError is raised) - the two sub-arrays/lists of parameter_bounds must have the same length (or BoundsOfDifferentLengthError is raised) - parameters_precision array/list must have the same number of elements than the two sub-arrays/lists in parameters_bounds (or BadPrecisionLengthError is raised) - lower bounds and upper bounds cannot have the same value (or SameLowerAndUpperBoundError is raised) - every lower bound must be lower than the corresponding upper bound (or LowerBoundGreaterThanUpperBoundError) - 0 is an invalid value for a precision (or PrecisionZeroError is raised) - any given parameter precision has to be strictly lower than the allowed parameter span (or PrecisionGreaterThanBoundsRangeError is raised) Args: parameters_bounds: lower and upper bounds of the parameters. parameters_precision: resolution of the grid of parameters. verbose: whether to print or not the information on the search space. \"\"\" SearchSpace . _check_bounds ( parameters_bounds , parameters_precision ) # The bounds we were given are well formed. Save them. self . _parameters_bounds = np . array ( parameters_bounds ) self . _parameters_precision = np . array ( parameters_precision ) # Initialize search grid self . _param_grid : List [ NDArray [ np . float64 ]] = [] self . _space_size = 1 for i in range ( self . dims ): new_col = np . arange ( parameters_bounds [ 0 ][ i ], parameters_bounds [ 1 ][ i ] + 0.0000001 , parameters_precision [ i ], dtype = np . float64 , ) new_col = np . round ( new_col , - int ( np . log10 ( parameters_precision [ i ]))) self . _param_grid . append ( new_col ) self . _space_size *= len ( new_col ) if verbose : print ( \" \\n ***\" ) print ( f \"Number of free params: { self . dims } .\" ) print ( f \"Explorable param space size: { self . space_size } .\" ) print ( \"*** \\n \" ) black_it.search_space.SearchSpaceError ( ValueError ) Base class for the exceptions raised by SearchSpace when its construction fails. If you need to distinguish a specific error, please do not rely on parsing the error message, because it is considered unstable: catch instead the specific exception type you want to handle, and use the additional fields each subtype exposes (for example: BadPrecisionLengthError.bounds_length) Source code in black_it/search_space.py class SearchSpaceError ( ValueError ): \"\"\"Base class for the exceptions raised by SearchSpace when its construction fails. If you need to distinguish a specific error, please do not rely on parsing the error message, because it is considered unstable: catch instead the specific exception type you want to handle, and use the additional fields each subtype exposes (for example: BadPrecisionLengthError.bounds_length) \"\"\" black_it.search_space.BadPrecisionLengthError ( SearchSpaceError ) Raised when the parameters_precision array has a different length than the bounds'. Attributes: Name Type Description precisions_length int number of elements of the precision subarray bounds_length int number of elements of the two bounds subbarrays Source code in black_it/search_space.py class BadPrecisionLengthError ( SearchSpaceError ): \"\"\"Raised when the parameters_precision array has a different length than the bounds'. Attributes: precisions_length (int): number of elements of the precision subarray bounds_length (int): number of elements of the two bounds subbarrays \"\"\" def __init__ ( # noqa: D107 self , precisions_length : int , bounds_length : int ) -> None : super () . __init__ ( f \"parameters_precision array has { precisions_length } elements. Its \" f \"length, instead, has to be { bounds_length } , the same as the bounds'.\" ) self . precisions_length = precisions_length self . bounds_length = bounds_length black_it.search_space.BoundsNotOfSizeTwoError ( SearchSpaceError ) Raised when bounds are not a two-dimensional array. Attributes: Name Type Description count_bounds_subarrays int wrong number of subarrays the parameter_bounds array was made of. It will be different than 2. Source code in black_it/search_space.py class BoundsNotOfSizeTwoError ( SearchSpaceError ): \"\"\"Raised when bounds are not a two-dimensional array. Attributes: count_bounds_subarrays (int): wrong number of subarrays the parameter_bounds array was made of. It will be different than 2. \"\"\" def __init__ ( self , count_bounds_subarrays : int ) -> None : # noqa: D107 super () . __init__ ( f \"parameters_bounds must be a two dimensional array. This one has \" f \"size { count_bounds_subarrays } .\" ) self . count_bounds_subarrays = count_bounds_subarrays black_it.search_space.BoundsOfDifferentLengthError ( SearchSpaceError ) Raised when the lower and upper bounds do not have the same number of elements. Attributes: Name Type Description lower_bounds_length int number of elements in the subarray 0. It will be different than upper_bounds_length upper_bounds_length int number of elements in the subarray 1. It will be different than lower_bounds_length Source code in black_it/search_space.py class BoundsOfDifferentLengthError ( SearchSpaceError ): \"\"\"Raised when the lower and upper bounds do not have the same number of elements. Attributes: lower_bounds_length (int): number of elements in the subarray 0. It will be different than upper_bounds_length upper_bounds_length (int): number of elements in the subarray 1. It will be different than lower_bounds_length \"\"\" def __init__ ( # noqa: D107 self , lower_bounds_length : int , upper_bounds_length : int ) -> None : super () . __init__ ( f \"parameters_bounds subarrays must be of the same length. Lower \" f \"bounds length: { lower_bounds_length } , upper bounds length: \" f \" { upper_bounds_length } .\" ) self . lower_bounds_length = lower_bounds_length self . upper_bounds_length = upper_bounds_length black_it.search_space.LowerBoundGreaterThanUpperBoundError ( SearchSpaceError ) Raised when the lower bound of a parameter is greater than its upper bound. Attributes: Name Type Description param_index int 0-based index of the parameter presenting the error lower_bound float lower bound. It will be higher than upper bound upper_bound float upper bound. It will be lower than lower bound Source code in black_it/search_space.py class LowerBoundGreaterThanUpperBoundError ( SearchSpaceError ): \"\"\"Raised when the lower bound of a parameter is greater than its upper bound. Attributes: param_index (int): 0-based index of the parameter presenting the error lower_bound (float): lower bound. It will be higher than upper bound upper_bound (float): upper bound. It will be lower than lower bound \"\"\" def __init__ ( # noqa: D107 self , param_index : int , lower_bound : float , upper_bound : float ) -> None : super () . __init__ ( f \"Parameter { param_index } 's lower bound ( { lower_bound } ) must be \" f \"lower than its upper bound ( { upper_bound } ).\" ) self . param_index = param_index self . lower_bound = lower_bound self . upper_bound = upper_bound black_it.search_space.PrecisionZeroError ( SearchSpaceError ) Raised when a parameter precision is set to 0. Attributes: Name Type Description param_index int 0-based index of the parameter presenting the error Source code in black_it/search_space.py class PrecisionZeroError ( SearchSpaceError ): \"\"\"Raised when a parameter precision is set to 0. Attributes: param_index (int): 0-based index of the parameter presenting the error \"\"\" def __init__ ( self , param_index : int ) -> None : # noqa: D107 super () . __init__ ( f \"Parameter { param_index } 's precision cannot be zero.\" ) self . param_index = param_index black_it.search_space.SameLowerAndUpperBoundError ( SearchSpaceError ) Raised when the lower and the upper bound of a parameter have the same value. Attributes: Name Type Description param_index int 0-based index of the parameter presenting the error bound_value float common value of the parameter bound Source code in black_it/search_space.py class SameLowerAndUpperBoundError ( SearchSpaceError ): \"\"\"Raised when the lower and the upper bound of a parameter have the same value. Attributes: param_index (int): 0-based index of the parameter presenting the error bound_value (float): common value of the parameter bound \"\"\" def __init__ ( self , param_index : int , bound_value : float ) -> None : # noqa: D107 super () . __init__ ( f \"Parameter { param_index } 's lower and upper bounds have the same \" f \"value ( { bound_value } ). This calibrator cannot handle that. \" f \"Please redefine externally your model in order to hardcode \" f \"parameter { param_index } to { bound_value } .\" ) self . param_index = param_index self . bound_value = bound_value","title":"Search space"},{"location":"search_space/#black_it.search_space.SearchSpace","text":"A class that contains information on the search grid of explorable parameters. Source code in black_it/search_space.py class SearchSpace : # pylint: disable=too-few-public-methods \"\"\"A class that contains information on the search grid of explorable parameters.\"\"\" def __init__ ( self , parameters_bounds : Union [ NDArray [ np . float64 ], List [ List [ float ]]], parameters_precision : Union [ NDArray [ np . float64 ], List [ float ]], verbose : bool , ): \"\"\" Initialize the SearchSpace object. The values of parameters_bounds and parameters_precision parameters have to satisfy the following constraints, otherwise an exception (subclass of SearchSpaceError) is raised: - parameters_bounds must be a two-elements array/list (or BoundsNotOfSizeTwoError is raised) - the two sub-arrays/lists of parameter_bounds must have the same length (or BoundsOfDifferentLengthError is raised) - parameters_precision array/list must have the same number of elements than the two sub-arrays/lists in parameters_bounds (or BadPrecisionLengthError is raised) - lower bounds and upper bounds cannot have the same value (or SameLowerAndUpperBoundError is raised) - every lower bound must be lower than the corresponding upper bound (or LowerBoundGreaterThanUpperBoundError) - 0 is an invalid value for a precision (or PrecisionZeroError is raised) - any given parameter precision has to be strictly lower than the allowed parameter span (or PrecisionGreaterThanBoundsRangeError is raised) Args: parameters_bounds: lower and upper bounds of the parameters. parameters_precision: resolution of the grid of parameters. verbose: whether to print or not the information on the search space. \"\"\" SearchSpace . _check_bounds ( parameters_bounds , parameters_precision ) # The bounds we were given are well formed. Save them. self . _parameters_bounds = np . array ( parameters_bounds ) self . _parameters_precision = np . array ( parameters_precision ) # Initialize search grid self . _param_grid : List [ NDArray [ np . float64 ]] = [] self . _space_size = 1 for i in range ( self . dims ): new_col = np . arange ( parameters_bounds [ 0 ][ i ], parameters_bounds [ 1 ][ i ] + 0.0000001 , parameters_precision [ i ], dtype = np . float64 , ) new_col = np . round ( new_col , - int ( np . log10 ( parameters_precision [ i ]))) self . _param_grid . append ( new_col ) self . _space_size *= len ( new_col ) if verbose : print ( \" \\n ***\" ) print ( f \"Number of free params: { self . dims } .\" ) print ( f \"Explorable param space size: { self . space_size } .\" ) print ( \"*** \\n \" ) @staticmethod def _check_bounds ( parameters_bounds : Union [ NDArray [ np . float64 ], List [ List [ float ]]], parameters_precision : Union [ NDArray [ np . float64 ], List [ float ]], ) -> None : \"\"\" Ensure parameter_bounds and parameter_precision have acceptable values. This is an helper function for SearchSpace.__init__(). Args: parameters_bounds: lower and upper bounds of the parameters parameters_precision: resolution of the grid of parameters \"\"\" # ensure parameters_bounds is a two-elements array if len ( parameters_bounds ) != 2 : raise BoundsNotOfSizeTwoError ( len ( parameters_bounds )) # ensure the two sub-arrays of parameter_bounds (which are the min and # max bounds for each parameter) have the same length if len ( parameters_bounds [ 0 ]) != len ( parameters_bounds [ 1 ]): raise BoundsOfDifferentLengthError ( len ( parameters_bounds [ 0 ]), len ( parameters_bounds [ 1 ]), ) # ensure parameters_precision array has as many elements as either one # of parameters_bounds sub-array if len ( parameters_precision ) != len ( parameters_bounds [ 0 ]): raise BadPrecisionLengthError ( len ( parameters_precision ), len ( parameters_bounds [ 0 ]), ) for i , ( lower_bound , upper_bound , precision ) in enumerate ( zip ( parameters_bounds [ 0 ], parameters_bounds [ 1 ], parameters_precision ) ): # ensure lower bounds and upper bounds do not have the same value if lower_bound == upper_bound : raise SameLowerAndUpperBoundError ( i , lower_bound ) # ensure each lower bound is lower than the corresponding upper one if lower_bound > upper_bound : raise LowerBoundGreaterThanUpperBoundError ( i , lower_bound , upper_bound ) # a precision of 0 is not meaningful if precision == 0 : raise PrecisionZeroError ( i ) # any given parameter precision has to be strictly lower than the # allowed parameter span if precision > ( upper_bound - lower_bound ): raise PrecisionGreaterThanBoundsRangeError ( i , lower_bound , upper_bound , precision ) @property def param_grid ( self ) -> List [ NDArray [ np . float64 ]]: \"\"\"Discretized parameter space containing all possible candidates for calibration.\"\"\" return self . _param_grid @property def parameters_bounds ( self ) -> NDArray [ np . float64 ]: \"\"\"Two dimensional array containing lower and upper bounds for each parameter.\"\"\" return self . _parameters_bounds @property def parameters_precision ( self ) -> NDArray [ np . float64 ]: \"\"\"One dimensional array containing the precisions for each parameter.\"\"\" return self . _parameters_precision @property def dims ( self ) -> int : \"\"\"Return the number of model parameters configured for calibration.\"\"\" return len ( self . _parameters_precision ) @property def space_size ( self ) -> int : \"\"\"Cardinality of the potential parameter space to be searched.\"\"\" return self . _space_size","title":"SearchSpace"},{"location":"search_space/#black_it.search_space.SearchSpace.dims","text":"Return the number of model parameters configured for calibration.","title":"dims"},{"location":"search_space/#black_it.search_space.SearchSpace.param_grid","text":"Discretized parameter space containing all possible candidates for calibration.","title":"param_grid"},{"location":"search_space/#black_it.search_space.SearchSpace.parameters_bounds","text":"Two dimensional array containing lower and upper bounds for each parameter.","title":"parameters_bounds"},{"location":"search_space/#black_it.search_space.SearchSpace.parameters_precision","text":"One dimensional array containing the precisions for each parameter.","title":"parameters_precision"},{"location":"search_space/#black_it.search_space.SearchSpace.space_size","text":"Cardinality of the potential parameter space to be searched.","title":"space_size"},{"location":"search_space/#black_it.search_space.SearchSpace.__init__","text":"Initialize the SearchSpace object. The values of parameters_bounds and parameters_precision parameters have to satisfy the following constraints, otherwise an exception (subclass of SearchSpaceError) is raised: parameters_bounds must be a two-elements array/list (or BoundsNotOfSizeTwoError is raised) the two sub-arrays/lists of parameter_bounds must have the same length (or BoundsOfDifferentLengthError is raised) parameters_precision array/list must have the same number of elements than the two sub-arrays/lists in parameters_bounds (or BadPrecisionLengthError is raised) lower bounds and upper bounds cannot have the same value (or SameLowerAndUpperBoundError is raised) every lower bound must be lower than the corresponding upper bound (or LowerBoundGreaterThanUpperBoundError) 0 is an invalid value for a precision (or PrecisionZeroError is raised) any given parameter precision has to be strictly lower than the allowed parameter span (or PrecisionGreaterThanBoundsRangeError is raised) Parameters: Name Type Description Default parameters_bounds Union[numpy.ndarray, List[List[float]]] lower and upper bounds of the parameters. required parameters_precision Union[numpy.ndarray, List[float]] resolution of the grid of parameters. required verbose bool whether to print or not the information on the search space. required Source code in black_it/search_space.py def __init__ ( self , parameters_bounds : Union [ NDArray [ np . float64 ], List [ List [ float ]]], parameters_precision : Union [ NDArray [ np . float64 ], List [ float ]], verbose : bool , ): \"\"\" Initialize the SearchSpace object. The values of parameters_bounds and parameters_precision parameters have to satisfy the following constraints, otherwise an exception (subclass of SearchSpaceError) is raised: - parameters_bounds must be a two-elements array/list (or BoundsNotOfSizeTwoError is raised) - the two sub-arrays/lists of parameter_bounds must have the same length (or BoundsOfDifferentLengthError is raised) - parameters_precision array/list must have the same number of elements than the two sub-arrays/lists in parameters_bounds (or BadPrecisionLengthError is raised) - lower bounds and upper bounds cannot have the same value (or SameLowerAndUpperBoundError is raised) - every lower bound must be lower than the corresponding upper bound (or LowerBoundGreaterThanUpperBoundError) - 0 is an invalid value for a precision (or PrecisionZeroError is raised) - any given parameter precision has to be strictly lower than the allowed parameter span (or PrecisionGreaterThanBoundsRangeError is raised) Args: parameters_bounds: lower and upper bounds of the parameters. parameters_precision: resolution of the grid of parameters. verbose: whether to print or not the information on the search space. \"\"\" SearchSpace . _check_bounds ( parameters_bounds , parameters_precision ) # The bounds we were given are well formed. Save them. self . _parameters_bounds = np . array ( parameters_bounds ) self . _parameters_precision = np . array ( parameters_precision ) # Initialize search grid self . _param_grid : List [ NDArray [ np . float64 ]] = [] self . _space_size = 1 for i in range ( self . dims ): new_col = np . arange ( parameters_bounds [ 0 ][ i ], parameters_bounds [ 1 ][ i ] + 0.0000001 , parameters_precision [ i ], dtype = np . float64 , ) new_col = np . round ( new_col , - int ( np . log10 ( parameters_precision [ i ]))) self . _param_grid . append ( new_col ) self . _space_size *= len ( new_col ) if verbose : print ( \" \\n ***\" ) print ( f \"Number of free params: { self . dims } .\" ) print ( f \"Explorable param space size: { self . space_size } .\" ) print ( \"*** \\n \" )","title":"__init__()"},{"location":"search_space/#black_it.search_space.SearchSpaceError","text":"Base class for the exceptions raised by SearchSpace when its construction fails. If you need to distinguish a specific error, please do not rely on parsing the error message, because it is considered unstable: catch instead the specific exception type you want to handle, and use the additional fields each subtype exposes (for example: BadPrecisionLengthError.bounds_length) Source code in black_it/search_space.py class SearchSpaceError ( ValueError ): \"\"\"Base class for the exceptions raised by SearchSpace when its construction fails. If you need to distinguish a specific error, please do not rely on parsing the error message, because it is considered unstable: catch instead the specific exception type you want to handle, and use the additional fields each subtype exposes (for example: BadPrecisionLengthError.bounds_length) \"\"\"","title":"SearchSpaceError"},{"location":"search_space/#black_it.search_space.BadPrecisionLengthError","text":"Raised when the parameters_precision array has a different length than the bounds'. Attributes: Name Type Description precisions_length int number of elements of the precision subarray bounds_length int number of elements of the two bounds subbarrays Source code in black_it/search_space.py class BadPrecisionLengthError ( SearchSpaceError ): \"\"\"Raised when the parameters_precision array has a different length than the bounds'. Attributes: precisions_length (int): number of elements of the precision subarray bounds_length (int): number of elements of the two bounds subbarrays \"\"\" def __init__ ( # noqa: D107 self , precisions_length : int , bounds_length : int ) -> None : super () . __init__ ( f \"parameters_precision array has { precisions_length } elements. Its \" f \"length, instead, has to be { bounds_length } , the same as the bounds'.\" ) self . precisions_length = precisions_length self . bounds_length = bounds_length","title":"BadPrecisionLengthError"},{"location":"search_space/#black_it.search_space.BoundsNotOfSizeTwoError","text":"Raised when bounds are not a two-dimensional array. Attributes: Name Type Description count_bounds_subarrays int wrong number of subarrays the parameter_bounds array was made of. It will be different than 2. Source code in black_it/search_space.py class BoundsNotOfSizeTwoError ( SearchSpaceError ): \"\"\"Raised when bounds are not a two-dimensional array. Attributes: count_bounds_subarrays (int): wrong number of subarrays the parameter_bounds array was made of. It will be different than 2. \"\"\" def __init__ ( self , count_bounds_subarrays : int ) -> None : # noqa: D107 super () . __init__ ( f \"parameters_bounds must be a two dimensional array. This one has \" f \"size { count_bounds_subarrays } .\" ) self . count_bounds_subarrays = count_bounds_subarrays","title":"BoundsNotOfSizeTwoError"},{"location":"search_space/#black_it.search_space.BoundsOfDifferentLengthError","text":"Raised when the lower and upper bounds do not have the same number of elements. Attributes: Name Type Description lower_bounds_length int number of elements in the subarray 0. It will be different than upper_bounds_length upper_bounds_length int number of elements in the subarray 1. It will be different than lower_bounds_length Source code in black_it/search_space.py class BoundsOfDifferentLengthError ( SearchSpaceError ): \"\"\"Raised when the lower and upper bounds do not have the same number of elements. Attributes: lower_bounds_length (int): number of elements in the subarray 0. It will be different than upper_bounds_length upper_bounds_length (int): number of elements in the subarray 1. It will be different than lower_bounds_length \"\"\" def __init__ ( # noqa: D107 self , lower_bounds_length : int , upper_bounds_length : int ) -> None : super () . __init__ ( f \"parameters_bounds subarrays must be of the same length. Lower \" f \"bounds length: { lower_bounds_length } , upper bounds length: \" f \" { upper_bounds_length } .\" ) self . lower_bounds_length = lower_bounds_length self . upper_bounds_length = upper_bounds_length","title":"BoundsOfDifferentLengthError"},{"location":"search_space/#black_it.search_space.LowerBoundGreaterThanUpperBoundError","text":"Raised when the lower bound of a parameter is greater than its upper bound. Attributes: Name Type Description param_index int 0-based index of the parameter presenting the error lower_bound float lower bound. It will be higher than upper bound upper_bound float upper bound. It will be lower than lower bound Source code in black_it/search_space.py class LowerBoundGreaterThanUpperBoundError ( SearchSpaceError ): \"\"\"Raised when the lower bound of a parameter is greater than its upper bound. Attributes: param_index (int): 0-based index of the parameter presenting the error lower_bound (float): lower bound. It will be higher than upper bound upper_bound (float): upper bound. It will be lower than lower bound \"\"\" def __init__ ( # noqa: D107 self , param_index : int , lower_bound : float , upper_bound : float ) -> None : super () . __init__ ( f \"Parameter { param_index } 's lower bound ( { lower_bound } ) must be \" f \"lower than its upper bound ( { upper_bound } ).\" ) self . param_index = param_index self . lower_bound = lower_bound self . upper_bound = upper_bound","title":"LowerBoundGreaterThanUpperBoundError"},{"location":"search_space/#black_it.search_space.PrecisionZeroError","text":"Raised when a parameter precision is set to 0. Attributes: Name Type Description param_index int 0-based index of the parameter presenting the error Source code in black_it/search_space.py class PrecisionZeroError ( SearchSpaceError ): \"\"\"Raised when a parameter precision is set to 0. Attributes: param_index (int): 0-based index of the parameter presenting the error \"\"\" def __init__ ( self , param_index : int ) -> None : # noqa: D107 super () . __init__ ( f \"Parameter { param_index } 's precision cannot be zero.\" ) self . param_index = param_index","title":"PrecisionZeroError"},{"location":"search_space/#black_it.search_space.SameLowerAndUpperBoundError","text":"Raised when the lower and the upper bound of a parameter have the same value. Attributes: Name Type Description param_index int 0-based index of the parameter presenting the error bound_value float common value of the parameter bound Source code in black_it/search_space.py class SameLowerAndUpperBoundError ( SearchSpaceError ): \"\"\"Raised when the lower and the upper bound of a parameter have the same value. Attributes: param_index (int): 0-based index of the parameter presenting the error bound_value (float): common value of the parameter bound \"\"\" def __init__ ( self , param_index : int , bound_value : float ) -> None : # noqa: D107 super () . __init__ ( f \"Parameter { param_index } 's lower and upper bounds have the same \" f \"value ( { bound_value } ). This calibrator cannot handle that. \" f \"Please redefine externally your model in order to hardcode \" f \"parameter { param_index } to { bound_value } .\" ) self . param_index = param_index self . bound_value = bound_value","title":"SameLowerAndUpperBoundError"},{"location":"simulator_interface/","text":"How to interface Black-it with your simulator As already mentioned, the tool was designed with the ability to be customizable in each of its components. Being able to use a custom model is even more vital to the usability of the tool, since one may want to plug their own model in the tool and calibrate it. A possibility is to write a custom Python function and use it as explained here . But one may have already written their own model simulator somewhere else and may reasonably expect to use it with the calibrator. To do this, essentially a Python wrapper of the simulator must be written. The interface is flexible and language agnostic, and it allows calibrating models built using standard Python ABM frameworks such as Mesa , as well as custom models written directly in low level languages. To illustrate this, we will take a look at the SIR model tutorial which makes use of a C++ simulator run on a Docker container. Here the wrapper is defined as follows: def SIR_docker ( theta , N , rndSeed ): sim_params = { \"agents\" : 1000 , \"epochs\" : N - 1 , \"beta\" : theta [ 0 ], \"gamma\" : theta [ 1 ], \"infectious-t0\" : 10 , \"lattice-order\" : 20 , \"rewire-probability\" : 0.2 , } res = simlib . execute_simulator ( \"bancaditalia/abmsimulator\" , sim_params ) ret = np . array ([( x [ \"susceptible\" ], x [ \"infectious\" ], x [ \"recovered\" ]) for x in res ]) return ret To function correctly, the wrapper must have the interface shown in the example: it must accept in input three parameters (theta, N, rndSeed) , which are respectively the parameter vector to be optimized, the length of the time series and a random seed (this last one is not used in the example) it must output a N \\times D N \\times D array where N N is the same as before and D D is the vector dimension of the time series (in the SIR example it is D=3 D=3 )","title":"Interface with simulators"},{"location":"simulator_interface/#how-to-interface-black-it-with-your-simulator","text":"As already mentioned, the tool was designed with the ability to be customizable in each of its components. Being able to use a custom model is even more vital to the usability of the tool, since one may want to plug their own model in the tool and calibrate it. A possibility is to write a custom Python function and use it as explained here . But one may have already written their own model simulator somewhere else and may reasonably expect to use it with the calibrator. To do this, essentially a Python wrapper of the simulator must be written. The interface is flexible and language agnostic, and it allows calibrating models built using standard Python ABM frameworks such as Mesa , as well as custom models written directly in low level languages. To illustrate this, we will take a look at the SIR model tutorial which makes use of a C++ simulator run on a Docker container. Here the wrapper is defined as follows: def SIR_docker ( theta , N , rndSeed ): sim_params = { \"agents\" : 1000 , \"epochs\" : N - 1 , \"beta\" : theta [ 0 ], \"gamma\" : theta [ 1 ], \"infectious-t0\" : 10 , \"lattice-order\" : 20 , \"rewire-probability\" : 0.2 , } res = simlib . execute_simulator ( \"bancaditalia/abmsimulator\" , sim_params ) ret = np . array ([( x [ \"susceptible\" ], x [ \"infectious\" ], x [ \"recovered\" ]) for x in res ]) return ret To function correctly, the wrapper must have the interface shown in the example: it must accept in input three parameters (theta, N, rndSeed) , which are respectively the parameter vector to be optimized, the length of the time series and a random seed (this last one is not used in the example) it must output a N \\times D N \\times D array where N N is the same as before and D D is the vector dimension of the time series (in the SIR example it is D=3 D=3 )","title":"How to interface Black-it with your simulator"},{"location":"slack_stock_price_shock/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Fitting a simple shock model to the stock price of \"Slack Technologies\" Here we will fit a very simple \"shock model\" to the stock price of Slack Technologies from the 27th of august 2020 to the 31st of march 2021. We will try to capture the shock induces by the spearing of rumors on the 25th of november 2020 that Salesforce was interested in buying Slack. More info can be found here https://www.cnbc.com/2020/11/25/slack-shares-jump-following-report-of-possible-salesforce-acquisition.html. # import standard libraries import numpy as np import matplotlib.pyplot as plt slack_shock_data = np . atleast_2d ( np . loadtxt ( \"data/slack_shock.txt\" )) . T plt . plot ( slack_shock_data ) plt . xlabel ( \"days from 27-8-2020\" ) plt . ylabel ( \"Slack stock price\" ) Text(0, 0.5, 'Slack stock price') Model # a simple model of a simple step function with three parameters def step_func ( theta , N , seed = None ): # [tau, d1, d2] e = np . zeros ( N ) tau = int ( theta [ 0 ]) # day of the sudden change in evaluation d1 , d2 = theta [ 1 ], theta [ 2 ] # initial and final stock prices e [ 0 : tau ] = d1 e [ tau :] = d2 return np . atleast_2d ( e ) . T plt . plot ( step_func ([ 20 , 0 , 1 ], 100 )) [<matplotlib.lines.Line2D at 0x7f05b2c2f1c0>] parameter bounds and precisions bounds = [[ 0 , 20 , 20 ],[ 150 , 40 , 40 ]] precisions = [ 1 , 0.25 , 0.25 ] bounds [[0, 20, 20], [150, 40, 40]] samplers from black_it.samplers.halton import HaltonSampler from black_it.samplers.random_forest import RandomForestSampler from black_it.samplers.best_batch import BestBatchSampler hs = HaltonSampler ( batch_size = 16 ) rf = RandomForestSampler ( batch_size = 16 ) bb = BestBatchSampler ( batch_size = 16 ) samplers = [ hs , rf , bb ] loss # use a quadratic loss from black_it.loss_functions.minkowski import MinkowskiLoss loss = MinkowskiLoss () calibrator from black_it.calibrator import Calibrator cal = Calibrator ( samplers = samplers , loss_function = loss , model = step_func , parameters_bounds = bounds , parameters_precision = precisions , ensemble_size = 1 , convergence_precision = None , verbose = True , saving_folder = None , real_data = slack_shock_data , random_state = 1 , ) *** Number of free params: 3. Explorable param space size: 990711. *** Selecting 8 processes for the parallel evaluation of the model Calibration params , losses = cal . calibrate ( 10 ) BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: HaltonSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 48.81 ----> avg loss new params: 93.88 ----> avg loss exist params: 93.88 ----> curr min loss: 48.81198552405123 ====> total elapsed time: 0.3s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 46.24 ----> avg loss new params: 66.12 ----> avg loss exist params: 80.0 ----> curr min loss: 46.23645638238496 ====> total elapsed time: 2.1s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 41.37 ----> avg loss new params: 59.29 ----> avg loss exist params: 73.1 ----> curr min loss: 41.374024300280325 ====> total elapsed time: 0.0s BATCH NUMBER: 2 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 59.83 ----> avg loss new params: 100.14 ----> avg loss exist params: 79.86 ----> curr min loss: 41.374024300280325 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 26.62 ----> avg loss new params: 63.31 ----> avg loss exist params: 76.55 ----> curr min loss: 26.615971460763685 ====> total elapsed time: 2.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 20.26 ----> avg loss new params: 45.86 ----> avg loss exist params: 71.43 ----> curr min loss: 20.25857835091562 ====> total elapsed time: 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 96 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 64.43 ----> avg loss new params: 97.26 ----> avg loss exist params: 75.12 ----> curr min loss: 20.25857835091562 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 21.18 ----> avg loss new params: 43.8 ----> avg loss exist params: 71.21 ----> curr min loss: 20.25857835091562 ====> total elapsed time: 2.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 19.47 ----> avg loss new params: 30.07 ----> avg loss exist params: 66.64 ----> curr min loss: 19.468179801927736 ====> total elapsed time: 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 144 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 25.85 ----> avg loss new params: 89.51 ----> avg loss exist params: 68.92 ----> curr min loss: 19.468179801927736 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 21.5 ----> avg loss new params: 30.01 ----> avg loss exist params: 65.39 ----> curr min loss: 19.468179801927736 ====> total elapsed time: 2.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 23.76 ----> avg loss new params: 29.4 ----> avg loss exist params: 62.39 ----> curr min loss: 19.468179801927736 ====> total elapsed time: 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 192 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 48.76 ----> avg loss new params: 95.72 ----> avg loss exist params: 64.95 ----> curr min loss: 19.468179801927736 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 19.4 ----> avg loss new params: 30.32 ----> avg loss exist params: 62.48 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 2.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 20.73 ----> avg loss new params: 30.09 ----> avg loss exist params: 60.32 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 240 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 44.43 ----> avg loss new params: 93.83 ----> avg loss exist params: 62.41 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 20.85 ----> avg loss new params: 26.51 ----> avg loss exist params: 60.3 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 2.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 22.49 ----> avg loss new params: 27.91 ----> avg loss exist params: 58.5 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s BATCH NUMBER: 7 PARAMS SAMPLED: 288 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 57.21 ----> avg loss new params: 96.94 ----> avg loss exist params: 60.52 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 21.6 ----> avg loss new params: 29.33 ----> avg loss exist params: 58.96 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 2.0s METHOD: BestBatchSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 21.7 ----> avg loss new params: 29.8 ----> avg loss exist params: 57.58 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s BATCH NUMBER: 8 PARAMS SAMPLED: 336 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 62.8 ----> avg loss new params: 97.94 ----> avg loss exist params: 59.41 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 24.04 ----> avg loss new params: 31.56 ----> avg loss exist params: 58.2 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 2.1s METHOD: BestBatchSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 18.78 ----> avg loss new params: 27.02 ----> avg loss exist params: 56.9 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 384 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 49.95 ----> avg loss new params: 90.04 ----> avg loss exist params: 58.23 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 20.55 ----> avg loss new params: 30.55 ----> avg loss exist params: 57.16 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 2.1s METHOD: BestBatchSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 20.85 ----> avg loss new params: 29.97 ----> avg loss exist params: 56.15 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 432 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 33.91 ----> avg loss new params: 89.94 ----> avg loss exist params: 57.36 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 23.68 ----> avg loss new params: 35.37 ----> avg loss exist params: 56.6 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 2.1s METHOD: BestBatchSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 18.78 ----> avg loss new params: 27.49 ----> avg loss exist params: 55.63 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 0.1s # best parameters obtained so far params [ 0 ] array([64., 24., 35.]) plots # index of mimumum loss idxmin = np . argmin ( cal . losses_samp ) param_min = cal . params_samp [ idxmin ] # convergence losses_per_batch = [ cal . losses_samp [ cal . batch_num_samp == i ] for i in range ( int ( max ( cal . batch_num_samp )) + 1 ) ] mins_per_batch = np . array ([ np . min ( l ) for l in losses_per_batch ]) cummin_per_batch = [ np . min ( mins_per_batch [: i + 1 ]) for i in range ( mins_per_batch . shape [ 0 ]) ] plt . figure () plt . plot ( mins_per_batch , \"-o\" , label = \"batch minimum\" ) plt . plot ( cummin_per_batch , \"-o\" , label = \"cumulative minimum\" ) plt . ylabel ( \"loss\" ) plt . xlabel ( \"batch number\" ) plt . legend () <matplotlib.legend.Legend at 0x7f05d0a0eaf0> # agreement between real and simulated time series plt . plot ( slack_shock_data [:, 0 ], \"-\" , label = \"real series\" ) plt . ylabel ( \"Slack stock price\" , ) plt . xlabel ( \"days from 27-8-2020\" ) plt . plot ( cal . series_samp [ idxmin , 0 , :, 0 ] . T , ls = \"--\" , label = \"fitted model\" ) plt . legend () <matplotlib.legend.Legend at 0x7f05b2c8dd30>","title":"Simple shock model"},{"location":"slack_stock_price_shock/#fitting-a-simple-shock-model-to-the-stock-price-of-slack-technologies","text":"Here we will fit a very simple \"shock model\" to the stock price of Slack Technologies from the 27th of august 2020 to the 31st of march 2021. We will try to capture the shock induces by the spearing of rumors on the 25th of november 2020 that Salesforce was interested in buying Slack. More info can be found here https://www.cnbc.com/2020/11/25/slack-shares-jump-following-report-of-possible-salesforce-acquisition.html. # import standard libraries import numpy as np import matplotlib.pyplot as plt slack_shock_data = np . atleast_2d ( np . loadtxt ( \"data/slack_shock.txt\" )) . T plt . plot ( slack_shock_data ) plt . xlabel ( \"days from 27-8-2020\" ) plt . ylabel ( \"Slack stock price\" ) Text(0, 0.5, 'Slack stock price')","title":"Fitting a simple shock model to the stock price of \"Slack Technologies\""},{"location":"slack_stock_price_shock/#model","text":"# a simple model of a simple step function with three parameters def step_func ( theta , N , seed = None ): # [tau, d1, d2] e = np . zeros ( N ) tau = int ( theta [ 0 ]) # day of the sudden change in evaluation d1 , d2 = theta [ 1 ], theta [ 2 ] # initial and final stock prices e [ 0 : tau ] = d1 e [ tau :] = d2 return np . atleast_2d ( e ) . T plt . plot ( step_func ([ 20 , 0 , 1 ], 100 )) [<matplotlib.lines.Line2D at 0x7f05b2c2f1c0>]","title":"Model"},{"location":"slack_stock_price_shock/#parameter-bounds-and-precisions","text":"bounds = [[ 0 , 20 , 20 ],[ 150 , 40 , 40 ]] precisions = [ 1 , 0.25 , 0.25 ] bounds [[0, 20, 20], [150, 40, 40]]","title":"parameter bounds and precisions"},{"location":"slack_stock_price_shock/#samplers","text":"from black_it.samplers.halton import HaltonSampler from black_it.samplers.random_forest import RandomForestSampler from black_it.samplers.best_batch import BestBatchSampler hs = HaltonSampler ( batch_size = 16 ) rf = RandomForestSampler ( batch_size = 16 ) bb = BestBatchSampler ( batch_size = 16 ) samplers = [ hs , rf , bb ]","title":"samplers"},{"location":"slack_stock_price_shock/#loss","text":"# use a quadratic loss from black_it.loss_functions.minkowski import MinkowskiLoss loss = MinkowskiLoss ()","title":"loss"},{"location":"slack_stock_price_shock/#calibrator","text":"from black_it.calibrator import Calibrator cal = Calibrator ( samplers = samplers , loss_function = loss , model = step_func , parameters_bounds = bounds , parameters_precision = precisions , ensemble_size = 1 , convergence_precision = None , verbose = True , saving_folder = None , real_data = slack_shock_data , random_state = 1 , ) *** Number of free params: 3. Explorable param space size: 990711. *** Selecting 8 processes for the parallel evaluation of the model","title":"calibrator"},{"location":"slack_stock_price_shock/#calibration","text":"params , losses = cal . calibrate ( 10 ) BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: HaltonSampler ----> sim exec elapsed time: 0.3s ----> min loss new params: 48.81 ----> avg loss new params: 93.88 ----> avg loss exist params: 93.88 ----> curr min loss: 48.81198552405123 ====> total elapsed time: 0.3s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 46.24 ----> avg loss new params: 66.12 ----> avg loss exist params: 80.0 ----> curr min loss: 46.23645638238496 ====> total elapsed time: 2.1s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 41.37 ----> avg loss new params: 59.29 ----> avg loss exist params: 73.1 ----> curr min loss: 41.374024300280325 ====> total elapsed time: 0.0s BATCH NUMBER: 2 PARAMS SAMPLED: 48 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 59.83 ----> avg loss new params: 100.14 ----> avg loss exist params: 79.86 ----> curr min loss: 41.374024300280325 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 26.62 ----> avg loss new params: 63.31 ----> avg loss exist params: 76.55 ----> curr min loss: 26.615971460763685 ====> total elapsed time: 2.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 20.26 ----> avg loss new params: 45.86 ----> avg loss exist params: 71.43 ----> curr min loss: 20.25857835091562 ====> total elapsed time: 0.0s BATCH NUMBER: 3 PARAMS SAMPLED: 96 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 64.43 ----> avg loss new params: 97.26 ----> avg loss exist params: 75.12 ----> curr min loss: 20.25857835091562 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 21.18 ----> avg loss new params: 43.8 ----> avg loss exist params: 71.21 ----> curr min loss: 20.25857835091562 ====> total elapsed time: 2.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 19.47 ----> avg loss new params: 30.07 ----> avg loss exist params: 66.64 ----> curr min loss: 19.468179801927736 ====> total elapsed time: 0.0s BATCH NUMBER: 4 PARAMS SAMPLED: 144 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 25.85 ----> avg loss new params: 89.51 ----> avg loss exist params: 68.92 ----> curr min loss: 19.468179801927736 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 21.5 ----> avg loss new params: 30.01 ----> avg loss exist params: 65.39 ----> curr min loss: 19.468179801927736 ====> total elapsed time: 2.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 23.76 ----> avg loss new params: 29.4 ----> avg loss exist params: 62.39 ----> curr min loss: 19.468179801927736 ====> total elapsed time: 0.0s BATCH NUMBER: 5 PARAMS SAMPLED: 192 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 48.76 ----> avg loss new params: 95.72 ----> avg loss exist params: 64.95 ----> curr min loss: 19.468179801927736 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 19.4 ----> avg loss new params: 30.32 ----> avg loss exist params: 62.48 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 2.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 20.73 ----> avg loss new params: 30.09 ----> avg loss exist params: 60.32 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s BATCH NUMBER: 6 PARAMS SAMPLED: 240 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 44.43 ----> avg loss new params: 93.83 ----> avg loss exist params: 62.41 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 20.85 ----> avg loss new params: 26.51 ----> avg loss exist params: 60.3 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 2.0s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 22.49 ----> avg loss new params: 27.91 ----> avg loss exist params: 58.5 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s BATCH NUMBER: 7 PARAMS SAMPLED: 288 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 57.21 ----> avg loss new params: 96.94 ----> avg loss exist params: 60.52 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 21.6 ----> avg loss new params: 29.33 ----> avg loss exist params: 58.96 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 2.0s METHOD: BestBatchSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 21.7 ----> avg loss new params: 29.8 ----> avg loss exist params: 57.58 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s BATCH NUMBER: 8 PARAMS SAMPLED: 336 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 62.8 ----> avg loss new params: 97.94 ----> avg loss exist params: 59.41 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 24.04 ----> avg loss new params: 31.56 ----> avg loss exist params: 58.2 ----> curr min loss: 19.40128801910293 ====> total elapsed time: 2.1s METHOD: BestBatchSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 18.78 ----> avg loss new params: 27.02 ----> avg loss exist params: 56.9 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 384 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 49.95 ----> avg loss new params: 90.04 ----> avg loss exist params: 58.23 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 20.55 ----> avg loss new params: 30.55 ----> avg loss exist params: 57.16 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 2.1s METHOD: BestBatchSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 20.85 ----> avg loss new params: 29.97 ----> avg loss exist params: 56.15 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 432 METHOD: HaltonSampler ----> sim exec elapsed time: 0.0s ----> min loss new params: 33.91 ----> avg loss new params: 89.94 ----> avg loss exist params: 57.36 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 0.0s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 23.68 ----> avg loss new params: 35.37 ----> avg loss exist params: 56.6 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 2.1s METHOD: BestBatchSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.0s ----> min loss new params: 18.78 ----> avg loss new params: 27.49 ----> avg loss exist params: 55.63 ----> curr min loss: 18.777912631604902 ====> total elapsed time: 0.1s # best parameters obtained so far params [ 0 ] array([64., 24., 35.])","title":"Calibration"},{"location":"slack_stock_price_shock/#plots","text":"# index of mimumum loss idxmin = np . argmin ( cal . losses_samp ) param_min = cal . params_samp [ idxmin ] # convergence losses_per_batch = [ cal . losses_samp [ cal . batch_num_samp == i ] for i in range ( int ( max ( cal . batch_num_samp )) + 1 ) ] mins_per_batch = np . array ([ np . min ( l ) for l in losses_per_batch ]) cummin_per_batch = [ np . min ( mins_per_batch [: i + 1 ]) for i in range ( mins_per_batch . shape [ 0 ]) ] plt . figure () plt . plot ( mins_per_batch , \"-o\" , label = \"batch minimum\" ) plt . plot ( cummin_per_batch , \"-o\" , label = \"cumulative minimum\" ) plt . ylabel ( \"loss\" ) plt . xlabel ( \"batch number\" ) plt . legend () <matplotlib.legend.Legend at 0x7f05d0a0eaf0> # agreement between real and simulated time series plt . plot ( slack_shock_data [:, 0 ], \"-\" , label = \"real series\" ) plt . ylabel ( \"Slack stock price\" , ) plt . xlabel ( \"days from 27-8-2020\" ) plt . plot ( cal . series_samp [ idxmin , 0 , :, 0 ] . T , ls = \"--\" , label = \"fitted model\" ) plt . legend () <matplotlib.legend.Legend at 0x7f05b2c8dd30>","title":"plots"},{"location":"tests_on_toy_model/","text":"(function() { function addWidgetsRenderer() { var requireJsScript = document.createElement('script'); requireJsScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js'; var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var jupyterWidgetsScript = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} jupyterWidgetsScript.src = widgetRendererSrc; document.body.appendChild(requireJsScript); document.body.appendChild(jupyterWidgetsScript); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Finding the parameters of a normal distribution In this tutorial we will use black-it to find the mean and variance of a normal distribution by fitting the 'model' to a dataset. Obviously the parameters of a normal distribution can be obtained more efficiently (such as a by maximum likelihood), yet this example can be useful to understand how black-it works in practice. # import standard libraries import numpy as np import matplotlib.pyplot as plt % matplotlib inline We stard by loading the dataset that we want to fit with our model. # load a dataset true_params = [ 1 , 1 ] # in general these are not known! real_data = np . atleast_2d ( np . loadtxt ( f \"data/gaussian_mean { true_params [ 0 ] } _var { true_params [ 1 ] } .txt\" ) ) . T plt . plot ( real_data [:, 0 ]) plt . xlabel ( \"time step\" ) plt . ylabel ( \"value\" ) Text(0, 0.5, 'value') Initialize a calibrator object Then, to set up a calibration one needs to define the following components first: a model to be calibrated a loss function to measure the distance between the real time series and the simulated time series a set of samplers that iteratively suggest a set of parameter values to explore the parameter space that should be explored 1 Model simulator # a normal distribution with unknown mean and variance from models.simple_models import NormalMV # when called with a set of parameter values, the model provides a simulated time series NormalMV ([ 1 , 1 ], N = 10 , seed = 0 ) array([[2.76405235], [1.40015721], [1.97873798], [3.2408932 ], [2.86755799], [0.02272212], [1.95008842], [0.84864279], [0.89678115], [1.4105985 ]]) 2 Loss function # loss function based on the Method Of Moments from black_it.loss_functions.msm import MethodOfMomentsLoss loss = MethodOfMomentsLoss () 3 Samplers # import some samplers from black_it.samplers.best_batch import BestBatchSampler from black_it.samplers.halton import HaltonSampler from black_it.samplers.r_sequence import RSequenceSampler from black_it.samplers.random_forest import RandomForestSampler from black_it.samplers.random_uniform import RandomUniformSampler # initialize the samplers with their specific 'batch_size', i.e. the number of points # explored every time they are called batch_size = 4 random_sampler = RandomUniformSampler ( batch_size = batch_size ) rseq_sampler = RSequenceSampler ( batch_size = batch_size ) halton_sampler = HaltonSampler ( batch_size = batch_size ) best_batch_sampler = BestBatchSampler ( batch_size = batch_size ) random_forest_sampler = RandomForestSampler ( batch_size = batch_size ) samplers = [ random_sampler , rseq_sampler , halton_sampler , random_forest_sampler , best_batch_sampler , ] 4) Parameter space (bounds and precision) # the full space of parameters is defined by the lower and upper bounds # and by the precision of each parameter bounds = [[ 0.00 , 0.01 ], [ 2.00 , 2.00 ]] precisions = [ 0.0001 , 0.0001 ] Finally, initialise a Calibrator object from black_it.calibrator import Calibrator # initialize a Calibrator object cal = Calibrator ( samplers = samplers , real_data = real_data , model = NormalMV , parameters_bounds = bounds , parameters_precision = precisions , ensemble_size = 5 , loss_function = loss , saving_folder = None , ) *** Number of free params: 2. Explorable param space size: 398039901. *** Selecting 4 processes for the parallel evaluation of the model Calibration params , losses = cal . calibrate ( 10 ) BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: RandomUniformSampler ----> sim exec elapsed time: 1.7s ----> min loss new params: 0.17 ----> avg loss new params: 1.41 ----> avg loss exist params: 1.41 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 1.7s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.6 ----> avg loss new params: 1.97 ----> avg loss exist params: 1.69 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.77 ----> avg loss new params: 1.46 ----> avg loss exist params: 1.61 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.2s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.64 ----> avg loss new params: 0.94 ----> avg loss exist params: 1.45 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 1.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.2s ----> min loss new params: 0.54 ----> avg loss new params: 0.82 ----> avg loss exist params: 1.32 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.2s BATCH NUMBER: 2 PARAMS SAMPLED: 20 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.65 ----> avg loss new params: 1.76 ----> avg loss exist params: 1.39 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.68 ----> avg loss new params: 1.84 ----> avg loss exist params: 1.46 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.2s ----> min loss new params: 0.86 ----> avg loss new params: 1.71 ----> avg loss exist params: 1.49 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.2s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.35 ----> avg loss new params: 0.57 ----> avg loss exist params: 1.39 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 1.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.42 ----> avg loss new params: 0.53 ----> avg loss exist params: 1.3 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s BATCH NUMBER: 3 PARAMS SAMPLED: 40 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.96 ----> avg loss new params: 2.14 ----> avg loss exist params: 1.38 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.52 ----> avg loss new params: 1.24 ----> avg loss exist params: 1.37 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.67 ----> avg loss new params: 1.89 ----> avg loss exist params: 1.41 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.34 ----> avg loss new params: 0.57 ----> avg loss exist params: 1.35 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 1.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.29 ----> avg loss new params: 0.55 ----> avg loss exist params: 1.29 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s BATCH NUMBER: 4 PARAMS SAMPLED: 60 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.46 ----> avg loss new params: 2.06 ----> avg loss exist params: 1.34 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.52 ----> avg loss new params: 1.77 ----> avg loss exist params: 1.37 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.92 ----> avg loss new params: 1.45 ----> avg loss exist params: 1.37 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.1 ----> avg loss new params: 0.37 ----> avg loss exist params: 1.32 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.23 ----> avg loss new params: 0.29 ----> avg loss exist params: 1.27 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 5 PARAMS SAMPLED: 80 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.63 ----> avg loss new params: 1.1 ----> avg loss exist params: 1.26 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.17 ----> avg loss new params: 1.67 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.7 ----> avg loss new params: 1.99 ----> avg loss exist params: 1.31 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.25 ----> avg loss new params: 0.41 ----> avg loss exist params: 1.27 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.34 ----> avg loss new params: 0.54 ----> avg loss exist params: 1.24 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 6 PARAMS SAMPLED: 100 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.2s ----> min loss new params: 1.06 ----> avg loss new params: 1.68 ----> avg loss exist params: 1.26 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.2s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.53 ----> avg loss new params: 1.91 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.38 ----> avg loss new params: 1.69 ----> avg loss exist params: 1.3 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.3 ----> avg loss new params: 0.65 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.2 ----> avg loss new params: 0.53 ----> avg loss exist params: 1.25 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 7 PARAMS SAMPLED: 120 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.7 ----> avg loss new params: 1.3 ----> avg loss exist params: 1.25 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.36 ----> avg loss new params: 1.58 ----> avg loss exist params: 1.26 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.51 ----> avg loss new params: 2.12 ----> avg loss exist params: 1.29 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.43 ----> avg loss new params: 0.54 ----> avg loss exist params: 1.27 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.29 ----> avg loss new params: 0.48 ----> avg loss exist params: 1.24 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 8 PARAMS SAMPLED: 140 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.54 ----> avg loss new params: 2.54 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.05 ----> avg loss new params: 1.86 ----> avg loss exist params: 1.3 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.0 ----> avg loss new params: 1.73 ----> avg loss exist params: 1.31 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.54 ----> avg loss new params: 0.64 ----> avg loss exist params: 1.29 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.21 ----> avg loss new params: 0.32 ----> avg loss exist params: 1.27 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 160 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.81 ----> avg loss new params: 2.2 ----> avg loss exist params: 1.29 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.88 ----> avg loss new params: 2.12 ----> avg loss exist params: 1.31 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.63 ----> avg loss new params: 2.04 ----> avg loss exist params: 1.33 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.31 ----> avg loss new params: 0.6 ----> avg loss exist params: 1.31 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.4s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.2 ----> avg loss new params: 0.29 ----> avg loss exist params: 1.29 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 180 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.67 ----> avg loss new params: 1.12 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.58 ----> avg loss new params: 1.31 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.2s ----> min loss new params: 0.52 ----> avg loss new params: 1.26 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.2s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.35 ----> avg loss new params: 0.44 ----> avg loss exist params: 1.27 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.31 ----> avg loss new params: 0.53 ----> avg loss exist params: 1.25 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s # best parameters obtained so far params [ 0 ] array([1.0002, 0.9791]) Plots # index of mimumum loss idxmin = np . argmin ( cal . losses_samp ) param_min = cal . params_samp [ idxmin ] # scatter plot of losses plt . figure ( figsize = ( 6 , 5 )) plt . scatter ( cal . params_samp [:, 0 ], cal . params_samp [:, 1 ], c = cal . losses_samp , edgecolor = \"k\" ) plt . scatter ( param_min [ 0 ], param_min [ 1 ], marker = \"x\" , s = 500 , color = \"y\" ) plt . scatter ( true_params [ 0 ], true_params [ 1 ], marker = \"x\" , s = 500 , color = \"red\" ) plt . xlabel ( \"mean\" ) plt . ylabel ( \"variance\" ) plt . colorbar () <matplotlib.colorbar.Colorbar at 0x7fa43a70f890> from black_it.utils.time_series import get_mom_ts real_moments = get_mom_ts ( cal . real_data ) simulated_moments = get_mom_ts ( cal . series_samp [ idxmin , 0 , :, :]) # agreement of moments plt . figure () plt . plot ( real_moments , \"-o\" , label = \"real series\" ) plt . plot ( simulated_moments , \"-o\" , label = \"simulated series\" ) plt . xlabel ( \"moment index\" ) plt . xticks ( np . arange ( 18 )) plt . ylabel ( \"moments\" ) plt . legend () <matplotlib.legend.Legend at 0x7fa43a589510> # convergence losses_per_batch = [ cal . losses_samp [ cal . batch_num_samp == i ] for i in range ( int ( max ( cal . batch_num_samp )) + 1 ) ] mins_per_batch = np . array ([ np . min ( l ) for l in losses_per_batch ]) cummin_per_batch = [ np . min ( mins_per_batch [: i + 1 ]) for i in range ( mins_per_batch . shape [ 0 ]) ] plt . figure () plt . plot ( mins_per_batch , \"-o\" , label = \"batch minimum\" ) plt . plot ( cummin_per_batch , \"-o\" , label = \"cumulative minimum\" ) plt . ylabel ( \"loss\" ) plt . xlabel ( \"batch number\" ) plt . legend () <matplotlib.legend.Legend at 0x7fa4334355d0>","title":"Toy model"},{"location":"tests_on_toy_model/#finding-the-parameters-of-a-normal-distribution","text":"In this tutorial we will use black-it to find the mean and variance of a normal distribution by fitting the 'model' to a dataset. Obviously the parameters of a normal distribution can be obtained more efficiently (such as a by maximum likelihood), yet this example can be useful to understand how black-it works in practice. # import standard libraries import numpy as np import matplotlib.pyplot as plt % matplotlib inline We stard by loading the dataset that we want to fit with our model. # load a dataset true_params = [ 1 , 1 ] # in general these are not known! real_data = np . atleast_2d ( np . loadtxt ( f \"data/gaussian_mean { true_params [ 0 ] } _var { true_params [ 1 ] } .txt\" ) ) . T plt . plot ( real_data [:, 0 ]) plt . xlabel ( \"time step\" ) plt . ylabel ( \"value\" ) Text(0, 0.5, 'value')","title":"Finding the parameters of a normal distribution"},{"location":"tests_on_toy_model/#initialize-a-calibrator-object","text":"Then, to set up a calibration one needs to define the following components first: a model to be calibrated a loss function to measure the distance between the real time series and the simulated time series a set of samplers that iteratively suggest a set of parameter values to explore the parameter space that should be explored","title":"Initialize a calibrator object"},{"location":"tests_on_toy_model/#1-model-simulator","text":"# a normal distribution with unknown mean and variance from models.simple_models import NormalMV # when called with a set of parameter values, the model provides a simulated time series NormalMV ([ 1 , 1 ], N = 10 , seed = 0 ) array([[2.76405235], [1.40015721], [1.97873798], [3.2408932 ], [2.86755799], [0.02272212], [1.95008842], [0.84864279], [0.89678115], [1.4105985 ]])","title":"1 Model simulator"},{"location":"tests_on_toy_model/#2-loss-function","text":"# loss function based on the Method Of Moments from black_it.loss_functions.msm import MethodOfMomentsLoss loss = MethodOfMomentsLoss ()","title":"2 Loss function"},{"location":"tests_on_toy_model/#3-samplers","text":"# import some samplers from black_it.samplers.best_batch import BestBatchSampler from black_it.samplers.halton import HaltonSampler from black_it.samplers.r_sequence import RSequenceSampler from black_it.samplers.random_forest import RandomForestSampler from black_it.samplers.random_uniform import RandomUniformSampler # initialize the samplers with their specific 'batch_size', i.e. the number of points # explored every time they are called batch_size = 4 random_sampler = RandomUniformSampler ( batch_size = batch_size ) rseq_sampler = RSequenceSampler ( batch_size = batch_size ) halton_sampler = HaltonSampler ( batch_size = batch_size ) best_batch_sampler = BestBatchSampler ( batch_size = batch_size ) random_forest_sampler = RandomForestSampler ( batch_size = batch_size ) samplers = [ random_sampler , rseq_sampler , halton_sampler , random_forest_sampler , best_batch_sampler , ]","title":"3 Samplers"},{"location":"tests_on_toy_model/#4-parameter-space-bounds-and-precision","text":"# the full space of parameters is defined by the lower and upper bounds # and by the precision of each parameter bounds = [[ 0.00 , 0.01 ], [ 2.00 , 2.00 ]] precisions = [ 0.0001 , 0.0001 ]","title":"4) Parameter space (bounds and precision)"},{"location":"tests_on_toy_model/#finally-initialise-a-calibrator-object","text":"from black_it.calibrator import Calibrator # initialize a Calibrator object cal = Calibrator ( samplers = samplers , real_data = real_data , model = NormalMV , parameters_bounds = bounds , parameters_precision = precisions , ensemble_size = 5 , loss_function = loss , saving_folder = None , ) *** Number of free params: 2. Explorable param space size: 398039901. *** Selecting 4 processes for the parallel evaluation of the model","title":"Finally, initialise a Calibrator object"},{"location":"tests_on_toy_model/#calibration","text":"params , losses = cal . calibrate ( 10 ) BATCH NUMBER: 1 PARAMS SAMPLED: 0 METHOD: RandomUniformSampler ----> sim exec elapsed time: 1.7s ----> min loss new params: 0.17 ----> avg loss new params: 1.41 ----> avg loss exist params: 1.41 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 1.7s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.6 ----> avg loss new params: 1.97 ----> avg loss exist params: 1.69 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.77 ----> avg loss new params: 1.46 ----> avg loss exist params: 1.61 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.2s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.64 ----> avg loss new params: 0.94 ----> avg loss exist params: 1.45 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 1.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.2s ----> min loss new params: 0.54 ----> avg loss new params: 0.82 ----> avg loss exist params: 1.32 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.2s BATCH NUMBER: 2 PARAMS SAMPLED: 20 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.65 ----> avg loss new params: 1.76 ----> avg loss exist params: 1.39 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.68 ----> avg loss new params: 1.84 ----> avg loss exist params: 1.46 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.2s ----> min loss new params: 0.86 ----> avg loss new params: 1.71 ----> avg loss exist params: 1.49 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.2s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.35 ----> avg loss new params: 0.57 ----> avg loss exist params: 1.39 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 1.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.42 ----> avg loss new params: 0.53 ----> avg loss exist params: 1.3 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s BATCH NUMBER: 3 PARAMS SAMPLED: 40 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.96 ----> avg loss new params: 2.14 ----> avg loss exist params: 1.38 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.52 ----> avg loss new params: 1.24 ----> avg loss exist params: 1.37 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.67 ----> avg loss new params: 1.89 ----> avg loss exist params: 1.41 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.34 ----> avg loss new params: 0.57 ----> avg loss exist params: 1.35 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 1.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.29 ----> avg loss new params: 0.55 ----> avg loss exist params: 1.29 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s BATCH NUMBER: 4 PARAMS SAMPLED: 60 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.46 ----> avg loss new params: 2.06 ----> avg loss exist params: 1.34 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.52 ----> avg loss new params: 1.77 ----> avg loss exist params: 1.37 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.92 ----> avg loss new params: 1.45 ----> avg loss exist params: 1.37 ----> curr min loss: 0.16632065926583173 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.1 ----> avg loss new params: 0.37 ----> avg loss exist params: 1.32 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.23 ----> avg loss new params: 0.29 ----> avg loss exist params: 1.27 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 5 PARAMS SAMPLED: 80 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.63 ----> avg loss new params: 1.1 ----> avg loss exist params: 1.26 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.17 ----> avg loss new params: 1.67 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.7 ----> avg loss new params: 1.99 ----> avg loss exist params: 1.31 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.25 ----> avg loss new params: 0.41 ----> avg loss exist params: 1.27 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.34 ----> avg loss new params: 0.54 ----> avg loss exist params: 1.24 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 6 PARAMS SAMPLED: 100 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.2s ----> min loss new params: 1.06 ----> avg loss new params: 1.68 ----> avg loss exist params: 1.26 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.2s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.53 ----> avg loss new params: 1.91 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.38 ----> avg loss new params: 1.69 ----> avg loss exist params: 1.3 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.3 ----> avg loss new params: 0.65 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.2 ----> avg loss new params: 0.53 ----> avg loss exist params: 1.25 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 7 PARAMS SAMPLED: 120 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.7 ----> avg loss new params: 1.3 ----> avg loss exist params: 1.25 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.36 ----> avg loss new params: 1.58 ----> avg loss exist params: 1.26 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.51 ----> avg loss new params: 2.12 ----> avg loss exist params: 1.29 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.43 ----> avg loss new params: 0.54 ----> avg loss exist params: 1.27 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.9s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.29 ----> avg loss new params: 0.48 ----> avg loss exist params: 1.24 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 8 PARAMS SAMPLED: 140 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.54 ----> avg loss new params: 2.54 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.05 ----> avg loss new params: 1.86 ----> avg loss exist params: 1.3 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 1.0 ----> avg loss new params: 1.73 ----> avg loss exist params: 1.31 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RandomForestSampler Warning: Repeated samples still found after 5 duplication passes. This is probably due to a small search space. ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.54 ----> avg loss new params: 0.64 ----> avg loss exist params: 1.29 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.7s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.21 ----> avg loss new params: 0.32 ----> avg loss exist params: 1.27 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 9 PARAMS SAMPLED: 160 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.81 ----> avg loss new params: 2.2 ----> avg loss exist params: 1.29 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.88 ----> avg loss new params: 2.12 ----> avg loss exist params: 1.31 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.63 ----> avg loss new params: 2.04 ----> avg loss exist params: 1.33 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.31 ----> avg loss new params: 0.6 ----> avg loss exist params: 1.31 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.4s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.2 ----> avg loss new params: 0.29 ----> avg loss exist params: 1.29 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s BATCH NUMBER: 10 PARAMS SAMPLED: 180 METHOD: RandomUniformSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.67 ----> avg loss new params: 1.12 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: RSequenceSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.58 ----> avg loss new params: 1.31 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s METHOD: HaltonSampler ----> sim exec elapsed time: 0.2s ----> min loss new params: 0.52 ----> avg loss new params: 1.26 ----> avg loss exist params: 1.28 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.2s METHOD: RandomForestSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.35 ----> avg loss new params: 0.44 ----> avg loss exist params: 1.27 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 1.6s METHOD: BestBatchSampler ----> sim exec elapsed time: 0.1s ----> min loss new params: 0.31 ----> avg loss new params: 0.53 ----> avg loss exist params: 1.25 ----> curr min loss: 0.09902649522714026 ====> total elapsed time: 0.1s # best parameters obtained so far params [ 0 ] array([1.0002, 0.9791])","title":"Calibration"},{"location":"tests_on_toy_model/#plots","text":"# index of mimumum loss idxmin = np . argmin ( cal . losses_samp ) param_min = cal . params_samp [ idxmin ] # scatter plot of losses plt . figure ( figsize = ( 6 , 5 )) plt . scatter ( cal . params_samp [:, 0 ], cal . params_samp [:, 1 ], c = cal . losses_samp , edgecolor = \"k\" ) plt . scatter ( param_min [ 0 ], param_min [ 1 ], marker = \"x\" , s = 500 , color = \"y\" ) plt . scatter ( true_params [ 0 ], true_params [ 1 ], marker = \"x\" , s = 500 , color = \"red\" ) plt . xlabel ( \"mean\" ) plt . ylabel ( \"variance\" ) plt . colorbar () <matplotlib.colorbar.Colorbar at 0x7fa43a70f890> from black_it.utils.time_series import get_mom_ts real_moments = get_mom_ts ( cal . real_data ) simulated_moments = get_mom_ts ( cal . series_samp [ idxmin , 0 , :, :]) # agreement of moments plt . figure () plt . plot ( real_moments , \"-o\" , label = \"real series\" ) plt . plot ( simulated_moments , \"-o\" , label = \"simulated series\" ) plt . xlabel ( \"moment index\" ) plt . xticks ( np . arange ( 18 )) plt . ylabel ( \"moments\" ) plt . legend () <matplotlib.legend.Legend at 0x7fa43a589510> # convergence losses_per_batch = [ cal . losses_samp [ cal . batch_num_samp == i ] for i in range ( int ( max ( cal . batch_num_samp )) + 1 ) ] mins_per_batch = np . array ([ np . min ( l ) for l in losses_per_batch ]) cummin_per_batch = [ np . min ( mins_per_batch [: i + 1 ]) for i in range ( mins_per_batch . shape [ 0 ]) ] plt . figure () plt . plot ( mins_per_batch , \"-o\" , label = \"batch minimum\" ) plt . plot ( cummin_per_batch , \"-o\" , label = \"cumulative minimum\" ) plt . ylabel ( \"loss\" ) plt . xlabel ( \"batch number\" ) plt . legend () <matplotlib.legend.Legend at 0x7fa4334355d0>","title":"Plots"}]}